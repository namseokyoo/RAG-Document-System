# RAG ì‹œìŠ¤í…œ í†µí•© ì„±ëŠ¥ ê°œì„  ë¡œë“œë§µ (Qwen3 í†µí•©)

**ì‘ì„±ì¼**: 2025-11-07
**ë²„ì „**: v4.0 Unified Roadmap
**ëª©í‘œ**: NotebookLM ìˆ˜ì¤€ ë‹¬ì„± + Qwen3-Embedding-8B í†µí•©
**ì˜ˆìƒ ì™„ë£Œ**: 2-3ì£¼

---

## ğŸ“Š Executive Summary

### í˜„ì¬ ìƒíƒœ (v3.1 + Phase A-2)
- **Embedding Model**: mxbai-embed-large (1024D, ~335M params)
- **Reranker Model**: multilingual-e5-small (ê¸°ì¡´ ìœ ì§€)
- **Citation Rate**: 80% (Phase A-2 êµ¬í˜„ ì™„ë£Œ)
- **Average Response Time**: 91.1ì´ˆ
- **Cross-domain Pollution**: 4.5%

### ìµœì¢… ëª©í‘œ (v4.0)
- **Embedding Model**: Qwen3-Embedding-8B (ìµœëŒ€ 4096D, 8B params)
- **Reranker Model**: multilingual-e5-small (ë³€ê²½ ì—†ìŒ)
- **Citation Rate**: 95% (NotebookLM ìˆ˜ì¤€)
- **Average Response Time**: 60-70ì´ˆ (25-30% ê°ì†Œ)
- **Cross-domain Pollution**: 0%

### ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ (ëˆ„ì )
| ë‹¨ê³„ | ì •í™•ë„ í–¥ìƒ | ì†ë„ ê°œì„  | Citation Rate | ì£¼ìš” ê°œì„  ì‚¬í•­ |
|------|-------------|-----------|---------------|----------------|
| **Phase A-3** | +5-8% | -10-15ì´ˆ | 80% | Answer Verification ê°•í™” |
| **Phase B-1** | +10-15% | -5ì´ˆ | 80% | Qwen3 ê¸°ë³¸ í†µí•© (2048D) |
| **Phase B-2** | +5-10% | -8-10ì´ˆ | 80% | Matryoshka ìµœì í™” |
| **Phase B-3** | +3-5% | -2ì´ˆ | 80% | Instruction-aware Embedding |
| **Phase C** | +5-8% | +3ì´ˆ | 95% | Citation ìµœì í™” |
| **ì´í•©** | **+28-46%** | **-22-30ì´ˆ** | **95%** | **NotebookLM ìˆ˜ì¤€ ë‹¬ì„±** |

---

## ğŸ¯ Phase A-3: Answer Verification ê°œì„  (ìš°ì„ ìˆœìœ„ 1)

### ëª©í‘œ
- ì¬ìƒì„± ë¹ˆë„ 50% ê°ì†Œ (20% â†’ 10%)
- ì‘ë‹µ ì‹œê°„ 10-15ì´ˆ ë‹¨ì¶•
- LLM í˜¸ì¶œ ë¹„ìš© ê°ì†Œ

### í˜„ì¬ ë¬¸ì œ
```
Query: "kFRET ê°’ì€?"
1ì°¨ ë‹µë³€: "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" (ê¸ˆì§€ êµ¬ë¬¸)
â†’ ê²€ì¦ ì‹¤íŒ¨
â†’ 2ì°¨ ì¬ìƒì„± (+10-15ì´ˆ)
â†’ ì„±ê³µ

ì¬ìƒì„± ë¹ˆë„: ~20% (5ê°œ ì¤‘ 1ê°œ)
```

### êµ¬í˜„ ë‚´ìš©

#### 1. Prompt Engineering ê°•í™” (30ë¶„)

**íŒŒì¼**: `utils/rag_chain.py`
**ë¼ì¸**: ~120-180 (base_prompt_template)

**ë³€ê²½ ì‚¬í•­**:
```python
# Before (í˜„ì¬)
âš ï¸ ì¤‘ìš” ê·œì¹™:
1. ë¬¸ì„œ ìš°ì„  ì›ì¹™
2. ì¼ë°˜ ì§€ì‹ ê¸ˆì§€
3. ì •ë³´ ì—†ìŒ ê¸ˆì§€

# After (ê°œì„ )
âš ï¸ í•µì‹¬ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜):

1. **ê¸ˆì§€ í‘œí˜„** (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€):
   âŒ "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
   âŒ "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"
   âŒ "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

2. **ê¶Œì¥ í‘œí˜„** (ëŒ€ì‹  ì‚¬ìš©):
   âœ… "ì œê³µëœ ë¬¸ì„œì— ë”°ë¥´ë©´, [êµ¬ì²´ì  ì •ë³´]..."
   âœ… "ë¬¸ì„œ #1ì˜ 5í˜ì´ì§€ì—ì„œ [ë‚´ìš©]ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   âœ… "ì§ì ‘ì ì¸ ìˆ˜ì¹˜ëŠ” ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì§€ë§Œ, ê´€ë ¨ ì •ë³´ë¡œëŠ” [ë‚´ìš©]ì´ ìˆìŠµë‹ˆë‹¤"

3. **NotebookLM ìŠ¤íƒ€ì¼ ë‹µë³€ ì˜ˆì‹œ**:
   "According to the provided document (HF_OLED.pptx, slide 5), the kFRET value is approximately 87.8%."
```

**ì˜ˆìƒ íš¨ê³¼**:
- ì¬ìƒì„± ë¹ˆë„: 20% â†’ 15% (-25%)
- ì‘ë‹µ ì‹œê°„: -4-6ì´ˆ

#### 2. Self-Consistency Check (2ì¼)

**ìƒˆ ë©”ì„œë“œ**: `_generate_with_self_consistency()`

**í•µì‹¬ ë¡œì§**:
```python
def _generate_with_self_consistency(self, question: str, context: str, n: int = 3):
    """ì—¬ëŸ¬ ë²ˆ ìƒì„± í›„ ì¼ê´€ì„± ê²€ì¦"""

    # 1. Në²ˆ ë…ë¦½ì ìœ¼ë¡œ ë‹µë³€ ìƒì„± (temperature=0.5)
    answers = []
    for i in range(n):
        answer = self._generate_answer_internal(question, context)
        answers.append(answer)

    # 2. ë‹µë³€ ê°„ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚° (Jaccard similarity)
    consistency_score = self._calculate_answer_consistency(answers)

    # 3. ì¼ê´€ì„±ì— ë”°ë¼ ì²˜ë¦¬
    if consistency_score > 0.8:
        # ë†’ì€ ì¼ê´€ì„± â†’ ê°€ì¥ ìƒì„¸í•œ ë‹µë³€ ì„ íƒ
        return max(answers, key=lambda a: len(a))
    elif consistency_score > 0.5:
        # ì¤‘ê°„ ì¼ê´€ì„± â†’ ê³µí†µ ì •ë³´ ì¶”ì¶œ
        return self._extract_common_info(answers)
    else:
        # ë‚®ì€ ì¼ê´€ì„± â†’ ê²½ê³  í‘œì‹œ
        return f"âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ (ì¼ê´€ì„±: {consistency_score:.1%})\n{answers[0]}"
```

**ì˜ˆìƒ íš¨ê³¼**:
- ì¬ìƒì„± ë¹ˆë„: 15% â†’ 10% (-33%)
- ì‘ë‹µ ì‹œê°„: -6-9ì´ˆ (ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì¬ìƒì„± íšŸìˆ˜ ê°ì†Œ)
- ë‹µë³€ ì‹ ë¢°ë„: +15-20%

### Phase A-3 ì´ ì˜ˆìƒ ì„±ê³¼

| ì§€í‘œ | Before (A-2) | After (A-3) | ê°œì„  |
|------|--------------|-------------|------|
| ì¬ìƒì„± ë¹ˆë„ | 20% | 10% | -50% |
| ì‘ë‹µ ì‹œê°„ | 91.1ì´ˆ | 76-81ì´ˆ | -10-15ì´ˆ |
| ì •í™•ë„ | ê¸°ì¤€ì¹˜ | +5-8% | +5-8% |
| LLM í˜¸ì¶œ ë¹„ìš© | ê¸°ì¤€ì¹˜ | -10% | -10% |

**êµ¬í˜„ ìš°ì„ ìˆœìœ„**: â˜…â˜…â˜…â˜…â˜… (ì¦‰ì‹œ ì°©ìˆ˜)
**ì˜ˆìƒ êµ¬í˜„ ê¸°ê°„**: 2-3ì¼
**ë¦¬ìŠ¤í¬**: ë‚®ìŒ (ê¸°ì¡´ ì‹œìŠ¤í…œ ìœ ì§€)

---

## ğŸš€ Phase B-1: Qwen3-Embedding-8B ê¸°ë³¸ í†µí•© (ìš°ì„ ìˆœìœ„ 2)

### ëª©í‘œ
- ê³ ì„±ëŠ¥ ì„ë² ë”© ëª¨ë¸ë¡œ êµì²´
- ê²€ìƒ‰ ì •í™•ë„ ëŒ€í­ í–¥ìƒ
- í•œêµ­ì–´/ì˜ì–´ í˜¼í•© ë¬¸ì„œ ì²˜ë¦¬ ê°œì„ 

### Qwen3-Embedding-8B íŠ¹ì§•

| íŠ¹ì„± | mxbai-embed-large | Qwen3-Embedding-8B | ê°œì„  |
|------|-------------------|---------------------|------|
| **ëª¨ë¸ í¬ê¸°** | ~335M params | 8B params | +24ë°° |
| **ì„ë² ë”© ì°¨ì›** | 1024D (ê³ ì •) | 1024D/2048D/4096D (ê°€ë³€) | ìœ ì—°ì„± |
| **MTEB ì ìˆ˜** | ~56 | 70.58 | +26% |
| **ë‹¤êµ­ì–´ ì§€ì›** | 100+ languages | 100+ languages | ë™ì¼ |
| **íŠ¹ìˆ˜ ê¸°ëŠ¥** | - | Matryoshka, Instruction-aware | ê³ ê¸‰ |
| **VRAM ìš”êµ¬ëŸ‰** | ~2GB | ~16GB | - |

### êµ¬í˜„ ë‚´ìš©

#### 1. VectorStore ìˆ˜ì • (1ì¼)

**íŒŒì¼**: `utils/vector_store.py`

**ë³€ê²½ ì‚¬í•­**:
```python
# Before
def __init__(self, embedding_model="mxbai-embed-large:latest"):
    self.embedding_model = embedding_model
    self.embedding_dimension = 1024  # ê³ ì •

# After
def __init__(self,
             embedding_model="qwen3-embedding-8b:latest",
             embedding_dimension=2048):  # ê°€ë³€ (ê¸°ë³¸ 2048D)

    self.embedding_model = embedding_model
    self.embedding_dimension = embedding_dimension

    # Qwen3 ì „ìš© ì„¤ì • ê²€ì¦
    if "qwen3" in embedding_model.lower():
        assert embedding_dimension in [1024, 2048, 4096], \
            "Qwen3ëŠ” 1024, 2048, 4096 ì°¨ì›ë§Œ ì§€ì›í•©ë‹ˆë‹¤"
        print(f"[VectorStore] Qwen3-Embedding-8B ì‚¬ìš© (ì°¨ì›: {embedding_dimension}D)")
```

#### 2. ChromaDB ì¬êµ¬ì¶• (4-6ì‹œê°„)

**í•„ìˆ˜ ì‘ì—…**:
1. ê¸°ì¡´ ChromaDB ë°±ì—…
2. ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± (2048D ì°¨ì›)
3. ì „ì²´ ë¬¸ì„œ ì¬ì„ë² ë”©
4. ì¸ë±ìŠ¤ ì¬êµ¬ì¶•

**ìŠ¤í¬ë¦½íŠ¸**: `scripts/migrate_to_qwen3.py`
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""ChromaDBë¥¼ Qwen3-Embedding-8Bë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""

import os
from utils.vector_store import VectorStoreManager

def migrate_to_qwen3():
    """ê¸°ì¡´ ë¬¸ì„œë¥¼ Qwen3ë¡œ ì¬ì„ë² ë”©"""

    # 1. ê¸°ì¡´ DB ë°±ì—…
    print("1. ê¸°ì¡´ ChromaDB ë°±ì—… ì¤‘...")
    os.system("cp -r ./chromadb ./chromadb_backup_mxbai")

    # 2. ê¸°ì¡´ ë¬¸ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    print("2. ê¸°ì¡´ ë¬¸ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    old_vectorstore = VectorStoreManager(
        embedding_model="mxbai-embed-large:latest",
        embedding_dimension=1024
    )
    existing_docs = old_vectorstore.get_all_documents()

    # 3. ìƒˆ VectorStore ì´ˆê¸°í™” (Qwen3)
    print("3. Qwen3 VectorStore ì´ˆê¸°í™” ì¤‘...")
    new_vectorstore = VectorStoreManager(
        embedding_model="qwen3-embedding-8b:latest",
        embedding_dimension=2048,  # ê· í˜• ì¡íŒ ì°¨ì›
        persist_directory="./chromadb_qwen3"
    )

    # 4. ë¬¸ì„œ ì¬ì„ë² ë”© ë° ì¶”ê°€
    print(f"4. {len(existing_docs)}ê°œ ë¬¸ì„œ ì¬ì„ë² ë”© ì¤‘...")
    for i, doc in enumerate(existing_docs):
        new_vectorstore.add_documents([doc])
        if (i+1) % 10 == 0:
            print(f"   ì§„í–‰: {i+1}/{len(existing_docs)} ({(i+1)/len(existing_docs)*100:.1f}%)")

    # 5. ê¸°ì¡´ DB êµì²´
    print("5. ê¸°ì¡´ ChromaDB êµì²´ ì¤‘...")
    os.system("rm -rf ./chromadb")
    os.system("mv ./chromadb_qwen3 ./chromadb")

    print("âœ… Qwen3 ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")

if __name__ == "__main__":
    migrate_to_qwen3()
```

#### 3. ì°¨ì› ì„ íƒ ì „ëµ (30ë¶„)

**ì´ˆê¸° ê¶Œì¥**: 2048D (ê· í˜•)

| ì°¨ì› | ì •í™•ë„ | ì†ë„ | VRAM | ì¶”ì²œ ìš©ë„ |
|------|--------|------|------|-----------|
| 1024D | ë³´í†µ | ë¹ ë¦„ | ë‚®ìŒ | ë¹ ë¥¸ ê²€ìƒ‰ ìš°ì„  |
| 2048D | ë†’ìŒ | ë³´í†µ | ì¤‘ê°„ | **ê· í˜• ì¡íŒ ì„ íƒ (ê¶Œì¥)** |
| 4096D | ìµœê³  | ëŠë¦¼ | ë†’ìŒ | ì •í™•ë„ ìµœìš°ì„  |

**í…ŒìŠ¤íŠ¸ í›„ ì¡°ì •**:
- ì •í™•ë„ ìš°ì„  â†’ 4096D
- ì†ë„ ìš°ì„  â†’ 1024D

### Phase B-1 ì˜ˆìƒ ì„±ê³¼

| ì§€í‘œ | Before (A-3) | After (B-1) | ê°œì„  |
|------|--------------|-------------|------|
| ê²€ìƒ‰ ì •í™•ë„ | ê¸°ì¤€ì¹˜ | +10-15% | +10-15% |
| MTEB ì ìˆ˜ | ~56 | ~70.58 | +26% |
| ì‘ë‹µ ì‹œê°„ | 76-81ì´ˆ | 71-76ì´ˆ | -5ì´ˆ |
| í•œêµ­ì–´ ì²˜ë¦¬ | ë³´í†µ | ìš°ìˆ˜ | +20% |
| ë‹¤ì¤‘ ë„ë©”ì¸ ê²€ìƒ‰ | ë³´í†µ | ìš°ìˆ˜ | +15% |

**êµ¬í˜„ ìš°ì„ ìˆœìœ„**: â˜…â˜…â˜…â˜…â˜† (Phase A-3 ì´í›„)
**ì˜ˆìƒ êµ¬í˜„ ê¸°ê°„**: 2ì¼ (ì½”ë“œ ìˆ˜ì •) + 4-6ì‹œê°„ (ì¬ì„ë² ë”©)
**ë¦¬ìŠ¤í¬**: ì¤‘ê°„ (VRAM 16GB í•„ìš”, ì¬ì„ë² ë”© ì‹œê°„)

---

## âš¡ Phase B-2: Matryoshka ì°¨ì› ìµœì í™” (ìš°ì„ ìˆœìœ„ 3)

### ëª©í‘œ
- ë‹¤ë‹¨ê³„ ê²€ìƒ‰ìœ¼ë¡œ ì†ë„ 30-50% í–¥ìƒ
- ì •í™•ë„ ìœ ì§€ ë˜ëŠ” ì†Œí­ í–¥ìƒ
- ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± ê·¹ëŒ€í™”

### Matryoshka Representation Learning (MRL) ì›ë¦¬

```
ê¸°ì¡´ ë°©ì‹ (Single-dimension):
Query â†’ 2048D ì„ë² ë”© â†’ ì „ì²´ DB ê²€ìƒ‰ (ëŠë¦¼)

Matryoshka ë°©ì‹ (Multi-stage):
Query â†’ 1024D (ë¹ ë¥¸ í•„í„°ë§, 100ê°œ í›„ë³´)
      â†’ 2048D (ì¤‘ê°„ Re-ranking, 20ê°œ í›„ë³´)
      â†’ 4096D (ì •ë°€ ìµœì¢… ì„ íƒ, 5ê°œ ê²°ê³¼)

ê²°ê³¼: ì†ë„ 30-50% í–¥ìƒ, ì •í™•ë„ ìœ ì§€
```

### êµ¬í˜„ ë‚´ìš©

#### 1. HybridRetriever í™•ì¥ (2ì¼)

**íŒŒì¼**: `utils/hybrid_retriever.py`

**ìƒˆ ë©”ì„œë“œ**: `hierarchical_search()`

```python
class HybridRetriever:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° (Matryoshka ì§€ì›)"""

    def __init__(self, vectorstore, enable_matryoshka=False):
        self.vectorstore = vectorstore
        self.enable_matryoshka = enable_matryoshka

    def hierarchical_search(self, query: str, final_k: int = 5) -> List[Document]:
        """ê³„ì¸µì  ê²€ìƒ‰ (Matryoshka)

        3ë‹¨ê³„ ê²€ìƒ‰:
        1. 1024D: ë¹ ë¥¸ í•„í„°ë§ (k=100)
        2. 2048D: ì¤‘ê°„ Re-ranking (k=20)
        3. 4096D: ì •ë°€ ìµœì¢… ì„ íƒ (k=5)
        """

        if not self.enable_matryoshka:
            # ê¸°ì¡´ ë°©ì‹: ë‹¨ì¼ ì°¨ì› ê²€ìƒ‰
            return self.search(query, top_k=final_k)

        print("  [SEARCH] Matryoshka ê³„ì¸µì  ê²€ìƒ‰ ì‹œì‘")

        # Stage 1: ë¹ ë¥¸ í•„í„°ë§ (1024D)
        print("    [Stage 1] 1024D ê²€ìƒ‰ (k=100)")
        query_emb_1024 = self._embed_query(query, dimension=1024)
        candidates_100 = self.vectorstore.similarity_search_by_vector(
            query_emb_1024, k=100
        )
        print(f"    [OK] 100ê°œ í›„ë³´ ì¶”ì¶œ (0.5-1ì´ˆ)")

        # Stage 2: ì¤‘ê°„ Re-ranking (2048D)
        print("    [Stage 2] 2048D Re-ranking (k=20)")
        query_emb_2048 = self._embed_query(query, dimension=2048)
        scores_2048 = [
            self._cosine_similarity(query_emb_2048, self._embed_doc(doc, 2048))
            for doc in candidates_100
        ]
        candidates_20 = self._top_k_by_score(candidates_100, scores_2048, k=20)
        print(f"    [OK] 20ê°œ í›„ë³´ ì¶”ì¶œ (2-3ì´ˆ)")

        # Stage 3: ì •ë°€ ìµœì¢… ì„ íƒ (4096D)
        print("    [Stage 3] 4096D ì •ë°€ ê²€ìƒ‰ (k={final_k})")
        query_emb_4096 = self._embed_query(query, dimension=4096)
        scores_4096 = [
            self._cosine_similarity(query_emb_4096, self._embed_doc(doc, 4096))
            for doc in candidates_20
        ]
        final_results = self._top_k_by_score(candidates_20, scores_4096, k=final_k)
        print(f"    [OK] {final_k}ê°œ ìµœì¢… ê²°ê³¼ (1-2ì´ˆ)")

        return final_results

    def _embed_query(self, text: str, dimension: int) -> np.ndarray:
        """ì¿¼ë¦¬ ì„ë² ë”© (ì°¨ì› ì§€ì •)"""
        # Qwen3 Ollama API í˜¸ì¶œ ì‹œ dimension íŒŒë¼ë¯¸í„° ì „ë‹¬
        response = ollama.embeddings(
            model=self.embedding_model,
            prompt=text,
            options={"dimension": dimension}
        )
        return np.array(response['embedding'])
```

#### 2. ì°¨ì›ë³„ ìºì‹± ì „ëµ (1ì¼)

**ìµœì í™” í¬ì¸íŠ¸**:
- 1024D ì„ë² ë”© â†’ ìºì‹œ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
- 2048D/4096D â†’ ì˜¨ë””ë§¨ë“œ ê³„ì‚°

### Phase B-2 ì˜ˆìƒ ì„±ê³¼

| ì§€í‘œ | Before (B-1) | After (B-2) | ê°œì„  |
|------|--------------|-------------|------|
| ê²€ìƒ‰ ì†ë„ | 15-20ì´ˆ | 8-12ì´ˆ | -30-50% |
| ì •í™•ë„ | ê¸°ì¤€ì¹˜ | +5-10% | +5-10% |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 100% | 70% | -30% |
| CPU/GPU íš¨ìœ¨ | ë³´í†µ | ë†’ìŒ | +40% |

**êµ¬í˜„ ìš°ì„ ìˆœìœ„**: â˜…â˜…â˜…â˜…â˜† (Phase B-1 ì´í›„)
**ì˜ˆìƒ êµ¬í˜„ ê¸°ê°„**: 3ì¼
**ë¦¬ìŠ¤í¬**: ì¤‘ê°„ (Ollama dimension íŒŒë¼ë¯¸í„° ì§€ì› ì—¬ë¶€ í™•ì¸ í•„ìš”)

---

## ğŸ“ Phase B-3: Instruction-Aware Embedding (ìš°ì„ ìˆœìœ„ 4)

### ëª©í‘œ
- íƒœìŠ¤í¬ë³„ ìµœì í™”ë¡œ ì •í™•ë„ 1-5% ì¶”ê°€ í–¥ìƒ
- ê²€ìƒ‰/ë¬¸ì„œ ì„ë² ë”© êµ¬ë¶„ìœ¼ë¡œ ê²€ìƒ‰ í’ˆì§ˆ ê°œì„ 

### Instruction-Aware Embedding ì›ë¦¬

```
ê¸°ì¡´ ë°©ì‹:
Query: "TADFë€ ë¬´ì—‡ì¸ê°€?"
â†’ Embedding(query) vs Embedding(document)

Instruction-Aware:
Query: "Represent this query for retrieving relevant documents: TADFë€ ë¬´ì—‡ì¸ê°€?"
â†’ Embedding(instructed_query) vs Embedding(instructed_document)

íš¨ê³¼: ê²€ìƒ‰ ì˜ë„ ëª…í™•í™”, +1-5% ì •í™•ë„
```

### êµ¬í˜„ ë‚´ìš©

#### 1. Instruction Template ì •ì˜ (30ë¶„)

**íŒŒì¼**: `utils/vector_store.py`

```python
class VectorStoreManager:
    """VectorStore ê´€ë¦¬ì (Instruction-aware)"""

    # Instruction Templates (Qwen3 ê³µì‹ ê¶Œì¥)
    INSTRUCTION_TEMPLATES = {
        "retrieval_query": "Represent this query for retrieving relevant documents: ",
        "retrieval_document": "Represent this document for retrieval: ",
        "similarity_query": "Represent this sentence for measuring similarity: ",
        "classification": "Classify this document: "
    }

    def embed_with_instruction(self, text: str, task: str = "retrieval_query") -> np.ndarray:
        """Instruction-aware ì„ë² ë”©

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            task: íƒœìŠ¤í¬ íƒ€ì… (retrieval_query, retrieval_document ë“±)
        """
        instruction = self.INSTRUCTION_TEMPLATES.get(task, "")
        instructed_text = f"{instruction}{text}"

        return self._embed_text(instructed_text)
```

#### 2. RAGChain í†µí•© (1ì¼)

**íŒŒì¼**: `utils/rag_chain.py`

**ìˆ˜ì • ìœ„ì¹˜**:
- `query()` ë©”ì„œë“œ: ì¿¼ë¦¬ ì„ë² ë”© ì‹œ "retrieval_query" ì§€ì‹œë¬¸
- `add_documents()` ë©”ì„œë“œ: ë¬¸ì„œ ì„ë² ë”© ì‹œ "retrieval_document" ì§€ì‹œë¬¸
- `_find_best_source_for_sentence()`: Citation ì‹œ "similarity_query" ì§€ì‹œë¬¸

```python
# Query ì„ë² ë”©
query_embedding = self.vectorstore.embed_with_instruction(
    question,
    task="retrieval_query"
)

# ë¬¸ì„œ ì„ë² ë”© (ì¸ë±ì‹± ì‹œ)
doc_embedding = self.vectorstore.embed_with_instruction(
    document.page_content,
    task="retrieval_document"
)

# Citation ë¬¸ì¥ ë§¤ì¹­
sentence_embedding = self.vectorstore.embed_with_instruction(
    sentence,
    task="similarity_query"
)
```

### Phase B-3 ì˜ˆìƒ ì„±ê³¼

| ì§€í‘œ | Before (B-2) | After (B-3) | ê°œì„  |
|------|--------------|-------------|------|
| ê²€ìƒ‰ ì •í™•ë„ | ê¸°ì¤€ì¹˜ | +3-5% | +3-5% |
| Citation ì •í™•ë„ | 80% | 85-88% | +5-8% |
| ì‘ë‹µ ì‹œê°„ | 8-12ì´ˆ | 6-10ì´ˆ | -2ì´ˆ |
| False Positive | ê¸°ì¤€ì¹˜ | -10-15% | -10-15% |

**êµ¬í˜„ ìš°ì„ ìˆœìœ„**: â˜…â˜…â˜…â˜†â˜† (Phase B-2 ì´í›„)
**ì˜ˆìƒ êµ¬í˜„ ê¸°ê°„**: 1.5ì¼
**ë¦¬ìŠ¤í¬**: ë‚®ìŒ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™•ì¥)

---

## ğŸ¯ Phase C: Citation Rate ìµœì í™” (ìš°ì„ ìˆœìœ„ 5)

### ëª©í‘œ
- Citation Rate 80% â†’ 95% (NotebookLM ìˆ˜ì¤€)
- ëª¨ë“  ê´€ë ¨ ë¬¸ì¥ì— ì •í™•í•œ ì¶œì²˜ í‘œì‹œ

### í˜„ì¬ ìƒíƒœ (Phase A-2)
```
Query: "TADFë€ ë¬´ì—‡ì¸ê°€?"
ë‹µë³€: 4ë¬¸ì¥
Citation: 4/5 ì¶œì²˜ (80%)

ë¬¸ì œì :
- 1ê°œ ì¶œì²˜ ëˆ„ë½
- ì§§ì€ ë¬¸ì¥ (<15ì) Skip
- ì„ê³„ê°’ 0.4 ì œì•½
```

### êµ¬í˜„ ë‚´ìš©

#### 1. ì„ê³„ê°’ ìµœì í™” (1ì¼)

**íŒŒì¼**: `utils/rag_chain.py`
**ë©”ì„œë“œ**: `_find_best_source_for_sentence()`

```python
# Before
SIMILARITY_THRESHOLD = 0.4  # ê³ ì •

# After
def _get_adaptive_threshold(self, sentence: str, sources: List[Document]) -> float:
    """ë¬¸ì¥ ê¸¸ì´ì™€ ì¶œì²˜ ê°œìˆ˜ì— ë”°ë¼ ì„ê³„ê°’ ì¡°ì •"""

    # ê¸°ë³¸ ì„ê³„ê°’
    base_threshold = 0.35  # 0.4 â†’ 0.35 (ë” ê´€ëŒ€)

    # ë¬¸ì¥ ê¸¸ì´ì— ë”°ë¼ ì¡°ì •
    if len(sentence) < 20:
        # ì§§ì€ ë¬¸ì¥: ë” ê´€ëŒ€í•˜ê²Œ
        return base_threshold - 0.05  # 0.30
    elif len(sentence) > 50:
        # ê¸´ ë¬¸ì¥: ë” ì—„ê²©í•˜ê²Œ
        return base_threshold + 0.05  # 0.40

    return base_threshold
```

**ì˜ˆìƒ íš¨ê³¼**: 80% â†’ 88-90% (+8-10%)

#### 2. ë¬¸ì¥ ë¶„ë¦¬ ê°œì„  (1ì¼)

**í˜„ì¬ ë¬¸ì œ**:
```python
# í˜„ì¬: ì •ê·œì‹ ê¸°ë°˜ ë¶„ë¦¬
sentences = re.split(r'([.!?])\s+', text)

ë¬¸ì œ:
- "Dr.", "Mr." ë“± ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ì¡±
- í•œêµ­ì–´ ë³µë¬¸ ì²˜ë¦¬ ë¯¸í¡
- ì ‘ì†ì‚¬ ì²˜ë¦¬ ë¶ˆì™„ì „
```

**ê°œì„ ì•ˆ**: KSS (Korean Sentence Splitter) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©

```python
import kss

def _split_sentences(self, text: str) -> List[str]:
    """í•œêµ­ì–´ íŠ¹í™” ë¬¸ì¥ ë¶„ë¦¬ (KSS)"""

    # KSS ì‚¬ìš© (í•œêµ­ì–´ íŠ¹í™”)
    sentences = kss.split_sentences(text)

    # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ë³‘í•© (ì ‘ì†ì‚¬, ì „í™˜ì–´ ë“±)
    merged = []
    temp = ""
    for sent in sentences:
        if len(sent) < 10:
            temp += " " + sent
        else:
            if temp:
                merged.append(temp + " " + sent)
                temp = ""
            else:
                merged.append(sent)

    return merged
```

**ì˜ˆìƒ íš¨ê³¼**: 88-90% â†’ 92-93% (+3-4%)

#### 3. Multi-Source Citation (1ì¼)

**ì•„ì´ë””ì–´**: í•œ ë¬¸ì¥ì— ì—¬ëŸ¬ ì¶œì²˜ í—ˆìš©

```python
# Before
"TADFëŠ” ì‚¼ì¤‘í•­ì„ í™œìš©í•©ë‹ˆë‹¤. [ë¬¸ì„œ1, p.5]"

# After (Multi-Source)
"TADFëŠ” ì‚¼ì¤‘í•­ì„ í™œìš©í•˜ë©°[ë¬¸ì„œ1, p.5], ë†’ì€ íš¨ìœ¨ì„ ë³´ì…ë‹ˆë‹¤[ë¬¸ì„œ2, p.12]."
```

**êµ¬í˜„**:
```python
def _find_all_relevant_sources(self, sentence: str, sources: List[Document]) -> List[Document]:
    """ë¬¸ì¥ê³¼ ê´€ë ¨ëœ ëª¨ë“  ì¶œì²˜ ì°¾ê¸° (ì„ê³„ê°’ ì´ìƒ)"""

    sentence_embedding = self._embed_text(sentence)
    relevant_sources = []

    for source in sources:
        source_embedding = self._embed_text(source.page_content[:500])
        similarity = self._cosine_similarity(sentence_embedding, source_embedding)

        # ì„ê³„ê°’ ì´ìƒì´ë©´ ëª¨ë‘ ì¶”ê°€
        if similarity > self._get_adaptive_threshold(sentence, sources):
            relevant_sources.append((source, similarity))

    # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
    relevant_sources.sort(key=lambda x: x[1], reverse=True)

    # ìµœëŒ€ 2ê°œê¹Œì§€ (ê³¼ë„í•œ Citation ë°©ì§€)
    return [src for src, _ in relevant_sources[:2]]
```

**ì˜ˆìƒ íš¨ê³¼**: 92-93% â†’ 95% (+2-3%)

### Phase C ì˜ˆìƒ ì„±ê³¼

| ì§€í‘œ | Before (B-3) | After (C) | ê°œì„  |
|------|--------------|-------------|------|
| Citation Rate | 80% | 95% | +15% |
| ì •í™•ë„ | ê¸°ì¤€ì¹˜ | +5-8% | +5-8% |
| ì‚¬ìš©ì ì‹ ë¢°ë„ | - | - | +25-30% |
| ì‘ë‹µ ì‹œê°„ | 6-10ì´ˆ | 9-13ì´ˆ | +3ì´ˆ (Citation ê³„ì‚°) |

**êµ¬í˜„ ìš°ì„ ìˆœìœ„**: â˜…â˜…â˜…â˜…â˜† (Phase B-3 ì´í›„, ë˜ëŠ” A-3 ì§í›„)
**ì˜ˆìƒ êµ¬í˜„ ê¸°ê°„**: 3ì¼
**ë¦¬ìŠ¤í¬**: ë‚®ìŒ (A-2 í™•ì¥)

---

## ğŸ“Š í†µí•© ì„±ëŠ¥ ì˜ˆìƒì¹˜

### ëˆ„ì  ê°œì„  íš¨ê³¼

| Phase | ì •í™•ë„ | ì†ë„ (ì‘ë‹µ ì‹œê°„) | Citation Rate | ëˆ„ì  ì •í™•ë„ | ëˆ„ì  ì‹œê°„ |
|-------|--------|------------------|---------------|-------------|-----------|
| **Baseline (v3.1)** | 0% | 91.1ì´ˆ | 57.8% | 0% | 91.1ì´ˆ |
| **+ A-2 (ì™„ë£Œ)** | - | 91.1ì´ˆ | 80.0% | 0% | 91.1ì´ˆ |
| **+ A-3** | +5-8% | -10-15ì´ˆ | 80% | +5-8% | 76-81ì´ˆ |
| **+ B-1 (Qwen3)** | +10-15% | -5ì´ˆ | 80% | +15-23% | 71-76ì´ˆ |
| **+ B-2 (Matryoshka)** | +5-10% | -8-10ì´ˆ | 80% | +20-33% | 61-68ì´ˆ |
| **+ B-3 (Instruction)** | +3-5% | -2ì´ˆ | 85-88% | +23-38% | 59-66ì´ˆ |
| **+ C (Citation)** | +5-8% | +3ì´ˆ | 95% | +28-46% | 62-69ì´ˆ |

### ìµœì¢… ëª©í‘œ ë‹¬ì„± (v4.0)

| ì§€í‘œ | v3.1 Baseline | v4.0 Final | ê°œì„  |
|------|---------------|------------|------|
| **ì „ì²´ ì •í™•ë„** | ê¸°ì¤€ì¹˜ | +28-46% | +28-46% |
| **ì‘ë‹µ ì‹œê°„** | 91.1ì´ˆ | 62-69ì´ˆ | -22-29ì´ˆ (-24-32%) |
| **Citation Rate** | 57.8% | 95% | +37.2%p |
| **ì¬ìƒì„± ë¹ˆë„** | 20% | 10% | -50% |
| **í¬ë¡œìŠ¤ ë„ë©”ì¸ ì˜¤ì—¼** | 4.5% | 0% | -100% |
| **MTEB ì ìˆ˜** | ~56 | ~70.58 | +26% |
| **ì‚¬ìš©ì ì‹ ë¢°ë„** | - | - | +40-50% |

### ë‹¨ê³„ë³„ ìš°ì„ ìˆœìœ„ (ê¶Œì¥ ìˆœì„œ)

```
1. Phase A-3 (Answer Verification)
   â””â”€> ì¦‰ì‹œ íš¨ê³¼, ë¦¬ìŠ¤í¬ ë‚®ìŒ

2. Phase B-1 (Qwen3 í†µí•©)
   â””â”€> ê°€ì¥ í° ì„±ëŠ¥ í–¥ìƒ, VRAM 16GB í•„ìš”

3. Phase B-2 (Matryoshka ìµœì í™”)
   â””â”€> ì†ë„ ëŒ€í­ í–¥ìƒ, B-1 ì„ í–‰ í•„ìˆ˜

4. Phase B-3 (Instruction-Aware)
   â””â”€> ì¶”ê°€ ì •í™•ë„ ê°œì„ , B-1 ì„ í–‰ í•„ìˆ˜

5. Phase C (Citation ìµœì í™”)
   â””â”€> NotebookLM ìˆ˜ì¤€ ë‹¬ì„±, ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥
```

**ëŒ€ì•ˆ ìš°ì„ ìˆœìœ„** (Citation ìš°ì„  ì‹œ):
```
1. Phase A-3
2. Phase C (Citation ìµœì í™”)
3. Phase B-1 (Qwen3)
4. Phase B-2, B-3
```

---

## ğŸ› ï¸ êµ¬í˜„ ê°€ì´ë“œ

### Phase A-3 êµ¬í˜„ ë‹¨ê³„

**Day 1-2: Prompt Engineering + Self-Consistency**
1. `utils/rag_chain.py` Prompt ìˆ˜ì • (30ë¶„)
2. `_generate_with_self_consistency()` êµ¬í˜„ (4ì‹œê°„)
3. `_calculate_answer_consistency()` êµ¬í˜„ (2ì‹œê°„)
4. í†µí•© í…ŒìŠ¤íŠ¸ (2ì‹œê°„)

**Day 3: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦**
1. 45ê°œ ì¿¼ë¦¬ ì¬í…ŒìŠ¤íŠ¸
2. ì¬ìƒì„± ë¹ˆë„ ì¸¡ì •
3. ì„±ëŠ¥ ë³´ê³ ì„œ ì‘ì„±

### Phase B-1 êµ¬í˜„ ë‹¨ê³„

**Day 1: Qwen3 ë‹¤ìš´ë¡œë“œ ë° ì„¤ì •**
```bash
# Ollamaì— Qwen3 ëª¨ë¸ pull
ollama pull qwen3-embedding-8b:latest

# ëª¨ë¸ í™•ì¸
ollama list | grep qwen3
```

**Day 2-3: ì½”ë“œ ìˆ˜ì •**
1. `utils/vector_store.py` ìˆ˜ì • (2ì‹œê°„)
2. `scripts/migrate_to_qwen3.py` ì‘ì„± (2ì‹œê°„)
3. ChromaDB ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ (4-6ì‹œê°„)
4. í†µí•© í…ŒìŠ¤íŠ¸ (2ì‹œê°„)

**Day 4: ì„±ëŠ¥ ë¹„êµ**
1. mxbai vs Qwen3 ë¹„êµ í…ŒìŠ¤íŠ¸
2. MTEB ì ìˆ˜ ê²€ì¦
3. ì°¨ì› ì¡°ì • (1024D/2048D/4096D ë¹„êµ)

### Phase B-2 êµ¬í˜„ ë‹¨ê³„

**Day 1-2: Hierarchical Search êµ¬í˜„**
1. `utils/hybrid_retriever.py` í™•ì¥ (4ì‹œê°„)
2. `hierarchical_search()` ë©”ì„œë“œ (4ì‹œê°„)
3. ìºì‹± ì „ëµ êµ¬í˜„ (2ì‹œê°„)

**Day 3: ìµœì í™” ë° í…ŒìŠ¤íŠ¸**
1. ì†ë„ ë²¤ì¹˜ë§ˆí¬
2. ì •í™•ë„ ê²€ì¦
3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (k=100/20/5 ì¡°ì •)

### Phase B-3 êµ¬í˜„ ë‹¨ê³„

**Day 1: Instruction Template**
1. `utils/vector_store.py` í™•ì¥ (2ì‹œê°„)
2. `embed_with_instruction()` êµ¬í˜„ (2ì‹œê°„)

**Day 2: RAGChain í†µí•©**
1. Query ì„ë² ë”© ìˆ˜ì • (1ì‹œê°„)
2. Document ì„ë² ë”© ìˆ˜ì • (1ì‹œê°„)
3. Citation ì„ë² ë”© ìˆ˜ì • (1ì‹œê°„)
4. í†µí•© í…ŒìŠ¤íŠ¸ (3ì‹œê°„)

### Phase C êµ¬í˜„ ë‹¨ê³„

**Day 1: ì„ê³„ê°’ ìµœì í™”**
1. `_get_adaptive_threshold()` êµ¬í˜„ (2ì‹œê°„)
2. íŒŒë¼ë¯¸í„° íŠœë‹ (2ì‹œê°„)

**Day 2: ë¬¸ì¥ ë¶„ë¦¬ ê°œì„ **
1. KSS ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (`pip install kss`)
2. `_split_sentences()` ì¬êµ¬í˜„ (3ì‹œê°„)

**Day 3: Multi-Source Citation**
1. `_find_all_relevant_sources()` êµ¬í˜„ (3ì‹œê°„)
2. Citation í¬ë§· ê°œì„  (2ì‹œê°„)
3. ìµœì¢… í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (3ì‹œê°„)

---

## ğŸ“¦ Dependencies ì¶”ê°€

**requirements.txt ì—…ë°ì´íŠ¸**:
```txt
# ê¸°ì¡´ dependencies
...

# Phase C: í•œêµ­ì–´ ë¬¸ì¥ ë¶„ë¦¬
kss>=4.5.4

# Phase B: Qwen3 (Ollamaì—ì„œ ì œê³µ, ë³„ë„ ì„¤ì¹˜ ë¶ˆí•„ìš”)
# ollama pull qwen3-embedding-8b:latest
```

---

## âš ï¸ ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘

### Phase B-1 ë¦¬ìŠ¤í¬: VRAM ë¶€ì¡±

**ë¬¸ì œ**: Qwen3-Embedding-8BëŠ” ~16GB VRAM í•„ìš”

**ëŒ€ì‘ì±…**:
1. **ì°¨ì› ì¶•ì†Œ**: 2048D â†’ 1024D (VRAM ~8GB)
2. **ë°°ì¹˜ ì²˜ë¦¬**: ë¬¸ì„œ ì„ë² ë”© ì‹œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì •
3. **Fallback**: VRAM ë¶€ì¡± ì‹œ mxbaië¡œ ë³µê·€

```python
try:
    # Qwen3 ì‹œë„
    vectorstore = VectorStoreManager(
        embedding_model="qwen3-embedding-8b:latest",
        embedding_dimension=2048
    )
except OutOfMemoryError:
    # Fallback to mxbai
    print("âš ï¸ VRAM ë¶€ì¡±, mxbai-embed-largeë¡œ ë³µê·€")
    vectorstore = VectorStoreManager(
        embedding_model="mxbai-embed-large:latest",
        embedding_dimension=1024
    )
```

### Phase B-2 ë¦¬ìŠ¤í¬: Ollama Dimension íŒŒë¼ë¯¸í„° ë¯¸ì§€ì›

**ë¬¸ì œ**: Ollamaê°€ Qwen3ì˜ `dimension` íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

**ëŒ€ì‘ì±…**:
1. **ì‚¬ì „ í™•ì¸**: Ollama API ë¬¸ì„œ í™•ì¸
2. **í…ŒìŠ¤íŠ¸**: ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸ë¡œ dimension íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸
3. **ëŒ€ì•ˆ**: Dimension ê³ ì • (2048D ë˜ëŠ” 4096D) ì‚¬ìš©

```python
# í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
import ollama

try:
    response = ollama.embeddings(
        model="qwen3-embedding-8b:latest",
        prompt="test",
        options={"dimension": 1024}
    )
    print("âœ… Dimension íŒŒë¼ë¯¸í„° ì§€ì›ë¨")
except Exception as e:
    print(f"âŒ Dimension íŒŒë¼ë¯¸í„° ë¯¸ì§€ì›: {e}")
    print("â†’ ëŒ€ì•ˆ: ê³ ì • ì°¨ì› (2048D) ì‚¬ìš©")
```

### Phase C ë¦¬ìŠ¤í¬: Citation ê³„ì‚° ì‹œê°„ ì¦ê°€

**ë¬¸ì œ**: Multi-Source Citationìœ¼ë¡œ ì¸í•œ ì‘ë‹µ ì‹œê°„ ì¦ê°€ (+3ì´ˆ)

**ëŒ€ì‘ì±…**:
1. **ìºì‹±**: ë¬¸ì¥ ì„ë² ë”© ìºì‹±
2. **ë³‘ë ¬ ì²˜ë¦¬**: ë¬¸ì¥ë³„ Citation ë³‘ë ¬ ê³„ì‚°
3. **ì¡°ê¸° ì¢…ë£Œ**: ì„ê³„ê°’ ì´ìƒ 2ê°œë§Œ ì°¾ê³  ì¢…ë£Œ

---

## ğŸ“… ì¢…í•© ì¼ì • (ì˜ˆìƒ)

### ì˜µì…˜ 1: ìˆœì°¨ ì§„í–‰ (ì•ˆì •ì )

```
Week 1:
â”œâ”€ Phase A-3 (3ì¼)
â””â”€ Phase B-1 ì¤€ë¹„ (Qwen3 ë‹¤ìš´ë¡œë“œ, ë°±ì—…)

Week 2:
â”œâ”€ Phase B-1 êµ¬í˜„ (4ì¼)
â””â”€ Phase B-1 í…ŒìŠ¤íŠ¸ (1ì¼)

Week 3:
â”œâ”€ Phase B-2 êµ¬í˜„ (3ì¼)
â””â”€ Phase B-3 êµ¬í˜„ (2ì¼)

Week 4:
â”œâ”€ Phase C êµ¬í˜„ (3ì¼)
â””â”€ ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸ (2ì¼)

ì´ ì†Œìš” ì‹œê°„: 4ì£¼
```

### ì˜µì…˜ 2: ë³‘ë ¬ ì§„í–‰ (ë¹ ë¥¸ ì™„ë£Œ)

```
Week 1:
â”œâ”€ Phase A-3 (3ì¼) + Qwen3 ë‹¤ìš´ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œ)
â””â”€ Phase C êµ¬í˜„ ì‹œì‘ (2ì¼, A-3ì™€ ë…ë¦½)

Week 2:
â”œâ”€ Phase B-1 êµ¬í˜„ (4ì¼)
â””â”€ Phase C ì™„ë£Œ (1ì¼)

Week 3:
â”œâ”€ Phase B-2 + B-3 êµ¬í˜„ (5ì¼)
â””â”€ í†µí•© í…ŒìŠ¤íŠ¸ (2ì¼)

ì´ ì†Œìš” ì‹œê°„: 3ì£¼
```

### ì˜µì…˜ 3: Citation ìš°ì„  (ì‚¬ìš©ì ì²´ê° ê°œì„ )

```
Week 1:
â”œâ”€ Phase A-3 (3ì¼)
â””â”€ Phase C êµ¬í˜„ (3ì¼)

Week 2:
â”œâ”€ Phase C í…ŒìŠ¤íŠ¸ ë° ìµœì í™” (2ì¼)
â””â”€ Phase B-1 ì¤€ë¹„ ë° êµ¬í˜„ (5ì¼)

Week 3:
â”œâ”€ Phase B-2 + B-3 (5ì¼)
â””â”€ ìµœì¢… í…ŒìŠ¤íŠ¸ (2ì¼)

ì´ ì†Œìš” ì‹œê°„: 3ì£¼
íŠ¹ì§•: Citation Rate 95% ì¡°ê¸° ë‹¬ì„±
```

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ì¦‰ì‹œ ì°©ìˆ˜ ê¶Œì¥: Phase A-3
- **ê¸°ê°„**: 2-3ì¼
- **íš¨ê³¼**: ì¬ìƒì„± 50% ê°ì†Œ, ì‘ë‹µ 10-15ì´ˆ ë‹¨ì¶•
- **ë¦¬ìŠ¤í¬**: ë‚®ìŒ
- **ì˜ì¡´ì„±**: ì—†ìŒ

### ìµœëŒ€ ì„±ëŠ¥ í–¥ìƒ: Phase B-1 (Qwen3)
- **ê¸°ê°„**: 2ì¼ + 4-6ì‹œê°„ (ì¬ì„ë² ë”©)
- **íš¨ê³¼**: ì •í™•ë„ +10-15%, MTEB +26%
- **ë¦¬ìŠ¤í¬**: ì¤‘ê°„ (VRAM 16GB í•„ìš”)
- **ì˜ì¡´ì„±**: Ollama Qwen3 ëª¨ë¸

### ì‚¬ìš©ì ì‹ ë¢°ë„ í–¥ìƒ: Phase C (Citation)
- **ê¸°ê°„**: 3ì¼
- **íš¨ê³¼**: Citation Rate 80% â†’ 95%
- **ë¦¬ìŠ¤í¬**: ë‚®ìŒ
- **ì˜ì¡´ì„±**: Phase A-2 (ì™„ë£Œ)

### ì´ ì˜ˆìƒ íš¨ê³¼ (v4.0)
- âœ… **ì •í™•ë„**: +28-46%
- âœ… **ì‘ë‹µ ì‹œê°„**: -22-29ì´ˆ (-24-32%)
- âœ… **Citation Rate**: 57.8% â†’ 95%
- âœ… **MTEB ì ìˆ˜**: ~56 â†’ ~70.58
- âœ… **NotebookLM ìˆ˜ì¤€ ë‹¬ì„±**

---

**ë‹¤ìŒ ë‹¨ê³„**: Phase A-3 êµ¬í˜„ ì°©ìˆ˜ ê¶Œì¥

ì‹¤í–‰ ëª…ë ¹:
```bash
# Phase A-3 êµ¬í˜„ ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/phase-a3-answer-verification

# êµ¬í˜„ íŒŒì¼ ì—´ê¸°
code utils/rag_chain.py
```
