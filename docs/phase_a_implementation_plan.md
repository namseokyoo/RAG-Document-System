# Phase A êµ¬í˜„ ê³„íšì„œ (ì¦‰ì‹œ ì ìš©)

**ì‘ì„±ì¼**: 2025-11-06
**ëª©í‘œ**: NotebookLM ìˆ˜ì¤€ì˜ Source Citation ë° ê²€ì¦ ê°•í™”
**ì˜ˆìƒ ì™„ë£Œ**: 1-2ì£¼
**ìš°ì„ ìˆœìœ„**: ìµœê³ 

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [A-1: Standard ëª¨ë“œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§](#a-1-standard-ëª¨ë“œ-ì¹´í…Œê³ ë¦¬-í•„í„°ë§)
3. [A-2: Source Citation ê°•í™”](#a-2-source-citation-ê°•í™”)
4. [A-3: Answer Verification ê°œì„ ](#a-3-answer-verification-ê°œì„ )
5. [í…ŒìŠ¤íŠ¸ ê³„íš](#í…ŒìŠ¤íŠ¸-ê³„íš)
6. [ì˜ˆìƒ ì„±ê³¼](#ì˜ˆìƒ-ì„±ê³¼)

---

## ê°œìš”

### ëª©í‘œ

Phase AëŠ” **ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ í•µì‹¬ ê°œì„ ì‚¬í•­**ìœ¼ë¡œ, NotebookLMì˜ ê°•ì ì„ í¡ìˆ˜í•˜ë©´ì„œ í˜„ì¬ ì‹œìŠ¤í…œì˜ ì•½ì ì„ ë³´ì™„í•©ë‹ˆë‹¤.

### í•µì‹¬ ê°œì„  ì‚¬í•­

1. **A-1**: Standard ëª¨ë“œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§ (30ë¶„)
   - í¬ë¡œìŠ¤ ë„ë©”ì¸ ì˜¤ì—¼ ì™„ì „ ì œê±° (4.5% â†’ 0%)

2. **A-2**: Source Citation ê°•í™” (3ì¼)
   - NotebookLM ìˆ˜ì¤€ ì¶œì²˜ í‘œì‹œ (95% ì •í™•ë„)

3. **A-3**: Answer Verification ê°œì„  (2ì¼)
   - ì¬ìƒì„± ë¹ˆë„ 50% ê°ì†Œ, ì‘ë‹µ ì‹œê°„ 10-15ì´ˆ ë‹¨ì¶•

### ì˜ˆìƒ ì„±ê³¼

| ì§€í‘œ | Before (v3.1) | After (Phase A) | ê°œì„  |
|------|--------------|----------------|------|
| **í¬ë¡œìŠ¤ ë„ë©”ì¸ ì˜¤ì—¼** | 4.5% | 0% | -100% |
| **ì¶œì²˜ ì •í™•ë„** | ~60% | 95% | +58% |
| **ì¬ìƒì„± ë¹ˆë„** | ~20% | ~10% | -50% |
| **ì‚¬ìš©ì ì‹ ë¢°ë„** | - | - | +30% |
| **ì‘ë‹µ ì‹œê°„** | í‰ê·  92ì´ˆ | í‰ê·  77-82ì´ˆ | -10-15ì´ˆ |

**ì´ ì •í™•ë„ í–¥ìƒ**: +15-25%

---

## A-1: Standard ëª¨ë“œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§

### ë¬¸ì œ ì •ì˜

**í˜„ì¬ ìƒí™©**:
```python
# Small-to-Large ëª¨ë“œ: ì¹´í…Œê³ ë¦¬ í•„í„°ë§ âœ“ ì ìš©ë¨
# Standard ëª¨ë“œ (Hybrid Search): ì¹´í…Œê³ ë¦¬ í•„í„°ë§ âœ— ë¯¸ì ìš©

ê²°ê³¼:
Query: "FRET ì—ë„ˆì§€ ì „ë‹¬ íš¨ìœ¨ì€?"
ì¶œì²˜: technical (4/5), hr (1/5) â† HRD-Net ë¬¸ì„œ í˜¼ì… (ì˜¤ì—¼)
```

**ì˜í–¥**:
- í¬ë¡œìŠ¤ ë„ë©”ì¸ ì˜¤ì—¼ 4.5% (1/22 ì¶œì²˜)
- ê²€ìƒ‰ í’ˆì§ˆ ì €í•˜
- ì‚¬ìš©ì í˜¼ë€

### êµ¬í˜„ ê³„íš

#### 1. íŒŒì¼ ìœ„ì¹˜
- **ìˆ˜ì • íŒŒì¼**: `utils/rag_chain.py`
- **ìˆ˜ì • ë©”ì„œë“œ**: `_get_context_standard()`
- **ë¼ì¸ ìœ„ì¹˜**: ì•½ 450-550 ë¼ì¸

#### 2. êµ¬í˜„ ë‚´ìš©

**Before**:
```python
def _get_context_standard(self, question: str, initial_k: int = 60):
    """Standard ê²€ìƒ‰ ëª¨ë“œ (Hybrid Search)"""

    # Phase 4: Hybrid Search ì‚¬ìš©
    if self.enable_hybrid_search and self.hybrid_retriever:
        print(f"  ğŸ” [Phase 4] Hybrid Search (BM25+Vector) ì‚¬ìš© (top_k={initial_k})")
        hybrid_results = self.hybrid_retriever.search(question, top_k=initial_k)
        candidates = [(doc, score) for doc, score in hybrid_results]
    else:
        # Fallback: Vector Search only
        results = self.retriever.get_relevant_documents(question)
        candidates = [(doc, 1.0) for doc in results[:initial_k]]

    # Re-ranking
    if self.use_reranker and self.reranker and len(candidates) > 0:
        docs_only = [doc for doc, score in candidates]
        reranked_docs = self.reranker.compress_documents(
            documents=docs_only,
            query=question
        )
        candidates = [(doc, 1.0) for doc in reranked_docs[:self.top_k]]

    return candidates  # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì—†ìŒ!
```

**After**:
```python
def _get_context_standard(self, question: str, initial_k: int = 60):
    """Standard ê²€ìƒ‰ ëª¨ë“œ (Hybrid Search)"""

    # 1. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ê°ì§€
    detected_categories = self._detect_question_category(question)

    # Phase 4: Hybrid Search ì‚¬ìš©
    if self.enable_hybrid_search and self.hybrid_retriever:
        print(f"  ğŸ” [Phase 4] Hybrid Search (BM25+Vector) ì‚¬ìš© (top_k={initial_k})")
        hybrid_results = self.hybrid_retriever.search(question, top_k=initial_k)
        candidates = [(doc, score) for doc, score in hybrid_results]
    else:
        # Fallback: Vector Search only
        results = self.retriever.get_relevant_documents(question)
        candidates = [(doc, 1.0) for doc in results[:initial_k]]

    # 2. ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì ìš© (NEW!)
    if detected_categories:
        print(f"  ğŸ” ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì ìš©: {', '.join(detected_categories)}")
        original_count = len(candidates)
        candidates = self._filter_by_category(candidates, detected_categories)
        print(f"  âœ“ í•„í„°ë§ ì™„ë£Œ: {original_count}ê°œ â†’ {len(candidates)}ê°œ ë¬¸ì„œ")

    # 3. Re-ranking
    if self.use_reranker and self.reranker and len(candidates) > 0:
        docs_only = [doc for doc, score in candidates]
        reranked_docs = self.reranker.compress_documents(
            documents=docs_only,
            query=question
        )
        candidates = [(doc, 1.0) for doc in reranked_docs[:self.top_k]]

    return candidates
```

#### 3. êµ¬í˜„ ë‹¨ê³„

**Step 1**: ì½”ë“œ ìˆ˜ì • (10ë¶„)
- `_get_context_standard()` ë©”ì„œë“œì— ì¹´í…Œê³ ë¦¬ ê°ì§€ ë° í•„í„°ë§ ì¶”ê°€
- ê¸°ì¡´ `_detect_question_category()` ë° `_filter_by_category()` ë©”ì„œë“œ ì¬ì‚¬ìš©

**Step 2**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (10ë¶„)
```python
# test_phase_a1.py
def test_standard_mode_category_filtering():
    """Standard ëª¨ë“œì—ì„œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§ í™•ì¸"""

    # OLED ê¸°ìˆ  ì§ˆë¬¸
    question = "FRET ì—ë„ˆì§€ ì „ë‹¬ íš¨ìœ¨ì€?"

    # Standard ëª¨ë“œë¡œ ê²€ìƒ‰
    result = rag_chain.generate_answer(question)

    # ì¶œì²˜ ì¹´í…Œê³ ë¦¬ í™•ì¸
    sources = result['sources']
    categories = [s.metadata.get('category') for s in sources]

    # HR ë¬¸ì„œê°€ ì—†ì–´ì•¼ í•¨
    assert 'hr' not in categories, f"HR ë¬¸ì„œ í˜¼ì… ê°ì§€: {categories}"

    # technical ë˜ëŠ” businessë§Œ ìˆì–´ì•¼ í•¨
    valid_categories = ['technical', 'business']
    assert all(c in valid_categories for c in categories), \
        f"ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ í¬í•¨: {categories}"
```

**Step 3**: í†µí•© í…ŒìŠ¤íŠ¸ (10ë¶„)
- ì‹¤ì œ ë¬¸ì„œ ì„¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
- OLED ê¸°ìˆ  ì§ˆë¬¸ 5ê°œ â†’ HR ë¬¸ì„œ í˜¼ì… 0% í™•ì¸
- HR ì§ˆë¬¸ 3ê°œ â†’ OLED ë¬¸ì„œ í˜¼ì… 0% í™•ì¸

#### 4. ê²€ì¦ ê¸°ì¤€

**ì„±ê³µ ì¡°ê±´**:
- âœ… í¬ë¡œìŠ¤ ë„ë©”ì¸ ì˜¤ì—¼ 0% (0/N ì¶œì²˜)
- âœ… ì •ìƒ ê²€ìƒ‰ ìœ ì§€ (ê²€ìƒ‰ ì‹¤íŒ¨ ì—†ìŒ)
- âœ… ì‘ë‹µ ì‹œê°„ ë³€í™” ì—†ìŒ (Â±5% ì´ë‚´)

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
1. OLED ê¸°ìˆ  ì§ˆë¬¸ 10ê°œ â†’ HR ë¬¸ì„œ í˜¼ì… 0ê°œ
2. HR ì‹œìŠ¤í…œ ì§ˆë¬¸ 5ê°œ â†’ OLED ë¬¸ì„œ í˜¼ì… 0ê°œ
3. ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸ 5ê°œ â†’ ì˜¬ë°”ë¥¸ ì¹´í…Œê³ ë¦¬ë§Œ

#### 5. ì˜ˆìƒ ì†Œìš” ì‹œê°„

- ì½”ë“œ ìˆ˜ì •: 10ë¶„
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: 10ë¶„
- í†µí•© í…ŒìŠ¤íŠ¸: 10ë¶„
- **ì´ ì†Œìš” ì‹œê°„**: **30ë¶„**

---

## A-2: Source Citation ê°•í™”

### ë¬¸ì œ ì •ì˜

**í˜„ì¬ ìƒí™©**:
```
## ì°¸ì¡° ì •ë³´
- [kFRET ê°’]: ë¬¸ì„œ #4, í˜ì´ì§€ 4 / ì„¹ì…˜ "ë³¸ë¬¸"

ë¬¸ì œì :
1. ì¶œì²˜ í‘œì‹œ ì¼ê´€ì„± ë¶€ì¡± (ë•Œë•Œë¡œ ëˆ„ë½)
2. í˜ì´ì§€/ì„¹ì…˜ ì •ë³´ ë¶€ì •í™•
3. ì¶œì²˜ ì‹ ë¢°ë„ ì ìˆ˜ ë¯¸í‘œì‹œ
4. ë¬¸ì¥ ë‹¨ìœ„ ì¶œì²˜ ë§¤í•‘ ì—†ìŒ
```

**ëª©í‘œ (NotebookLM ìŠ¤íƒ€ì¼)**:
```
ì œê³µëœ ë¬¸ì„œì— ë”°ë¥´ë©´, kFRET ê°’ì€ 87.8%ì…ë‹ˆë‹¤ [HF_OLED_Nature_Photonics_2024.pptx, slide 5, ì‹ ë¢°ë„: 826.2].

ë˜í•œ ACRSA ì¬ë£Œë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤ [HF_OLED_Nature_Photonics_2024.pptx, slide 3, ì‹ ë¢°ë„: 792.8].
```

### êµ¬í˜„ ê³„íš

#### 1. íŒŒì¼ ìœ„ì¹˜
- **ìˆ˜ì • íŒŒì¼**: `utils/rag_chain.py`
- **ìƒˆ ë©”ì„œë“œë“¤**:
  - `_generate_source_citations()`
  - `_find_best_source_for_sentence()`
  - `_format_citation()`
  - `_split_sentences()`
  - `_embed_text()`
  - `_cosine_similarity()`

#### 2. êµ¬í˜„ ë‚´ìš©

**í•µì‹¬ ë¡œì§**:
```python
def _generate_source_citations(self, answer: str, sources: List[Document]) -> str:
    """NotebookLM ìŠ¤íƒ€ì¼ ì¶œì²˜ ì¸ë¼ì¸ í‘œì‹œ

    Args:
        answer: ìƒì„±ëœ ë‹µë³€
        sources: ì‚¬ìš©ëœ ì¶œì²˜ ë¬¸ì„œë“¤

    Returns:
        ì¶œì²˜ê°€ ì¸ë¼ì¸ìœ¼ë¡œ í‘œì‹œëœ ë‹µë³€
    """

    # 1. ë‹µë³€ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    sentences = self._split_sentences(answer)

    cited_sentences = []
    for sentence in sentences:
        # 2. ë¬¸ì¥ê³¼ ê°€ì¥ ê´€ë ¨ëœ ì¶œì²˜ ì°¾ê¸°
        best_source = self._find_best_source_for_sentence(sentence, sources)

        if best_source:
            # 3. ì¸ë¼ì¸ ì¶œì²˜ ìƒì„±
            citation = self._format_citation(best_source)
            cited_sentence = f"{sentence.strip()} {citation}"
        else:
            cited_sentence = sentence.strip()

        cited_sentences.append(cited_sentence)

    return " ".join(cited_sentences)
```

**ë¬¸ì¥ ë¶„ë¦¬**:
```python
def _split_sentences(self, text: str) -> List[str]:
    """ë‹µë³€ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬

    í•œê¸€/ì˜ë¬¸ ë¬¸ì¥ êµ¬ë¶„ ê³ ë ¤:
    - ë§ˆì¹¨í‘œ(.), ë¬¼ìŒí‘œ(?), ëŠë‚Œí‘œ(!)
    - ë‹¨, "Dr.", "Mr.", "etc." ë“±ì€ ì œì™¸
    """

    # ê°„ë‹¨í•œ ì •ê·œì‹ ê¸°ë°˜ ë¶„ë¦¬
    # í–¥í›„ KSS(Korean Sentence Splitter) ë˜ëŠ” NLTK ì‚¬ìš© ê³ ë ¤

    # 1. íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ë³´í˜¸ (Dr., Mr. ë“±)
    text = re.sub(r'(Dr|Mr|Ms|Mrs|etc)\.', r'\1<DOT>', text)

    # 2. ë¬¸ì¥ ë¶„ë¦¬ (., ?, !)
    sentences = re.split(r'([.!?])\s+', text)

    # 3. ì¬ì¡°í•©
    result = []
    for i in range(0, len(sentences)-1, 2):
        sentence = sentences[i] + (sentences[i+1] if i+1 < len(sentences) else '')
        result.append(sentence)

    # ë§ˆì§€ë§‰ ë¬¸ì¥ ì¶”ê°€
    if len(sentences) % 2 == 1:
        result.append(sentences[-1])

    # 4. <DOT> ë³µì›
    result = [s.replace('<DOT>', '.') for s in result]

    return [s.strip() for s in result if s.strip()]
```

**ì¶œì²˜ ì°¾ê¸° (Semantic Similarity)**:
```python
def _find_best_source_for_sentence(self, sentence: str, sources: List[Document]) -> Optional[Document]:
    """ë¬¸ì¥ê³¼ ê°€ì¥ ê´€ë ¨ëœ ì¶œì²˜ ì°¾ê¸°

    ë°©ë²•:
    1. ë¬¸ì¥ê³¼ ê° ì¶œì²˜ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    2. ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ì¶œì²˜ ì„ íƒ
    3. ìœ ì‚¬ë„ê°€ ì„ê³„ê°’(0.5) ì´í•˜ë©´ None ë°˜í™˜
    """

    if not sources:
        return None

    # 1. ë¬¸ì¥ ì„ë² ë”©
    sentence_embedding = self._embed_text(sentence)

    # 2. ê° ì¶œì²˜ì™€ ìœ ì‚¬ë„ ê³„ì‚°
    best_source = None
    best_similarity = 0.0

    for source in sources:
        # ì¶œì²˜ í…ìŠ¤íŠ¸ ì„ë² ë”©
        source_text = source.page_content[:500]  # ì²˜ìŒ 500ìë§Œ (ì„±ëŠ¥ ìµœì í™”)
        source_embedding = self._embed_text(source_text)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        similarity = self._cosine_similarity(sentence_embedding, source_embedding)

        if similarity > best_similarity and similarity > 0.5:  # ì„ê³„ê°’
            best_similarity = similarity
            best_source = source

    return best_source
```

**ì„ë² ë”© ë° ìœ ì‚¬ë„**:
```python
def _embed_text(self, text: str) -> np.ndarray:
    """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜

    ê¸°ì¡´ vectorstoreì˜ ì„ë² ë”© ëª¨ë¸ ì¬ì‚¬ìš©
    """

    # VectorStoreManagerì˜ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
    embedding_model = self.vectorstore.embeddings

    try:
        # í…ìŠ¤íŠ¸ ì„ë² ë”©
        embedding = embedding_model.embed_query(text)
        return np.array(embedding)
    except Exception as e:
        print(f"    âš ï¸ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return np.zeros(1024)  # ê¸°ë³¸ ì°¨ì› (mxbai-embed-large)

def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""

    # ì˜ë²¡í„° ì²´í¬
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)

    if norm1 == 0 or norm2 == 0:
        return 0.0

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    similarity = np.dot(vec1, vec2) / (norm1 * norm2)

    return float(similarity)
```

**ì¶œì²˜ í¬ë§·íŒ…**:
```python
def _format_citation(self, source: Document) -> str:
    """ì¶œì²˜ë¥¼ NotebookLM ìŠ¤íƒ€ì¼ë¡œ í¬ë§·

    í˜•ì‹: [íŒŒì¼ëª…, p.í˜ì´ì§€, ì‹ ë¢°ë„: ì ìˆ˜]
    """

    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    file_name = source.metadata.get('file_name', 'Unknown')
    page = source.metadata.get('page', '?')
    score = source.metadata.get('score', 0.0)

    # ì§§ì€ íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œê±°)
    short_name = file_name.rsplit('.', 1)[0]

    # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (30ì ì œí•œ)
    if len(short_name) > 30:
        short_name = short_name[:27] + "..."

    # ì¶œì²˜ í¬ë§·
    citation = f"[{short_name}, p.{page}, ì‹ ë¢°ë„: {score:.1f}]"

    return citation
```

#### 3. êµ¬í˜„ ë‹¨ê³„

**Day 1: í•µì‹¬ ë¡œì§ êµ¬í˜„** (4-5ì‹œê°„)
- âœ… `_split_sentences()` êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸
- âœ… `_embed_text()` êµ¬í˜„ (ê¸°ì¡´ ëª¨ë¸ í™œìš©)
- âœ… `_cosine_similarity()` êµ¬í˜„
- âœ… `_find_best_source_for_sentence()` êµ¬í˜„
- âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

**Day 2: ì¶œì²˜ ìƒì„± ë° í¬ë§·íŒ…** (4-5ì‹œê°„)
- âœ… `_format_citation()` êµ¬í˜„
- âœ… `_generate_source_citations()` êµ¬í˜„
- âœ… ê¸°ì¡´ `generate_answer()` ë©”ì„œë“œì— í†µí•©
- âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

**Day 3: í†µí•© í…ŒìŠ¤íŠ¸ ë° ìµœì í™”** (4-5ì‹œê°„)
- âœ… ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸
- âœ… ì¶œì²˜ ì •í™•ë„ ì¸¡ì • (ëª©í‘œ: 95%)
- âœ… ì„±ëŠ¥ ìµœì í™” (ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬)
- âœ… ë¬¸ì„œí™”

#### 4. ê²€ì¦ ê¸°ì¤€

**ì •ëŸ‰ì  ì§€í‘œ**:
- âœ… ì¶œì²˜ ì •í™•ë„: 95% ì´ìƒ
  - 100ê°œ ë¬¸ì¥ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
  - ì‚¬ëŒì´ ìˆ˜ë™ìœ¼ë¡œ ì¶œì²˜ ê²€ì¦
  - ì¼ì¹˜ìœ¨ ê³„ì‚°

- âœ… ì¶œì²˜ ì»¤ë²„ë¦¬ì§€: 90% ì´ìƒ
  - ë‹µë³€ì˜ 90% ì´ìƒ ë¬¸ì¥ì— ì¶œì²˜ í‘œì‹œ
  - ë‚˜ë¨¸ì§€ 10%ëŠ” ì—°ê²°ì–´, ì¼ë°˜ ë¬¸ì¥ ë“±

- âœ… ì„±ëŠ¥ ì˜í–¥: +20% ì´ë‚´
  - ì¶œì²˜ ìƒì„±ìœ¼ë¡œ ì¸í•œ ì¶”ê°€ ì‹œê°„
  - ì„ë² ë”© ìºì‹±ìœ¼ë¡œ ìµœì†Œí™”

**ì •ì„±ì  ì§€í‘œ**:
- âœ… ì‚¬ìš©ì ë§Œì¡±ë„: ì„¤ë¬¸ì¡°ì‚¬ (Phase A ì™„ë£Œ í›„)
- âœ… Hallucination ê°ì§€: ì¶œì²˜ ì—†ëŠ” ë¬¸ì¥ ì‰½ê²Œ ì‹ë³„

#### 5. ì˜ˆìƒ ì†Œìš” ì‹œê°„

- Day 1: 4-5ì‹œê°„
- Day 2: 4-5ì‹œê°„
- Day 3: 4-5ì‹œê°„
- **ì´ ì†Œìš” ì‹œê°„**: **3ì¼** (12-15ì‹œê°„)

---

## A-3: Answer Verification ê°œì„ 

### ë¬¸ì œ ì •ì˜

**í˜„ì¬ ìƒí™©**:
```
Query: "kFRET ê°’ì€?"
1ì°¨ ë‹µë³€ ìƒì„±: "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" (ê¸ˆì§€ êµ¬ë¬¸ ì‚¬ìš©)
â†’ ê²€ì¦ ì‹¤íŒ¨
â†’ 2ì°¨ ì¬ìƒì„± (10-15ì´ˆ ì¶”ê°€ ì†Œìš”)
â†’ ì„±ê³µ

ë¬¸ì œì :
1. ì¬ìƒì„± ë¹ˆë„ ~20% (5ê°œ ì¤‘ 1ê°œ)
2. ì¶”ê°€ LLM í˜¸ì¶œ ë¹„ìš©
3. ì‘ë‹µ ì‹œê°„ ì¦ê°€
```

**ëª©í‘œ**:
- ì¬ìƒì„± ë¹ˆë„ 50% ê°ì†Œ (20% â†’ 10%)
- ì‘ë‹µ ì‹œê°„ 10-15ì´ˆ ë‹¨ì¶•

### êµ¬í˜„ ê³„íš

#### 1. ê°œì„ ì•ˆ 1: Prompt Engineering ê°•í™”

**íŒŒì¼ ìœ„ì¹˜**: `utils/rag_chain.py`
**ìˆ˜ì • ëŒ€ìƒ**: `base_prompt_template`

**Before** (í˜„ì¬):
```python
âš ï¸ ì¤‘ìš” ê·œì¹™:
1. **ë¬¸ì„œ ìš°ì„  ì›ì¹™**: ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€í•˜ì„¸ìš”.
2. **ì¼ë°˜ ì§€ì‹ ê¸ˆì§€**: ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
3. **ì •ë³´ ì—†ìŒ ê¸ˆì§€**: ë¬¸ì„œê°€ ì œê³µëœ ê²½ìš° "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
4. **ë¬¸ì„œ ì¸ìš© ì˜ë¬´**: ë‹µë³€í•  ë•Œ ë°˜ë“œì‹œ ë¬¸ì„œì˜ êµ¬ì²´ì  ë‚´ìš©ì„ ì¸ìš©í•˜ì„¸ìš”.
```

**After** (ê°œì„ ):
```python
âš ï¸ í•µì‹¬ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜):

1. **ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€**: ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.

2. **ê¸ˆì§€ í‘œí˜„** (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€):
   âŒ "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
   âŒ "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"
   âŒ "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
   âŒ "ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

3. **ê¶Œì¥ í‘œí˜„** (ëŒ€ì‹  ì‚¬ìš©):
   âœ… "ì œê³µëœ ë¬¸ì„œì— ë”°ë¥´ë©´, [êµ¬ì²´ì  ì •ë³´]..."
   âœ… "ë¬¸ì„œ #1ì˜ 5í˜ì´ì§€ì—ì„œ [ë‚´ìš©]ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   âœ… "ì§ì ‘ì ì¸ ìˆ˜ì¹˜ëŠ” ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì§€ë§Œ, ê´€ë ¨ ì •ë³´ë¡œëŠ” [ë‚´ìš©]ì´ ìˆìŠµë‹ˆë‹¤"
   âœ… "[ë¬¸ì„œ]ì—ì„œ [ë‚´ìš©]ì„ ì–¸ê¸‰í•˜ê³  ìˆìŠµë‹ˆë‹¤"

4. **NotebookLM ìŠ¤íƒ€ì¼ ë‹µë³€ ì˜ˆì‹œ**:
   "According to the provided document (HF_OLED.pptx, slide 5), the kFRET value is approximately 87.8%."
   â†’ "ì œê³µëœ ë¬¸ì„œ(HF_OLED.pptx, ìŠ¬ë¼ì´ë“œ 5)ì— ë”°ë¥´ë©´, kFRET ê°’ì€ ì•½ 87.8%ì…ë‹ˆë‹¤."

5. **ì¶œì²˜ ëª…ì‹œ ì˜ë¬´**:
   - ëª¨ë“  ì‚¬ì‹¤ì— ì¶œì²˜ í‘œì‹œ: [íŒŒì¼ëª…, í˜ì´ì§€, ì‹ ë¢°ë„]
   - ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ ì§€ì‹ ì ˆëŒ€ ê¸ˆì§€
```

**êµ¬í˜„ ì‹œê°„**: 30ë¶„

#### 2. ê°œì„ ì•ˆ 2: Self-Consistency Check

**íŒŒì¼ ìœ„ì¹˜**: `utils/rag_chain.py`
**ìƒˆ ë©”ì„œë“œ**: `_generate_with_self_consistency()`

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•´ NíšŒ(ê¸°ë³¸ 3íšŒ) ë…ë¦½ì ìœ¼ë¡œ ë‹µë³€ ìƒì„±
- ë‹µë³€ë“¤ ê°„ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
- ì¼ê´€ì„± ë†’ìœ¼ë©´ â†’ ì‹ ë¢°ë„ ë†’ìŒ, ê°€ì¥ ìƒì„¸í•œ ë‹µë³€ ì„ íƒ
- ì¼ê´€ì„± ë‚®ìœ¼ë©´ â†’ ì‹ ë¢°ë„ ë‚®ìŒ, ê²½ê³  í‘œì‹œ

**êµ¬í˜„ ì½”ë“œ**:
```python
def _generate_with_self_consistency(self, question: str, context: str, n: int = 3) -> Dict[str, Any]:
    """ì—¬ëŸ¬ ë²ˆ ìƒì„± í›„ ì¼ê´€ì„± ê²€ì¦

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        context: ê²€ìƒ‰ëœ ë¬¸ë§¥
        n: ìƒì„± íšŸìˆ˜ (ê¸°ë³¸ 3íšŒ)

    Returns:
        {
            'answer': ìµœì¢… ë‹µë³€,
            'consistency': ì¼ê´€ì„± ì ìˆ˜ (0-1),
            'variants': ìƒì„±ëœ ë‹µë³€ë“¤
        }
    """

    print(f"  ğŸ”„ Self-consistency check: {n}íšŒ ìƒì„± ì¤‘...")

    # 1. Në²ˆ ë…ë¦½ì ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    original_temp = self.temperature
    self.temperature = 0.5  # ì•½ê°„ ë‹¤ì–‘ì„± ì¶”ê°€

    answers = []
    for i in range(n):
        answer = self._generate_answer_internal(question, context)
        answers.append(answer)
        print(f"    âœ“ {i+1}ë²ˆì§¸ ìƒì„± ì™„ë£Œ ({len(answer)} chars)")

    self.temperature = original_temp

    # 2. ë‹µë³€ ê°„ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
    consistency_score = self._calculate_answer_consistency(answers)
    print(f"  ğŸ“Š ì¼ê´€ì„± ì ìˆ˜: {consistency_score:.2%}")

    # 3. ì¼ê´€ì„±ì— ë”°ë¼ ì²˜ë¦¬
    if consistency_score > 0.8:
        # ë†’ì€ ì¼ê´€ì„±: ê°€ì¥ ìƒì„¸í•œ ë‹µë³€ ì„ íƒ
        best_answer = max(answers, key=lambda a: len(a))
        print(f"  âœ… ë†’ì€ ì¼ê´€ì„±: ìµœìƒ ë‹µë³€ ì„ íƒ")

    elif consistency_score > 0.5:
        # ì¤‘ê°„ ì¼ê´€ì„±: ê³µí†µ ì •ë³´ ì¶”ì¶œ
        best_answer = self._extract_common_info(answers)
        best_answer = f"âš ï¸ ì¤‘ê°„ ì‹ ë¢°ë„ (ì¼ê´€ì„±: {consistency_score:.1%})\n\n{best_answer}"
        print(f"  âš ï¸ ì¤‘ê°„ ì¼ê´€ì„±: ê³µí†µ ì •ë³´ ì¶”ì¶œ")

    else:
        # ë‚®ì€ ì¼ê´€ì„±: ê²½ê³ ì™€ í•¨ê»˜ ì²« ë²ˆì§¸ ë‹µë³€
        best_answer = f"âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ (ì¼ê´€ì„±: {consistency_score:.1%})\nì œê³µëœ ë¬¸ì„œì—ì„œ ëª…í™•í•œ ë‹µë³€ì„ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n\n{answers[0]}"
        print(f"  âš ï¸ ë‚®ì€ ì¼ê´€ì„±: ê²½ê³  í‘œì‹œ")

    return {
        'answer': best_answer,
        'consistency': consistency_score,
        'variants': answers
    }

def _calculate_answer_consistency(self, answers: List[str]) -> float:
    """ë‹µë³€ë“¤ ê°„ì˜ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚° (Jaccard ìœ ì‚¬ë„)"""

    from itertools import combinations

    if len(answers) < 2:
        return 1.0

    # ëª¨ë“  ìŒì˜ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    for ans1, ans2 in combinations(answers, 2):
        # ë‹¨ì–´ ê¸°ë°˜ Jaccard ìœ ì‚¬ë„
        words1 = set(ans1.lower().split())
        words2 = set(ans2.lower().split())

        if len(words1) == 0 and len(words2) == 0:
            similarity = 1.0
        elif len(words1) == 0 or len(words2) == 0:
            similarity = 0.0
        else:
            intersection = words1 & words2
            union = words1 | words2
            similarity = len(intersection) / len(union)

        similarities.append(similarity)

    return sum(similarities) / len(similarities)

def _extract_common_info(self, answers: List[str]) -> str:
    """ì—¬ëŸ¬ ë‹µë³€ì—ì„œ ê³µí†µ ì •ë³´ ì¶”ì¶œ (ë¹ˆë„ ê¸°ë°˜)"""

    # ê° ë‹µë³€ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    all_sentences = []
    for answer in answers:
        sentences = [s.strip() for s in answer.split('.') if s.strip()]
        all_sentences.extend(sentences)

    # ê°€ì¥ ë¹ˆë²ˆí•œ ë¬¸ì¥ë“¤ ì„ íƒ
    from collections import Counter
    sentence_counts = Counter(all_sentences)

    # 2ê°œ ì´ìƒ ë‹µë³€ì— ë“±ì¥í•˜ê±°ë‚˜, 50% ì´ìƒ ë‹µë³€ì— ë“±ì¥
    common_sentences = [
        sentence for sentence, count in sentence_counts.items()
        if count >= 2 or count >= len(answers) * 0.5
    ]

    if common_sentences:
        return '. '.join(common_sentences[:5]) + '.'
    else:
        # ê³µí†µ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë‹µë³€ ë°˜í™˜
        return answers[0]
```

**ì‚¬ìš© ë°©ë²•**:
```python
# RAGChain __init__ì— ì„¤ì • ì¶”ê°€
self.enable_self_consistency = config.get('enable_self_consistency', False)
self.self_consistency_n = config.get('self_consistency_n', 3)

# generate_answer()ì—ì„œ ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©
if self.enable_self_consistency:
    result = self._generate_with_self_consistency(question, context, n=self.self_consistency_n)
    answer = result['answer']
    # ì¼ê´€ì„± ì ìˆ˜ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥
    self._last_consistency_score = result['consistency']
else:
    answer = self._generate_answer_internal(question, context)
```

**íŠ¸ë ˆì´ë“œì˜¤í”„**:
- âœ… ì¥ì : ì¬ìƒì„± ë¹ˆë„ 50% ê°ì†Œ, ì‹ ë¢°ë„ í–¥ìƒ
- âŒ ë‹¨ì : ì‘ë‹µ ì‹œê°„ Në°° ì¦ê°€ (3íšŒ ìƒì„± ì‹œ 3ë°°)
- ğŸ’¡ í•´ê²°: **ì„ íƒì  ì ìš©** (ëª¨í˜¸í•œ ì§ˆë¬¸ì—ë§Œ)

**ì„ íƒì  ì ìš© ë¡œì§**:
```python
def _should_use_self_consistency(self, question: str, context: str) -> bool:
    """Self-consistencyê°€ í•„ìš”í•œì§€ íŒë‹¨"""

    # 1. ì§ˆë¬¸ ë³µì¡ë„ê°€ ë†’ìœ¼ë©´
    complexity = self._analyze_question_complexity(question)
    if complexity > 0.7:
        return True

    # 2. ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ (ì• ë§¤í•œ ê²€ìƒ‰ ê²°ê³¼)
    if hasattr(self, '_last_retrieved_docs'):
        avg_score = np.mean([doc.metadata.get('score', 0) for doc in self._last_retrieved_docs])
        if avg_score < 500:  # ì„ê³„ê°’
            return True

    # 3. ì§ˆë¬¸ì— "ì •í™•íˆ", "í™•ì‹¤íˆ" ë“± í‚¤ì›Œë“œ í¬í•¨ ì‹œ
    precision_keywords = ["ì •í™•íˆ", "í™•ì‹¤íˆ", "ëª…í™•íˆ", "êµ¬ì²´ì ìœ¼ë¡œ"]
    if any(kw in question for kw in precision_keywords):
        return True

    return False
```

#### 3. êµ¬í˜„ ë‹¨ê³„

**Day 1: Prompt ê°œì„ ** (2ì‹œê°„)
- âœ… ìƒˆ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
- âœ… A/B í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ vs ê°œì„ )
- âœ… ì¬ìƒì„± ë¹ˆë„ ì¸¡ì •

**Day 2: Self-Consistency êµ¬í˜„** (6-7ì‹œê°„)
- âœ… `_generate_with_self_consistency()` êµ¬í˜„
- âœ… `_calculate_answer_consistency()` êµ¬í˜„
- âœ… `_extract_common_info()` êµ¬í˜„
- âœ… `_should_use_self_consistency()` êµ¬í˜„ (ì„ íƒì  ì ìš©)
- âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

**Day 3: í†µí•© ë° ìµœì í™”** (3-4ì‹œê°„)
- âœ… ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸
- âœ… ì„±ëŠ¥ ì¸¡ì • (ì‘ë‹µ ì‹œê°„, ì¬ìƒì„± ë¹ˆë„)
- âœ… ìµœì í™” (ë³‘ë ¬ ìƒì„± ê³ ë ¤)
- âœ… ë¬¸ì„œí™”

#### 4. ê²€ì¦ ê¸°ì¤€

**ì •ëŸ‰ì  ì§€í‘œ**:
- âœ… ì¬ìƒì„± ë¹ˆë„: 20% â†’ 10% (50% ê°ì†Œ)
- âœ… í‰ê·  ì‘ë‹µ ì‹œê°„: 92ì´ˆ â†’ 77-82ì´ˆ (10-15ì´ˆ ë‹¨ì¶•)
  - Prompt ê°œì„ : -5-8ì´ˆ
  - Self-consistency (ì„ íƒì  ì ìš©): -5-7ì´ˆ (ì¬ìƒì„± ê°ì†Œ)

**ì •ì„±ì  ì§€í‘œ**:
- âœ… ê¸ˆì§€ êµ¬ë¬¸ ì‚¬ìš© ë¹ˆë„: 80% ê°ì†Œ
- âœ… ë‹µë³€ í’ˆì§ˆ: ì‚¬ìš©ì ë§Œì¡±ë„ ì¡°ì‚¬

#### 5. ì˜ˆìƒ ì†Œìš” ì‹œê°„

- Day 1: 2ì‹œê°„
- Day 2: 6-7ì‹œê°„
- **ì´ ì†Œìš” ì‹œê°„**: **2ì¼** (11-12ì‹œê°„)

---

## í…ŒìŠ¤íŠ¸ ê³„íš

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

**íŒŒì¼**: `tests/test_phase_a.py`

```python
import pytest
from utils.rag_chain import RAGChain

class TestPhaseA:
    """Phase A ê°œì„ ì‚¬í•­ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def rag_chain(self):
        """RAGChain ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        # í…ŒìŠ¤íŠ¸ìš© ì„¤ì •
        config = {...}
        return RAGChain(vectorstore, **config)

    # A-1: Standard ëª¨ë“œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    def test_standard_mode_category_filtering(self, rag_chain):
        """Standard ëª¨ë“œì—ì„œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§ í™•ì¸"""
        question = "FRET ì—ë„ˆì§€ ì „ë‹¬ íš¨ìœ¨ì€?"
        result = rag_chain.generate_answer(question)

        # HR ë¬¸ì„œ í˜¼ì… ì—†ìŒ
        categories = [s.metadata.get('category') for s in result['sources']]
        assert 'hr' not in categories

    # A-2: Source Citation
    def test_source_citation_accuracy(self, rag_chain):
        """ì¶œì²˜ í‘œì‹œ ì •í™•ë„ í™•ì¸"""
        question = "kFRET ê°’ì€?"
        result = rag_chain.generate_answer(question)
        answer = result['answer']

        # ì¶œì²˜ í¬ë§· í™•ì¸
        assert '[' in answer and ']' in answer  # ì¸ë¼ì¸ ì¶œì²˜ ì¡´ì¬
        assert 'ì‹ ë¢°ë„:' in answer or 'confidence:' in answer.lower()

        # ì¶œì²˜ ê°œìˆ˜ í™•ì¸ (ìµœì†Œ 1ê°œ)
        citation_count = answer.count('[')
        assert citation_count >= 1

    def test_sentence_source_mapping(self, rag_chain):
        """ë¬¸ì¥-ì¶œì²˜ ë§¤í•‘ ì •í™•ë„ í™•ì¸"""
        # ìƒ˜í”Œ ë‹µë³€ê³¼ ì¶œì²˜
        answer = "TADFëŠ” ì—´ í™œì„±í™” ì§€ì—° í˜•ê´‘ì…ë‹ˆë‹¤. OLEDì— ì‚¬ìš©ë©ë‹ˆë‹¤."
        sources = [...]  # í…ŒìŠ¤íŠ¸ ì¶œì²˜

        # ì¶œì²˜ ìƒì„±
        cited_answer = rag_chain._generate_source_citations(answer, sources)

        # ê° ë¬¸ì¥ì— ì¶œì²˜ í‘œì‹œ í™•ì¸
        sentences = cited_answer.split('.')
        citation_count = sum(1 for s in sentences if '[' in s and ']' in s)
        assert citation_count >= 1

    # A-3: Answer Verification
    def test_prompt_improvement_no_forbidden_phrases(self, rag_chain):
        """ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¡œ ê¸ˆì§€ êµ¬ë¬¸ ê°ì†Œ í™•ì¸"""
        # ëª¨í˜¸í•œ ì§ˆë¬¸ 10ê°œë¡œ í…ŒìŠ¤íŠ¸
        questions = [
            "kFRET ê°’ì€?",
            "ì–‘ì íš¨ìœ¨ì€?",
            # ... 8ê°œ more
        ]

        forbidden_count = 0
        for q in questions:
            result = rag_chain.generate_answer(q)
            answer = result['answer']

            # ê¸ˆì§€ êµ¬ë¬¸ ì²´í¬
            forbidden_phrases = ["ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"]
            if any(phrase in answer for phrase in forbidden_phrases):
                forbidden_count += 1

        # ê¸ˆì§€ êµ¬ë¬¸ ì‚¬ìš© ë¹ˆë„ < 10% (10ê°œ ì¤‘ 1ê°œ ë¯¸ë§Œ)
        assert forbidden_count < 1

    def test_self_consistency(self, rag_chain):
        """Self-consistency ê¸°ëŠ¥ í™•ì¸"""
        question = "TADFì˜ ì–‘ì íš¨ìœ¨ì€?"
        context = "..."

        result = rag_chain._generate_with_self_consistency(question, context, n=3)

        # ê²°ê³¼ êµ¬ì¡° í™•ì¸
        assert 'answer' in result
        assert 'consistency' in result
        assert 'variants' in result

        # ì¼ê´€ì„± ì ìˆ˜ ë²”ìœ„ í™•ì¸ (0-1)
        assert 0 <= result['consistency'] <= 1

        # ë³€í˜• ê°œìˆ˜ í™•ì¸
        assert len(result['variants']) == 3
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸

**íŒŒì¼**: `tests/test_phase_a_integration.py`

```python
class TestPhaseAIntegration:
    """Phase A í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_full_pipeline_with_phase_a(self):
        """Phase A ì ìš©ëœ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

        # 1. ì§ˆë¬¸ ì¤€ë¹„
        test_queries = [
            # OLED ê¸°ìˆ  ì§ˆë¬¸ (technical)
            "TADF ì¬ë£Œì˜ ì–‘ì íš¨ìœ¨ì€?",
            "FRET ì—ë„ˆì§€ ì „ë‹¬ íš¨ìœ¨ì€?",
            "kFRET ê°’ì€?",

            # ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸ (business)
            "LGë””ìŠ¤í”Œë ˆì´ì˜ OLED ì‹œì¥ ë™í–¥ì€?",

            # HR ì§ˆë¬¸ (hr)
            "HRD-Net ì¶œê²° ê´€ë¦¬ ë°©ë²•ì€?",
        ]

        # 2. ê° ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
        for question in test_queries:
            result = rag_chain.generate_answer(question)

            # A-1: ì¹´í…Œê³ ë¦¬ í•„í„°ë§ í™•ì¸
            categories = [s.metadata.get('category') for s in result['sources']]
            assert len(set(categories)) <= 2  # ìµœëŒ€ 2ê°œ ì¹´í…Œê³ ë¦¬

            # A-2: ì¶œì²˜ í‘œì‹œ í™•ì¸
            assert '[' in result['answer']  # ì¸ë¼ì¸ ì¶œì²˜

            # A-3: ê¸ˆì§€ êµ¬ë¬¸ ì—†ìŒ
            forbidden_phrases = ["ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"]
            assert not any(phrase in result['answer'] for phrase in forbidden_phrases)

    def test_cross_domain_contamination_zero(self):
        """í¬ë¡œìŠ¤ ë„ë©”ì¸ ì˜¤ì—¼ 0% í™•ì¸"""

        # OLED ê¸°ìˆ  ì§ˆë¬¸ 20ê°œ
        oled_queries = [...]  # 20ê°œ ì§ˆë¬¸

        hr_contamination = 0
        total_sources = 0

        for q in oled_queries:
            result = rag_chain.generate_answer(q)
            sources = result['sources']

            for s in sources:
                total_sources += 1
                if s.metadata.get('category') == 'hr':
                    hr_contamination += 1

        # ì˜¤ì—¼ë¥  0%
        contamination_rate = hr_contamination / total_sources
        assert contamination_rate == 0.0
```

### 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

**íŒŒì¼**: `tests/test_phase_a_performance.py`

```python
import time

class TestPhaseAPerformance:
    """Phase A ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    def test_response_time_improvement(self):
        """ì‘ë‹µ ì‹œê°„ ê°œì„  í™•ì¸"""

        questions = [...]  # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 20ê°œ

        # Before Phase A (v3.1 baseline)
        baseline_times = []
        for q in questions:
            start = time.time()
            rag_chain_baseline.generate_answer(q)
            elapsed = time.time() - start
            baseline_times.append(elapsed)

        # After Phase A
        phase_a_times = []
        for q in questions:
            start = time.time()
            rag_chain_phase_a.generate_answer(q)
            elapsed = time.time() - start
            phase_a_times.append(elapsed)

        # í‰ê·  ì‘ë‹µ ì‹œê°„ ë¹„êµ
        avg_baseline = sum(baseline_times) / len(baseline_times)
        avg_phase_a = sum(phase_a_times) / len(phase_a_times)

        # 10-15ì´ˆ ë‹¨ì¶• í™•ì¸
        improvement = avg_baseline - avg_phase_a
        assert improvement >= 10, f"ì‘ë‹µ ì‹œê°„ ê°œì„ : {improvement:.1f}ì´ˆ (ëª©í‘œ: 10ì´ˆ ì´ìƒ)"

    def test_source_citation_overhead(self):
        """Source Citation ì˜¤ë²„í—¤ë“œ ì¸¡ì •"""

        # Without citation
        start = time.time()
        result_no_citation = rag_chain.generate_answer(question, enable_citation=False)
        time_no_citation = time.time() - start

        # With citation
        start = time.time()
        result_with_citation = rag_chain.generate_answer(question, enable_citation=True)
        time_with_citation = time.time() - start

        # ì˜¤ë²„í—¤ë“œ 20% ì´ë‚´
        overhead = (time_with_citation - time_no_citation) / time_no_citation
        assert overhead <= 0.2, f"Citation ì˜¤ë²„í—¤ë“œ: {overhead:.1%} (ëª©í‘œ: 20% ì´ë‚´)"
```

### 4. Baseline í…ŒìŠ¤íŠ¸

**ëª©ì **: Phase A ì ìš© ì „í›„ ë¹„êµë¥¼ ìœ„í•œ Baseline ì„±ëŠ¥ ì¸¡ì •

**íŒŒì¼**: `test_phase_a_baseline.py`

```python
"""
Phase A Baseline í…ŒìŠ¤íŠ¸
Phase A êµ¬í˜„ ì „ í˜„ì¬ ì„±ëŠ¥ ì¸¡ì •
"""
import json
import time
from datetime import datetime

def run_baseline_test():
    """Baseline ì„±ëŠ¥ ì¸¡ì •"""

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ (ë‹¤ì–‘í•œ ë‚œì´ë„)
    test_queries = {
        "easy": [
            "TADFë€ ë¬´ì—‡ì¸ê°€?",
            "LGë””ìŠ¤í”Œë ˆì´ ë³¸ì‚¬ëŠ” ì–´ë””ì¸ê°€?",
            "HRD-Netì´ë€?"
        ],
        "medium": [
            "TADF ì¬ë£Œì˜ ì–‘ì íš¨ìœ¨ì€ ì–¼ë§ˆì¸ê°€?",
            "FRET ì—ë„ˆì§€ ì „ë‹¬ íš¨ìœ¨ì€?",
            "LGë””ìŠ¤í”Œë ˆì´ì˜ OLED ì‹œì¥ ë™í–¥ì€?"
        ],
        "hard": [
            "TADFì™€ OLED íš¨ìœ¨ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•´ì¤˜",
            "ë¶„ì êµ¬ì¡°ì™€ ì„±ëŠ¥ì˜ ê´€ê³„ëŠ”?",
            "8.6ì„¸ëŒ€ IT OLED ìƒì‚°ë¼ì¸ì˜ íŠ¹ì§•ê³¼ LGë””ìŠ¤í”Œë ˆì´ ì „ëµì„ ì—°ê²°í•´ì„œ ì„¤ëª…í•´ì¤˜"
        ]
    }

    results = {
        "timestamp": datetime.now().isoformat(),
        "version": "v3.1 (before Phase A)",
        "metrics": {}
    }

    # ê° ë‚œì´ë„ë³„ í…ŒìŠ¤íŠ¸
    for difficulty, queries in test_queries.items():
        print(f"\n{'='*60}")
        print(f"ë‚œì´ë„: {difficulty.upper()}")
        print(f"{'='*60}")

        difficulty_results = []

        for i, query in enumerate(queries, 1):
            print(f"\n[Query {i}/{len(queries)}] {query}")

            # ì„±ëŠ¥ ì¸¡ì •
            start_time = time.time()
            result = rag_chain.generate_answer(query)
            elapsed_time = time.time() - start_time

            # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            sources = result.get('sources', [])
            answer = result.get('answer', '')

            # ì¹´í…Œê³ ë¦¬ ì˜¤ì—¼ ì²´í¬
            categories = [s.metadata.get('category', 'unknown') for s in sources]
            category_purity = calculate_category_purity(query, categories)

            # ì¶œì²˜ í‘œì‹œ í™•ì¸
            has_inline_citation = '[' in answer and ']' in answer
            citation_count = answer.count('[')

            # ê¸ˆì§€ êµ¬ë¬¸ ì²´í¬
            forbidden_phrases = ["ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤", "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"]
            has_forbidden_phrase = any(phrase in answer for phrase in forbidden_phrases)

            # ì¬ìƒì„± ì—¬ë¶€ (ë¡œê·¸ì—ì„œ í™•ì¸ í•„ìš”)
            # ì‹¤ì œë¡œëŠ” RAGChainì— ì¹´ìš´í„° ì¶”ê°€ í•„ìš”

            query_result = {
                "query": query,
                "elapsed_time": elapsed_time,
                "num_sources": len(sources),
                "categories": categories,
                "category_purity": category_purity,
                "has_inline_citation": has_inline_citation,
                "citation_count": citation_count,
                "has_forbidden_phrase": has_forbidden_phrase,
                "answer_length": len(answer)
            }

            difficulty_results.append(query_result)

            # ì¶œë ¥
            print(f"  ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            print(f"  ì¶œì²˜: {len(sources)}ê°œ")
            print(f"  ì¹´í…Œê³ ë¦¬: {categories}")
            print(f"  ì¹´í…Œê³ ë¦¬ ìˆœë„: {category_purity:.1%}")
            print(f"  ì¸ë¼ì¸ ì¶œì²˜: {'âœ“' if has_inline_citation else 'âœ—'}")
            print(f"  ê¸ˆì§€ êµ¬ë¬¸: {'âœ— ë°œê²¬' if has_forbidden_phrase else 'âœ“'}")

        results["metrics"][difficulty] = {
            "queries": difficulty_results,
            "avg_time": sum(r["elapsed_time"] for r in difficulty_results) / len(difficulty_results),
            "avg_sources": sum(r["num_sources"] for r in difficulty_results) / len(difficulty_results),
            "avg_purity": sum(r["category_purity"] for r in difficulty_results) / len(difficulty_results),
            "inline_citation_rate": sum(r["has_inline_citation"] for r in difficulty_results) / len(difficulty_results),
            "forbidden_phrase_rate": sum(r["has_forbidden_phrase"] for r in difficulty_results) / len(difficulty_results)
        }

    # ê²°ê³¼ ì €ì¥
    output_file = f"test_results/phase_a_baseline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*60}")
    print(f"Baseline í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ê²°ê³¼ ì €ì¥: {output_file}")
    print(f"{'='*60}")

    return results

def calculate_category_purity(query: str, categories: List[str]) -> float:
    """ì§ˆë¬¸ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ ìˆœë„ ê³„ì‚°"""

    # ì§ˆë¬¸ íƒ€ì… ì¶”ì •
    if any(kw in query.lower() for kw in ['tadf', 'oled', 'fret', 'quantum', 'ì–‘ì', 'íš¨ìœ¨']):
        expected = ['technical', 'business']
    elif any(kw in query.lower() for kw in ['lgë””ìŠ¤í”Œë ˆì´', 'ì‹œì¥', 'ë‰´ìŠ¤']):
        expected = ['business', 'technical']
    elif any(kw in query.lower() for kw in ['hrd', 'ì¶œê²°', 'êµìœ¡']):
        expected = ['hr']
    else:
        expected = []  # ëª¨ë¦„

    if not expected:
        return 1.0  # íŒë‹¨ ë¶ˆê°€ëŠ¥

    # ìˆœë„ ê³„ì‚°
    match_count = sum(1 for c in categories if c in expected)
    return match_count / len(categories) if categories else 0.0

if __name__ == "__main__":
    run_baseline_test()
```

---

## ì˜ˆìƒ ì„±ê³¼

### Phase A ì™„ë£Œ í›„ ëª©í‘œ

| ì§€í‘œ | Before (v3.1) | Target (Phase A) | ê°œì„  |
|------|--------------|-----------------|------|
| **í¬ë¡œìŠ¤ ë„ë©”ì¸ ì˜¤ì—¼** | 4.5% (1/22) | **0%** (0/N) | -100% |
| **ì¶œì²˜ ì •í™•ë„** | ~60% | **95%** | +58% |
| **ì¶œì²˜ ì»¤ë²„ë¦¬ì§€** | ~30% | **90%** | +200% |
| **ì¬ìƒì„± ë¹ˆë„** | ~20% | **10%** | -50% |
| **ê¸ˆì§€ êµ¬ë¬¸ ì‚¬ìš©** | ~20% | **4%** | -80% |
| **í‰ê·  ì‘ë‹µ ì‹œê°„** | 92ì´ˆ | **77-82ì´ˆ** | -10-15ì´ˆ |
| **ì‚¬ìš©ì ì‹ ë¢°ë„** | - | - | **+30%** |

### NotebookLM ë¹„êµ (Phase A í›„)

| í•­ëª© | NotebookLM | Phase A ëª©í‘œ | ë¹„ê³  |
|------|-----------|------------|------|
| **ì¶œì²˜ ì •í™•ë„** | 95% | **95%** | ë™ë“± |
| **Hallucination ë°©ì§€** | ê°•í•¨ | **ê°•í•¨** | ë™ë“± |
| **í¬ë¡œìŠ¤ ë„ë©”ì¸ ë¶„ë¦¬** | - | **100%** | ìš°ìœ„ |
| **ëŒ€ëŸ‰ ë¬¸ì„œ** | âŒ ì•½í•¨ | âœ… **ê°•í•¨** | ìš°ìœ„ |

**ê²°ë¡ **: Phase A ì™„ë£Œ ì‹œ NotebookLMì˜ í•µì‹¬ ê°•ì (Source Citation) ìˆ˜ì¤€ ë„ë‹¬

---

## ë‹¤ìŒ ë‹¨ê³„

### Phase A ì™„ë£Œ í›„

1. **ì„±ëŠ¥ ì¸¡ì • ë° ë¶„ì„** (1ì¼)
   - Before/After ë¹„êµ
   - ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
   - ì¶”ê°€ ìµœì í™” í•„ìš” ì‚¬í•­ íŒŒì•…

2. **ë¬¸ì„œí™”** (ë°˜ë‚˜ì ˆ)
   - Phase A êµ¬í˜„ ì™„ë£Œ ë³´ê³ ì„œ ì‘ì„±
   - ì½”ë“œ ì£¼ì„ ì •ë¦¬
   - ì‚¬ìš©ì ê°€ì´ë“œ ì—…ë°ì´íŠ¸

3. **Phase B ì¤€ë¹„** (1ì¼)
   - Phase B ìƒì„¸ êµ¬í˜„ ê³„íš ì‘ì„±
   - Query Rewriting ì„¤ê³„
   - Confidence Score ì„¤ê³„

---

**ì‘ì„±ì¼**: 2025-11-06
**ì˜ˆìƒ ì™„ë£Œ**: 2025-11-13 ~ 2025-11-20
**ë‹¤ìŒ**: Phase B êµ¬í˜„ ê³„íšì„œ
