# OC_RAG ì‹œìŠ¤í…œ ì¢…í•© ì½”ë“œ ë¦¬ë·° ë° í‰ê°€ ë ˆí¬íŠ¸
**ì‘ì„±ì¼**: 2024-10-28  
**ê²€í†  ë²”ìœ„**: ì „ì²´ ì½”ë“œë² ì´ìŠ¤ (RAG Chain, Vector Store, Document Processing, UI)

---

## ğŸ“Š ì‹¤í–‰ ìš”ì•½ (Executive Summary)

### í˜„ì¬ ìˆ˜ì¤€ í‰ê°€
- **ì „ì²´ ì ìˆ˜**: 6.5/10 (ì¤‘ìƒê¸‰ ìˆ˜ì¤€)
- **ì½”ë“œ í’ˆì§ˆ**: 7/10 (ê¹”ë”í•˜ê³  ì˜ êµ¬ì¡°í™”ë¨)
- **ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„±**: 6/10 (ì¼ë¶€ ë¹„íš¨ìœ¨ ì¡´ì¬)
- **ìƒìš© ì„œë¹„ìŠ¤ ëŒ€ë¹„**: 65% ìˆ˜ì¤€ (20% ê°œì„  í•„ìš”)

### ì£¼ìš” ë°œê²¬ì‚¬í•­
âœ… **ê°•ì **: ì •ì„ì ì¸ RAG êµ¬ì¡°, ëª¨ë“ˆí™”ê°€ ì˜ ë¨, ìµœì‹  ê¸°ë²• ì ìš©  
âš ï¸ **ì•½ì **: ì¤‘ë³µ ê²€ìƒ‰, ë¹„íš¨ìœ¨ì ì¸ LLM í˜¸ì¶œ, ìºì‹± ë¶€ì¡±  
âŒ **ì¹˜ëª…ì  ë¬¸ì œ**: ì—†ìŒ (í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œì„  ê¸°íšŒ ì¡´ì¬)

---

## 1. ì•„í‚¤í…ì²˜ ë° ì„¤ê³„ í’ˆì§ˆ í‰ê°€

### 1.1 êµ¬ì¡° í‰ê°€: â­â­â­â­â˜† (8/10)

**ê°•ì :**
```
âœ… ëª…í™•í•œ ê³„ì¸µ ë¶„ë¦¬
   - UI Layer (PySide6) â†’ Business Logic â†’ Data Layer
   - utils/ ë””ë ‰í† ë¦¬ êµ¬ì¡°ê°€ ë…¼ë¦¬ì 
   
âœ… ëª¨ë“ˆí™” ì˜ ë˜ì–´ ìˆìŒ
   - rag_chain.py: í•µì‹¬ RAG ë¡œì§
   - vector_store.py: ë²¡í„° DB ê´€ë¦¬
   - document_processor.py: ë¬¸ì„œ ì²˜ë¦¬
   - reranker.py: ì¬ìˆœìœ„í™”
   
âœ… í™•ì¥ ê°€ëŠ¥í•œ ì„¤ê³„
   - ë‹¤ì–‘í•œ LLM API íƒ€ì… ì§€ì›
   - ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ ì§€ì›
```

**ì•½ì :**
```
âš ï¸ ìˆœí™˜ ì˜ì¡´ì„± ê°€ëŠ¥ì„±
   - rag_chain â†” vector_store ê°„ ë³µì¡í•œ ìƒí˜¸ì‘ìš©
   
âš ï¸ ì„¤ì • ê´€ë¦¬ ë¶„ì‚°
   - config.jsonê³¼ ì½”ë“œ ë‚´ í•˜ë“œì½”ë”© í˜¼ì¬
```

**ê°œì„  ì œì•ˆ:**
```python
# ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì ìš©
class RAGChain:
    def __init__(self, retriever: Retriever, generator: LLM, reranker: Reranker):
        # ëª…ì‹œì  ì˜ì¡´ì„±
```

---

## 2. í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„± ë¶„ì„

### 2.1 ê²€ìƒ‰ ì „ëµ í‰ê°€: â­â­â­â˜†â˜† (6/10)

#### ë¬¸ì œì  1: ì¤‘ë³µ ê²€ìƒ‰ ìˆ˜í–‰ âš ï¸ **ì‹¬ê°**

**í˜„ì¬ ì½”ë“œ (`rag_chain.py`):**
```python
def _get_context_without_summary_check(self, question: str) -> str:
    search_queries = self._translate_query(question)  # ë²ˆì—­
    
    if self.enable_multi_query:
        # ì›ë³¸ + ë²ˆì—­ë³¸ ëª¨ë‘ ì¬ì‘ì„±
        all_rewritten = []
        for base_query in search_queries:
            rewritten = self.generate_rewritten_queries(base_query, num_queries=2)
            all_rewritten.extend(rewritten)
        
        queries = list(dict.fromkeys(all_rewritten))[:5]  # ìµœëŒ€ 5ê°œ
        
        # ğŸ”´ ë¬¸ì œ: ê° ì¿¼ë¦¬ë§ˆë‹¤ ì „ì²´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        for query in queries:
            if self.use_reranker:
                base = self._search_candidates(query)  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
                # ì¬ë­í‚¹
                # Small-to-Large í™•ì¥
                # ì¤‘ë³µ ì œê±°
```

**ë¬¸ì œ ë¶„ì„:**
1. **5ê°œ ì¿¼ë¦¬ Ã— ì „ì²´ íŒŒì´í”„ë¼ì¸** = ê³¼ë„í•œ ê³„ì‚°
2. ì¬ë­í‚¹ì´ ì¿¼ë¦¬ë³„ë¡œ ë…ë¦½ ì‹¤í–‰ â†’ ë³‘í•© í›„ í•œ ë²ˆë§Œ í•´ì•¼ í•¨
3. Small-to-Large í™•ì¥ë„ ì¤‘ë³µ ìˆ˜í–‰

**ë¹„ìš© ë¶„ì„:**
```
í˜„ì¬ ë°©ì‹:
- ì„ë² ë”© ìš”ì²­: 5ê°œ ì¿¼ë¦¬ Ã— 6íšŒ ì¬ë­í‚¹ = 30íšŒ ì„ë² ë”©
- ì¬ë­í‚¹: 5íšŒ ë…ë¦½ ì‹¤í–‰
- ì´ LLM í˜¸ì¶œ: ë²ˆì—­ 1íšŒ + ì¬ì‘ì„± 10íšŒ = 11íšŒ

ì •ì„ ë°©ì‹:
- ì„ë² ë”© ìš”ì²­: 5ê°œ ì¿¼ë¦¬ = 5íšŒ ì„ë² ë”©
- ì¬ë­í‚¹: ë³‘í•© í›„ 1íšŒë§Œ
- ì´ LLM í˜¸ì¶œ: ë²ˆì—­ 1íšŒ + ì¬ì‘ì„± 5íšŒ = 6íšŒ

ê°œì„  íš¨ê³¼: ì•½ 60% ë¹„ìš© ì ˆê°
```

**ê°œì„  ë°©ì•ˆ:**
```python
def _get_context_optimized(self, question: str) -> str:
    # 1. ì¿¼ë¦¬ í™•ì¥ (ë²ˆì—­ + ì¬ì‘ì„±)
    search_queries = self._translate_and_rewrite(question, max_queries=5)
    
    # 2. ë³‘ë ¬ ê²€ìƒ‰ (ëª¨ë“  ì¿¼ë¦¬ ë™ì‹œ ê²€ìƒ‰)
    all_candidates = []
    for query in search_queries:
        candidates = self._vector_search(query, k=60)  # ë²¡í„° ê²€ìƒ‰ë§Œ
        all_candidates.extend(candidates)
    
    # 3. ì¤‘ë³µ ì œê±° ë° í†µí•©
    unique_candidates = self._deduplicate_by_content(all_candidates)
    
    # 4. í•œ ë²ˆë§Œ ì¬ë­í‚¹ (í†µí•©ëœ í›„ë³´êµ°)
    if self.use_reranker:
        reranked = self.reranker.rerank(question, unique_candidates, top_k=50)
    
    # 5. Small-to-Large í™•ì¥ (ìµœì¢… ê²°ê³¼ì—ë§Œ)
    expanded = self._expand_with_parent_chunks(reranked[:10])
    
    return self._format_docs(expanded)
```

#### ë¬¸ì œì  2: ë¶ˆí•„ìš”í•œ LLM í˜¸ì¶œ âš ï¸ **ì¤‘ê°„**

**í˜„ì¬ ì½”ë“œ:**
```python
def _translate_query(self, query: str) -> List[str]:
    # ë§¤ë²ˆ LLM í˜¸ì¶œ
    response = self.llm.invoke(prompt)
```

**ë¬¸ì œ:** ê°™ì€ ì¿¼ë¦¬ ë°˜ë³µ ì§ˆë¬¸ ì‹œ ë§¤ë²ˆ ë²ˆì—­

**í•´ê²°:** ê°„ë‹¨í•œ LRU ìºì‹œ ì¶”ê°€
```python
from functools import lru_cache

class RAGChain:
    def __init__(self, ...):
        self._query_cache = {}  # ë‹¨ìˆœ ìºì‹œ
        
    def _translate_query(self, query: str) -> List[str]:
        if query in self._query_cache:
            return self._query_cache[query]
        
        translated = self._do_translate(query)
        self._query_cache[query] = translated
        return translated
```

### 2.2 ì¬ë­í‚¹ ì „ëµ í‰ê°€: â­â­â­â­â˜† (7.5/10)

**ê°•ì :**
- Cross-encoder ì‚¬ìš© (ì •ì„)
- ë¡œì»¬ ëª¨ë¸ ìºì‹± ì§€ì›
- í´ë°± ë©”ì»¤ë‹ˆì¦˜ ìˆìŒ

**ì•½ì :**
```python
# í˜„ì¬: ì¿¼ë¦¬ë³„ ë…ë¦½ ì¬ë­í‚¹
for query in queries:
    reranked = self.reranker.rerank(query, docs_for_rerank, top_k=50)

# ì •ì„: í†µí•© í›„ í•œ ë²ˆë§Œ
all_docs = merge(all_query_results)
reranked = self.reranker.rerank(original_question, all_docs, top_k=50)
```

---

## 3. ì½”ë“œ í’ˆì§ˆ ë° ì•ˆì •ì„±

### 3.1 ì½”ë“œ í’ˆì§ˆ: â­â­â­â­â˜† (7.5/10)

**ê°•ì :**
```
âœ… íƒ€ì… íŒíŒ… ì ì ˆíˆ ì‚¬ìš©
âœ… ì—ëŸ¬ ì²˜ë¦¬ ì¡´ì¬
âœ… ë¡œê¹…ì´ ì˜ ë˜ì–´ ìˆìŒ
âœ… ì£¼ì„ ì ì ˆ
```

**ê°œì„  í•„ìš”:**
```python
# í˜„ì¬: ë§¤ì§ ë„˜ë²„
reranked = self.reranker.rerank(query, docs, top_k=max(self.top_k * 10, 50))

# ê°œì„ : ìƒìˆ˜ë¡œ ì •ì˜
RERANK_MULTIPLIER = 10
MIN_RERANK_CANDIDATES = 50
reranked = self.reranker.rerank(
    query, docs, 
    top_k=max(self.top_k * RERANK_MULTIPLIER, MIN_RERANK_CANDIDATES)
)
```

### 3.2 ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: â­â­â­â˜†â˜† (6/10)

**ë¬¸ì œ:**
```python
# í˜„ì¬: ëª¨ë“  í›„ë³´ë¥¼ ë©”ëª¨ë¦¬ì— ìœ ì§€
all_retrieved_chunks = []
for query in queries:
    chunks = search(query)
    all_retrieved_chunks.extend(chunks)  # ëˆ„ì 

# ê°œì„ : ìŠ¤íŠ¸ë¦¬ë° ë˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬
def _search_with_limit(self, queries, max_results=100):
    seen = set()
    for query in queries:
        for chunk in self._search_stream(query):
            if chunk.id not in seen:
                yield chunk
                seen.add(chunk.id)
                if len(seen) >= max_results:
                    return
```

---

## 4. ìƒìš© ì„œë¹„ìŠ¤ ëŒ€ë¹„ ë¶„ì„

### 4.1 ë¹„êµ ê¸°ì¤€

| í•­ëª© | í˜„ì¬ ì‹œìŠ¤í…œ | ìƒìš© ì„œë¹„ìŠ¤ (ì˜ˆ: Perplexity) | ê²©ì°¨ |
|------|------------|----------------------------|------|
| ê²€ìƒ‰ ì •í™•ë„ | ~70% | ~90% | -20% |
| ì‘ë‹µ ì†ë„ | 15ì´ˆ | 3-5ì´ˆ | -10ì´ˆ |
| ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ | ~10K chars | ~50K chars | -40K |
| ë‹¤êµ­ì–´ ì§€ì› | ê¸°ì´ˆ | ê³ ê¸‰ | - |
| ìºì‹± ì „ëµ | ì—†ìŒ | ë‹¤ì¸µ ìºì‹œ | - |
| ì—ëŸ¬ ë³µêµ¬ | ê¸°ë³¸ | ê°•í™” | - |

### 4.2 ì£¼ìš” ì°¨ì´ì 

#### 1. ìºì‹± ì „ëµ ë¶€ì¬ âš ï¸ **ì¹˜ëª…ì **

**ìƒìš© ì„œë¹„ìŠ¤:**
```
- ì¿¼ë¦¬ â†’ ê²°ê³¼ ìºì‹œ (Redis)
- ì„ë² ë”© ìºì‹œ
- LLM ì‘ë‹µ ìºì‹œ
- ì„¸ì…˜ë³„ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ
```

**í˜„ì¬ ì‹œìŠ¤í…œ:**
```
- ìºì‹œ ì—†ìŒ
- ë§¤ë²ˆ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```

**ê°œì„ :**
```python
# ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ ìºì‹œë¼ë„ ì¶”ê°€
class RAGChain:
    def __init__(self, ...):
        self._result_cache = TTLCache(maxsize=100, ttl=3600)
        
    def query(self, question: str, ...):
        cache_key = hash(question)
        if cache_key in self._result_cache:
            return self._result_cache[cache_key]
        
        result = self._query_internal(question)
        self._result_cache[cache_key] = result
        return result
```

#### 2. ì»¨í…ìŠ¤íŠ¸ ìµœì í™” ë¶€ì¡±

**í˜„ì¬:**
- ê³ ì •ëœ top_k ì‚¬ìš©
- ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œì´ ì—„ê²©í•¨

**ìƒìš© ì„œë¹„ìŠ¤:**
- ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¥¸ ë™ì  ì»¨í…ìŠ¤íŠ¸
- í† í° ì˜ˆì‚° ê´€ë¦¬
- ì²­í¬ ìŠ¤ì½”ì–´ë§ ê¸°ë°˜ ì„ ë³„

---

## 5. ë¹„íš¨ìœ¨ì  ìš°íšŒ ë°©ì‹ ë¶„ì„

### 5.1 ë°œê²¬ëœ ìš°íšŒ ë°©ì‹ë“¤

#### 1. ì¤‘ë³µ ê²€ìƒ‰ìœ¼ë¡œ ì •í™•ë„ ë³´ì™„ âŒ

**í˜„ì¬ ë°©ì‹:**
```python
# 5ê°œ ì¿¼ë¦¬ë¡œ ì—¬ëŸ¬ ë²ˆ ê²€ìƒ‰ â†’ ì •í™•ë„ ì˜¬ë¦¬ê¸°
queries = generate_multiple_queries(question, n=5)
for query in queries:
    results = search(query)  # ì¤‘ë³µ
```

**ë¬¸ì œ:** ì •í™•ë„ëŠ” ì˜¬ë¼ê°€ì§€ë§Œ ë¹„ìš©ì´ 5ë°°

**ì •ì„ ë°©ì‹:**
```python
# ë‹¨ì¼ ê°•ë ¥í•œ ì¿¼ë¦¬ + ì¬ë­í‚¹
single_query = enhance_query(question)  # LLMìœ¼ë¡œ í•œ ë²ˆë§Œ
candidates = search(single_query, k=100)
reranked = rerank(question, candidates, top_k=10)
```

#### 2. ì„ê³„ê°’ í•„í„°ë§ ìš°íšŒ âŒ

**í˜„ì¬:**
```python
# ìœ ì‚¬ë„ ì ìˆ˜ê°€ ë‚®ì•„ë„ í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´...
top_k=20  # ë„ˆë¬´ í° ê°’

# ë˜ëŠ”
if p < 15.0:
    continue  # í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì´ ì²´í¬ê°€ ë¶ˆì™„ì „
```

**ì •ì„:**
- ì¬ë­í‚¹ ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§
- ë™ì  ì„ê³„ê°’ (ì§ˆë¬¸ ìœ í˜•ë³„)

#### 3. ì¿¼ë¦¬ ë²ˆì—­ìœ¼ë¡œ ë‹¤êµ­ì–´ ì²˜ë¦¬ âš ï¸

**í˜„ì¬:**
```python
# ë§¤ë²ˆ LLMìœ¼ë¡œ ë²ˆì—­
translated = llm.translate(query)
```

**ì •ì„:**
- ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (mxbai-embed-largeëŠ” ì´ë¯¸ ì§€ì›)
- ë²ˆì—­ ë¶ˆí•„ìš” ë˜ëŠ” ê°„ë‹¨í•œ ë£° ê¸°ë°˜ ë²ˆì—­

---

## 6. ì •ì„ vs ë¹„ì •ì„ ë°©ì‹ ë¹„êµ

### 6.1 ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸

| ë‹¨ê³„ | í˜„ì¬ ë°©ì‹ | ì •ì„ ë°©ì‹ | í‰ê°€ |
|------|----------|----------|------|
| ì¿¼ë¦¬ í™•ì¥ | LLMìœ¼ë¡œ ë²ˆì—­+ì¬ì‘ì„± | LLMìœ¼ë¡œ ì¬ì‘ì„±ë§Œ | âš ï¸ ê³¼ë„ |
| ë²¡í„° ê²€ìƒ‰ | ì¿¼ë¦¬ë³„ ë…ë¦½ ê²€ìƒ‰ | í†µí•© ê²€ìƒ‰ | âŒ ë¹„íš¨ìœ¨ |
| ì¬ë­í‚¹ | ì¿¼ë¦¬ë³„ ë…ë¦½ ì‹¤í–‰ | í†µí•© í›„ 1íšŒ | âŒ ë¹„íš¨ìœ¨ |
| ê²°ê³¼ ë³‘í•© | ë‹¨ìˆœ í•©ì§‘í•© | ìŠ¤ì½”ì–´ ì¬ì •ê·œí™” | âš ï¸ ë‹¨ìˆœ |

### 6.2 ì •ì„ êµ¬í˜„ ì˜ˆì‹œ

```python
def _retrieve_optimal(self, question: str) -> List[Document]:
    """
    ìƒìš© ì„œë¹„ìŠ¤ ìˆ˜ì¤€ì˜ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸
    """
    # 1. ì¿¼ë¦¬ ê°•í™” (í•œ ë²ˆë§Œ)
    enhanced_query = self._enhance_query(question)
    
    # 2. ë²¡í„° ê²€ìƒ‰ (ë„“ê²Œ)
    vector_results = self.vectorstore.similarity_search_with_score(
        enhanced_query, k=100
    )
    
    # 3. BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ë³´ì™„)
    bm25_results = self._bm25_search(enhanced_query, k=50)
    
    # 4. í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ (ì •ê·œí™”)
    hybrid_results = self._hybrid_merge(
        vector_results, bm25_results,
        vector_weight=0.7, keyword_weight=0.3
    )
    
    # 5. ì¬ë­í‚¹ (í†µí•© í›„ 1íšŒ)
    reranked = self.reranker.rerank(
        question,  # ì›ë³¸ ì§ˆë¬¸ ì‚¬ìš©
        hybrid_results[:60],
        top_k=20
    )
    
    # 6. Small-to-Large í™•ì¥
    expanded = self._expand_with_parent_chunks(reranked[:10])
    
    # 7. ìµœì¢… í•„í„°ë§ (ë™ì  ì„ê³„ê°’)
    filtered = self._filter_by_relevance(
        expanded, 
        min_score=self._calculate_dynamic_threshold(question)
    )
    
    return filtered
```

---

## 7. ê°œì„  ìš°ì„ ìˆœìœ„ ë° ë¡œë“œë§µ

### Phase 1: ì¦‰ì‹œ ê°œì„  (1ì£¼ì¼) - ë¹„ìš© 60% ì ˆê°

**P1-1: ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ í†µí•©**
- ì¿¼ë¦¬ë³„ ë…ë¦½ ê²€ìƒ‰ â†’ í†µí•© ê²€ìƒ‰
- ì¬ë­í‚¹ í†µí•© (5íšŒ â†’ 1íšŒ)
- **ì˜ˆìƒ íš¨ê³¼**: ì‘ë‹µ ì‹œê°„ 15ì´ˆ â†’ 8ì´ˆ

**P1-2: ê¸°ë³¸ ìºì‹± ì¶”ê°€**
- ì¿¼ë¦¬ â†’ ê²°ê³¼ ìºì‹œ
- ì„ë² ë”© ìºì‹œ
- **ì˜ˆìƒ íš¨ê³¼**: ë°˜ë³µ ì§ˆë¬¸ ì‹œ ì¦‰ì‹œ ì‘ë‹µ

**P1-3: LLM í˜¸ì¶œ ìµœì í™”**
- ì¿¼ë¦¬ ë²ˆì—­ ìºì‹±
- ë¶ˆí•„ìš”í•œ ì¬ì‘ì„± ì¤„ì´ê¸°
- **ì˜ˆìƒ íš¨ê³¼**: LLM í˜¸ì¶œ 11íšŒ â†’ 6íšŒ

### Phase 2: ì •í™•ë„ ê°œì„  (2ì£¼) - í’ˆì§ˆ +20%

**P2-1: ë™ì  ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´**
- ì§ˆë¬¸ ë³µì¡ë„ ê¸°ë°˜ top_k ì¡°ì •
- í† í° ì˜ˆì‚° ê´€ë¦¬

**P2-2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°•í™”**
- BM25 ê°€ì¤‘ì¹˜ íŠœë‹
- ìŠ¤ì½”ì–´ ì¬ì •ê·œí™”

**P2-3: í”„ë¡¬í”„íŠ¸ ìµœì í™”**
- Few-shot ì˜ˆì‹œ ì¶”ê°€
- Chain-of-thought ì ìš©

### Phase 3: ìƒìš© ìˆ˜ì¤€ (1ê°œì›”) - ì „ì²´ì ìœ¼ë¡œ 90% ìˆ˜ì¤€

**P3-1: ê³ ê¸‰ ìºì‹±**
- Redis ì—°ë™
- ë©€í‹° ë ˆë²¨ ìºì‹œ

**P3-2: ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…**
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- A/B í…ŒìŠ¤íŠ¸ ì§€ì›

**P3-3: ì—ëŸ¬ ë³µêµ¬ ê°•í™”**
- ìë™ ì¬ì‹œë„
- Graceful degradation

---

## 8. ì¢…í•© í‰ê°€ ë° ê²°ë¡ 

### 8.1 ì „ì²´ ì ìˆ˜

| ì¹´í…Œê³ ë¦¬ | ì ìˆ˜ | í‰ê°€ |
|---------|------|------|
| ì•„í‚¤í…ì²˜ | 8/10 | âœ… ì˜ ì„¤ê³„ë¨ |
| ì½”ë“œ í’ˆì§ˆ | 7.5/10 | âœ… ê¹”ë”í•¨ |
| ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„± | 6/10 | âš ï¸ ê°œì„  í•„ìš” |
| í™•ì¥ì„± | 8/10 | âœ… ì¢‹ìŒ |
| ì•ˆì •ì„± | 7/10 | âœ… ê¸°ë³¸ì€ ìˆìŒ |
| ì„±ëŠ¥ | 6/10 | âš ï¸ ìºì‹± ë¶€ì¡± |
| **ì¢…í•©** | **6.5/10** | **ì¤‘ìƒê¸‰** |

### 8.2 ìƒìš© ì„œë¹„ìŠ¤ ëŒ€ë¹„

**í˜„ì¬ ìˆ˜ì¤€**: ì•½ **65%**

**ì£¼ìš” ê²©ì°¨:**
1. ì„±ëŠ¥ ìµœì í™” (-20%)
2. ìºì‹± ì „ëµ (-10%)
3. ì •í™•ë„ ë¯¸ì„¸ ì¡°ì • (-5%)

### 8.3 ìµœì¢… ê²°ë¡ 

**âœ… ê¸ì •ì  í‰ê°€:**
- ì •ì„ì ì¸ RAG ì•„í‚¤í…ì²˜ë¥¼ ë”°ë¥´ê³  ìˆìŒ
- ìµœì‹  ê¸°ë²•(ì¬ë­í‚¹, Small-to-Large) ì ìš©
- ì½”ë“œê°€ ê¹”ë”í•˜ê³  ìœ ì§€ë³´ìˆ˜ ê°€ëŠ¥
- í™•ì¥ì„± ì¢‹ìŒ

**âš ï¸ ê°œì„  í•„ìš”:**
- ì¤‘ë³µ ê²€ìƒ‰ìœ¼ë¡œ ì¸í•œ ë¹„íš¨ìœ¨ (ì£¼ìš” ë¬¸ì œ)
- ìºì‹± ë¶€ì¬ (í° ê°œì„  ì—¬ì§€)
- ê³¼ë„í•œ LLM í˜¸ì¶œ

**ğŸ¯ ê¶Œì¥ì‚¬í•­:**
1. **ì¦‰ì‹œ**: ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ í†µí•© (Phase 1)
2. **ë‹¨ê¸°**: ìºì‹± ì¶”ê°€
3. **ì¤‘ê¸°**: ë™ì  ìµœì í™” ë° í”„ë¡¬í”„íŠ¸ íŠœë‹

**í˜„ì¬ ì‹œìŠ¤í…œì€ "ì •ì„ì„ ë”°ë¥´ë˜ ë¹„íš¨ìœ¨ì ìœ¼ë¡œ êµ¬í˜„ëœ ìƒíƒœ"**
- ì•Œê³ ë¦¬ì¦˜: ì •ì„ âœ…
- êµ¬í˜„: ë¹„íš¨ìœ¨ âš ï¸
- ê°œì„  ì—¬ì§€: í¼ ğŸ¯

---

## ë¶€ë¡: ì½”ë“œ ìŠ¤ë‹ˆí« ê°œì„  ì˜ˆì‹œ

### A. í†µí•© ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸

```python
def _retrieve_optimized(self, question: str) -> List[Document]:
    """ê°œì„ ëœ í†µí•© ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸"""
    
    # 1. ì¿¼ë¦¬ í™•ì¥ (ìºì‹œ í™œìš©)
    queries = self._get_expanded_queries(question, max_n=3)  # 5ê°œ â†’ 3ê°œ
    
    # 2. ë³‘ë ¬ ë²¡í„° ê²€ìƒ‰ (ë¹„ë™ê¸° ê°€ëŠ¥)
    all_candidates = []
    for query in queries:
        results = self.vectorstore.similarity_search_with_score(query, k=40)
        all_candidates.extend(results)
    
    # 3. ì¤‘ë³µ ì œê±° ë° í†µí•©
    unique_candidates = self._deduplicate_by_content(all_candidates)
    
    # 4. í†µí•© ì¬ë­í‚¹ (í•œ ë²ˆë§Œ)
    if self.use_reranker:
        reranked = self.reranker.rerank(
            question,  # ì›ë³¸ ì§ˆë¬¸
            unique_candidates[:60],
            top_k=20
        )
    else:
        reranked = unique_candidates[:20]
    
    # 5. Small-to-Large í™•ì¥
    expanded = self._expand_with_parent_chunks(reranked[:10])
    
    return expanded
```

### B. ìºì‹± ë ˆì´ì–´

```python
from functools import lru_cache
from cachetools import TTLCache

class CachedRAGChain(RAGChain):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._query_cache = TTLCache(maxsize=100, ttl=3600)
        self._translation_cache = TTLCache(maxsize=500, ttl=86400)
    
    def _translate_query(self, query: str) -> List[str]:
        if query in self._translation_cache:
            return self._translation_cache[query]
        
        translated = super()._translate_query(query)
        self._translation_cache[query] = translated
        return translated
    
    def query(self, question: str, **kwargs) -> Dict:
        cache_key = f"{question}:{kwargs}"
        if cache_key in self._query_cache:
            return self._query_cache[cache_key]
        
        result = super().query(question, **kwargs)
        self._query_cache[cache_key] = result
        return result
```

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: Phase 1 ê°œì„  ì™„ë£Œ í›„

