# Phase D: ë‹µë³€ ìì—°í™” êµ¬í˜„ ê³„íš

**ì‘ì„±ì¼**: 2025-11-07
**ë²„ì „**: v3.3.0 (Phase D)
**ì˜ˆìƒ ì†Œìš”**: 0.5ì¼ (4-5ì‹œê°„)
**ìš°ì„ ìˆœìœ„**: â˜…â˜…â˜…â˜…â˜… (ì¦‰ì‹œ ì°©ìˆ˜)

---

## ğŸ¯ ëª©í‘œ

**ì‚¬ìš©ì ì œê¸° ë¬¸ì œ í•´ê²°**:
1. âŒ ì„¹ì…˜ êµ¬ì¡° ê°•ì œ (ë‹µë³€:, ìƒì„¸ì„¤ëª…:, ì°¸ì¡° ì •ë³´: ë“±)
2. âŒ ë‚´ìš© ì¤‘ë³µ (ì„¹ì…˜ ì±„ìš°ê¸° ìœ„í•œ ì–µì§€ ë¶„ë¦¬)
3. âŒ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€
4. âš ï¸ í† í° ë¶€ì¡± (ë³µì¡í•œ ì§ˆë¬¸/ë²ˆì—­ ì‹œ)

**Phase D ëª©í‘œ**:
1. âœ… ì„¹ì…˜ ì œëª© ì œê±° â†’ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨
2. âœ… max_tokens ì¦ê°€ â†’ ë³µì¡í•œ ë‹µë³€ ê°€ëŠ¥ (2048 â†’ 4096)
3. âœ… Inline Citation â†’ NotebookLM ìŠ¤íƒ€ì¼
4. âœ… ê¸ˆì§€ ì¡°í•­ ì™„í™” â†’ ê¸ì •ì  ê°€ì´ë“œ

---

## ğŸ“‹ í˜„ì¬ ë¬¸ì œì 

### ë¬¸ì œ 1: ì„¹ì…˜ ê°•ì œ êµ¬ì¡°

**í˜„ì¬ í”„ë¡¬í”„íŠ¸** (utils/rag_chain.py:189-194):
```
ë‹µë³€ í˜•ì‹ (ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”):

## ë‹µë³€
[ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€ì„ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½]

## ìƒì„¸ ì„¤ëª…
...
```

**ë¬¸ì œ**:
- ì§§ì€ ì§ˆë¬¸ì—ë„ ë¬´ë¦¬í•˜ê²Œ ì—¬ëŸ¬ ì„¹ì…˜ ìƒì„±
- ë‚´ìš© ì¤‘ë³µ (ë‹µë³€ â†” ìƒì„¸ì„¤ëª…)
- NotebookLMê³¼ ë‹¤ë¥¸ í˜•ì‹

### ë¬¸ì œ 2: ê³¼ë„í•œ ê¸ˆì§€ ì¡°í•­

**í˜„ì¬ í”„ë¡¬í”„íŠ¸** (utils/rag_chain.py:133-138):
```python
2. **ê¸ˆì§€ í‘œí˜„** (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€):
   [ERROR] "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
   [ERROR] "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"
   [ERROR] "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
   [ERROR] "ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
   [ERROR] "ë¬¸ì„œì— ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"
```

**ë¬¸ì œ**:
- LLMì´ ê¸ˆì§€ì–´ë¥¼ ë” ì˜ì‹í•˜ê²Œ ë§Œë“¦ (ì—­íš¨ê³¼)
- ì •ë³´ê°€ ì‹¤ì œë¡œ ì—†ì„ ë•Œ ëŒ€ì‘ ë°©ë²• ëª¨í˜¸
- í”„ë¡¬í”„íŠ¸ê°€ ë¶€ì •ì 

### ë¬¸ì œ 3: max_tokens ì„¤ì • ì—†ìŒ

**í˜„ì¬ ì½”ë“œ**:
```python
# __init__ì— max_tokens íŒŒë¼ë¯¸í„° ì—†ìŒ
# LLM ìƒì„± ì‹œ max_tokens ì„¤ì • ì—†ìŒ
# â†’ Ollama ê¸°ë³¸ê°’ (2048) ì‚¬ìš©
```

**ë¬¸ì œ**:
- ë³µì¡í•œ ì§ˆë¬¸/ë²ˆì—­ ì‹œ í† í° ë¶€ì¡±
- ë‹µë³€ì´ ì¤‘ê°„ì— ì˜ë¦¼

---

## âœ… ê°œì„  ë°©ì•ˆ

### 1. í”„ë¡¬í”„íŠ¸ ê°œì„  (1-2ì‹œê°„)

#### ì œê±°í•  ê²ƒ
- âŒ ì„¹ì…˜ ê°•ì œ êµ¬ì¡° (## ë‹µë³€, ## ìƒì„¸ ì„¤ëª… ë“±)
- âŒ 5ê°œ ê¸ˆì§€ í‘œí˜„ ëª©ë¡
- âŒ 5ë‹¨ê³„ ë‹µë³€ ì ˆì°¨

#### ì¶”ê°€í•  ê²ƒ
- âœ… ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ í˜•ì‹ ê°€ì´ë“œ
- âœ… 4ê°œ ë‹¤ì–‘í•œ ì˜ˆì‹œ (ê°„ë‹¨/ì„¤ëª…/ë²ˆì—­/ì •ë³´ë¶€ì¡±)
- âœ… Inline Citation ê°€ì´ë“œ
- âœ… ë¶€ë“œëŸ¬ìš´ ì›ì¹™ 1ê°œ

#### ê°œì„ ëœ í”„ë¡¬í”„íŠ¸

```python
self.base_prompt_template = """ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ì œê³µëœ ë¬¸ì„œ:
{context}

ì´ì „ ëŒ€í™”:
{chat_history}

ì§ˆë¬¸:
{question}

---

ë‹µë³€ ê°€ì´ë“œ:

1. **ìì—°ìŠ¤ëŸ¬ìš´ í˜•ì‹**:
   - ì„¹ì…˜ ì œëª© ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±
   - ì§ˆë¬¸ì´ ê°„ë‹¨í•˜ë©´ ì§§ê²Œ (1-2ë¬¸ì¥), ë³µì¡í•˜ë©´ ì—¬ëŸ¬ ë¬¸ë‹¨ìœ¼ë¡œ
   - ì‚¬ìš©ì ì˜ë„ì— ë§ê²Œ ë‹µë³€ (ë²ˆì—­/ìš”ì•½/ì„¤ëª… ë“±)

2. **Inline Citation** (í•„ìˆ˜):
   - ëª¨ë“  ì‚¬ì‹¤ì— [ë²ˆí˜¸] í‘œì‹œ
   - ì˜ˆì‹œ: "kFRET ê°’ì€ 87.8%ì…ë‹ˆë‹¤[1]."
   - ì—¬ëŸ¬ ì¶œì²˜: "TADFë¥¼ í™œìš©í•˜ë©°[1], ë†’ì€ íš¨ìœ¨ì„ ë³´ì…ë‹ˆë‹¤[2]."

3. **ì˜ˆì‹œ**:

ì§ˆë¬¸: "kFRET ê°’ì€?"
ë‹µë³€: ì œê³µëœ ë¬¸ì„œì— ë”°ë¥´ë©´, kFRET ê°’ì€ ì•½ 87.8%ì…ë‹ˆë‹¤[1]. ì´ëŠ” í˜•ê´‘ ë„í€íŠ¸ì™€ í˜¸ìŠ¤íŠ¸ ê°„ì˜ ì—ë„ˆì§€ ì „ë‹¬ íš¨ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤[1].

ì§ˆë¬¸: "TADFë€ ë¬´ì—‡ì¸ê°€?"
ë‹µë³€: TADF(Thermally Activated Delayed Fluorescence)ëŠ” ì‚¼ì¤‘í•­ ì—¬ê¸°ìë¥¼ ì—´ì ìœ¼ë¡œ í™œì„±í™”í•˜ì—¬ ì¼ì¤‘í•­ìœ¼ë¡œ ì¬ë³€í™˜í•˜ëŠ” ë°œê´‘ ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤[1]. ì´ë¥¼ í†µí•´ OLEDì—ì„œ ì´ë¡ ì ìœ¼ë¡œ 100%ì˜ ë‚´ë¶€ ì–‘ì íš¨ìœ¨ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤[1][2].

ì§ˆë¬¸: "ì„œë¡  ë²ˆì—­í•´ì¤˜"
ë‹µë³€: í•˜ì´ë¸Œë¦¬ë“œ í˜•ê´‘ OLEDëŠ” TADF ë³´ì¡° í˜¸ìŠ¤íŠ¸ì™€ í˜•ê´‘ ë„í€íŠ¸ë¥¼ ê²°í•©í•œ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤[1]. ì´ ì ‘ê·¼ë²•ì€ TADFì˜ ë†’ì€ íš¨ìœ¨ê³¼ í˜•ê´‘ ë„í€íŠ¸ì˜ ìš°ìˆ˜í•œ ìƒ‰ìˆœë„ë¥¼ ë™ì‹œì— ë‹¬ì„±í•©ë‹ˆë‹¤[1][2].

ì§ˆë¬¸: "í•©ì„± ì˜¨ë„ëŠ”?"
ë‹µë³€: ë¬¸ì„œì—ì„œëŠ” ìœ ê¸° í•©ì„± ê³¼ì •ì„ ì„¤ëª…í•˜ê³  ìˆì§€ë§Œ[1], êµ¬ì²´ì ì¸ í•©ì„± ì˜¨ë„ëŠ” ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.

4. **ì¤‘ìš”**:
   ë¬¸ì„œì— ê·¼ê±°í•˜ì§€ ì•Šì€ ì¶”ì¸¡ì€ í•˜ì§€ ë§ˆì„¸ìš”. ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€:
"""
```

---

### 2. max_tokens ì¦ê°€ (30ë¶„)

**íŒŒì¼**: utils/rag_chain.py

#### __init__ ë©”ì„œë“œ ìˆ˜ì •

```python
def __init__(self,
             vectorstore,
             llm_api_type: str = "ollama",
             llm_base_url: str = "http://localhost:11434",
             llm_model: str = "gemma2:2b",
             llm_api_key: str = None,
             temperature: float = 0.3,
             max_tokens: int = 4096,  # ì¶”ê°€: ê¸°ë³¸ê°’ 4096
             top_k: int = 5,
             ...):

    self.llm_api_type = llm_api_type
    self.llm_base_url = llm_base_url
    self.llm_model = llm_model
    self.llm_api_key = llm_api_key
    self.temperature = temperature
    self.max_tokens = max_tokens  # ì¶”ê°€
    self.top_k = top_k
    ...
```

#### _create_llm ë©”ì„œë“œ ìˆ˜ì •

```python
def _create_llm(self):
    """API íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    if self.llm_api_type == "request":
        return RequestLLM(
            base_url=self.llm_base_url,
            model=self.llm_model,
            temperature=self.temperature,
            max_tokens=self.max_tokens,  # ì¶”ê°€
            timeout=60
        )
    elif self.llm_api_type == "ollama":
        return OllamaLLM(
            base_url=self.llm_base_url,
            model=self.llm_model,
            temperature=self.temperature,
            num_predict=self.max_tokens  # ì¶”ê°€ (OllamaëŠ” num_predict ì‚¬ìš©)
        )
    elif self.llm_api_type == "openai":
        kwargs = {
            "model": self.llm_model,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,  # ì¶”ê°€
            "api_key": self.llm_api_key if self.llm_api_key else "not-needed"
        }
        ...
```

---

### 3. í…ŒìŠ¤íŠ¸ (2ì‹œê°„)

#### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

**test_phase_d.py**:
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Phase D í…ŒìŠ¤íŠ¸: ë‹µë³€ ìì—°í™” ê²€ì¦"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from utils.vector_store import VectorStoreManager
from utils.rag_chain import RAGChain

def test_phase_d():
    print("=" * 80)
    print("Phase D í…ŒìŠ¤íŠ¸: ë‹µë³€ ìì—°í™”")
    print("=" * 80)
    print()

    # VectorStore ì´ˆê¸°í™”
    vectorstore = VectorStoreManager(
        embedding_api_type="ollama",
        embedding_base_url="http://localhost:11434",
        embedding_model="mxbai-embed-large:latest"
    )

    # RAGChain ì´ˆê¸°í™” (max_tokens=4096)
    rag = RAGChain(
        vectorstore=vectorstore,
        llm_api_type="ollama",
        llm_base_url="http://localhost:11434",
        llm_model="gemma3:latest",
        temperature=0.3,
        max_tokens=4096,  # Phase D: ì¦ê°€
        top_k=5,
        use_reranker=True,
        enable_hybrid_search=True
    )

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    test_cases = [
        {
            "question": "kFRET ê°’ì€?",
            "expected": "ê°„ë‹¨í•œ ë‹µë³€ (1-2ë¬¸ì¥)",
            "check_section": False  # ì„¹ì…˜ ì œëª© ì—†ì–´ì•¼ í•¨
        },
        {
            "question": "TADFì˜ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ì¤˜",
            "expected": "ì—¬ëŸ¬ ë¬¸ë‹¨ ë‹µë³€",
            "check_section": False
        },
        {
            "question": "HF-OLED ë…¼ë¬¸ì˜ ì„œë¡  ë¶€ë¶„ ë²ˆì—­í•´ì¤˜",
            "expected": "ì „ì²´ ë²ˆì—­ (í† í° ì¶©ë¶„)",
            "check_section": False
        },
    ]

    for i, case in enumerate(test_cases, 1):
        print(f"\n[{i}] ì§ˆë¬¸: {case['question']}")
        print("-" * 80)

        result = rag.query(case["question"])

        if result["success"]:
            answer = result["answer"]
            print(answer)
            print()

            # ê²€ì¦
            has_section_title = any(
                title in answer
                for title in ["## ë‹µë³€", "## ìƒì„¸ ì„¤ëª…", "ë‹µë³€:", "ìƒì„¸ì„¤ëª…:"]
            )

            if has_section_title:
                print("[WARN] ì„¹ì…˜ ì œëª© ë°œê²¬ (ì œê±°ë˜ì§€ ì•ŠìŒ)")
            else:
                print("[OK] ì„¹ì…˜ ì œëª© ì—†ìŒ (ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨)")

            # Citation í™•ì¸
            citation_count = answer.count("[")
            print(f"[INFO] Citation ê°œìˆ˜: {citation_count}")

            # ë‹µë³€ ê¸¸ì´
            print(f"[INFO] ë‹µë³€ ê¸¸ì´: {len(answer)} chars")
        else:
            print(f"[ERROR] ì¿¼ë¦¬ ì‹¤íŒ¨: {result['answer']}")

        print()

    print("=" * 80)
    print("Phase D í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 80)

if __name__ == "__main__":
    test_phase_d()
```

---

## ğŸ“Š ì˜ˆìƒ íš¨ê³¼

| í•­ëª© | Before (v3.2.0) | After (Phase D) | ê°œì„  |
|------|----------------|-----------------|------|
| **ì„¹ì…˜ ê°•ì œ** | ìˆìŒ (5ê°œ) | ì—†ìŒ (ììœ ) | âœ… ì œê±° |
| **ë‹µë³€ ìì—°ìŠ¤ëŸ¬ì›€** | ë‚®ìŒ | ë†’ìŒ | âœ… +40% |
| **max_tokens** | 2048 | 4096 | âœ… +100% |
| **ê¸ˆì§€ ì¡°í•­** | 5ê°œ | 1ê°œ | âœ… -80% |
| **ì¤‘ë³µ ë‚´ìš©** | ë§ìŒ | ê±°ì˜ ì—†ìŒ | âœ… -60% |
| **ë²ˆì—­ ìš”ì²­ ëŒ€ì‘** | ë¶€ì¡± | ì¶©ë¶„ | âœ… +100% |

---

## ğŸ“… êµ¬í˜„ ì¼ì •

### 0.5ì¼ (4-5ì‹œê°„)

**ì˜¤ì „** (2-3ì‹œê°„):
1. í”„ë¡¬í”„íŠ¸ ê°œì„  (1-2ì‹œê°„)
   - ì„¹ì…˜ ê°•ì œ ì œê±°
   - ê¸ˆì§€ ì¡°í•­ ì™„í™”
   - 4ê°œ ì˜ˆì‹œ ì¶”ê°€
2. max_tokens ì¦ê°€ (30ë¶„)
   - __init__ ìˆ˜ì •
   - _create_llm ìˆ˜ì •

**ì˜¤í›„** (2ì‹œê°„):
3. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (30ë¶„)
4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²€ì¦ (1ì‹œê°„)
5. ë¬¸ì„œí™” (30ë¶„)

---

## ğŸ¯ ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„
- [ ] utils/rag_chain.py - base_prompt_template ìˆ˜ì •
- [ ] utils/rag_chain.py - __init__ max_tokens íŒŒë¼ë¯¸í„° ì¶”ê°€
- [ ] utils/rag_chain.py - _create_llm max_tokens ì „ë‹¬

### í…ŒìŠ¤íŠ¸
- [ ] test_phase_d.py ì‘ì„±
- [ ] ê°„ë‹¨í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (ì„¹ì…˜ ì—†ëŠ”ì§€ í™•ì¸)
- [ ] ë³µì¡í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (ì—¬ëŸ¬ ë¬¸ë‹¨ í™•ì¸)
- [ ] ë²ˆì—­ ìš”ì²­ í…ŒìŠ¤íŠ¸ (í† í° ì¶©ë¶„í•œì§€ í™•ì¸)

### ê²€ì¦
- [ ] ì„¹ì…˜ ì œëª© ì œê±° í™•ì¸
- [ ] Inline Citation í™•ì¸
- [ ] ë‹µë³€ ìì—°ìŠ¤ëŸ¬ì›€ í™•ì¸
- [ ] max_tokens 4096 ì ìš© í™•ì¸

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

Phase D ì™„ë£Œ í›„:
```
âœ… Phase A-3 (ì™„ë£Œ)
âœ… Phase D (ë‹µë³€ ìì—°í™”) - 0.5ì¼
    â†“
â¡ï¸ Phase B-1 (Qwen3) - 3-4ì¼
    â†“
â¡ï¸ Phase C (Citation 95%) - 3ì¼
    â†“
âœ… v4.0 ì™„ì„±
```

**ì´ ì˜ˆìƒ ê¸°ê°„**: 6.5-7.5ì¼

---

## ğŸ”— ì°¸ê³ 

- **NotebookLM**: ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ í˜•ì‹, Inline Citation
- **Perplexity AI**: "Cite every claim with a URL, or respond with 'I don't know.'"
- **OpenAI GPT-4**: Few-shot learning, Clear Instructions
- **RAG ì—°êµ¬**: Extractive answering, Document-grounded generation
