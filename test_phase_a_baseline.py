"""
Phase A Baseline í…ŒìŠ¤íŠ¸
Phase A êµ¬í˜„ ì „ í˜„ì¬ ì„±ëŠ¥ ì¸¡ì • (v3.1)

ëª©ì : Phase A ì ìš© ì „í›„ ë¹„êµë¥¼ ìœ„í•œ Baseline ë°ì´í„° ìˆ˜ì§‘
"""
import sys
import os
import json
import time
from datetime import datetime
from typing import List, Dict, Any

# UTF-8 ì¶œë ¥ ì„¤ì • (Windows ì½˜ì†” í˜¸í™˜)
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import ConfigManager
from utils.vector_store import VectorStoreManager
from utils.rag_chain import RAGChain


# í™•ì¥ëœ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„¸íŠ¸ (50ê°œ)
TEST_QUERIES = {
    "easy": {
        "technical": [
            "TADFë€ ë¬´ì—‡ì¸ê°€?",
            "OLEDë€?",
            "FRETë€ ë¬´ì—‡ì¸ê°€?",
            "EQEë€?",
            "Hyperfluorescenceë€?",
            "ACRSAë€ ë¬´ì—‡ì¸ê°€?",
            "DABNA1ì´ë€?",
            "kFRETëŠ” ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜?",
        ],
        "business": [
            "LGë””ìŠ¤í”Œë ˆì´ëŠ” ì–´ë–¤ íšŒì‚¬ì¸ê°€?",
            "OLED ì‹œì¥ ê·œëª¨ëŠ”?",
            "8.6ì„¸ëŒ€ OLEDë€?",
            "OLEDoSë€?",
        ],
        "hr": [
            "HRD-Netì´ë€?",
            "ì¶œê²°ê´€ë¦¬ ì‹œìŠ¤í…œì´ë€?",
            "í›ˆë ¨ìƒ ì¶œê²° ê´€ë¦¬ë€?",
        ],
    },
    "medium": [
        # Technical + ìˆ˜ì¹˜/ì„±ëŠ¥ ê´€ë ¨
        "TADF ì¬ë£Œì˜ ì–‘ì íš¨ìœ¨ì€ ì–¼ë§ˆì¸ê°€?",
        "FRET ì—ë„ˆì§€ ì „ë‹¬ íš¨ìœ¨ì€?",
        "kFRET ê°’ì€ ì–¼ë§ˆì¸ê°€?",
        "OLEDì˜ ì™¸ë¶€ ì–‘ì íš¨ìœ¨(EQE)ì€?",
        "Hyperfluorescence ê¸°ìˆ ì˜ í•µì‹¬ì€?",
        "TADF sensitizerì˜ ì—­í• ì€?",
        "ACRSAì˜ íŠ¹ì§•ì€?",
        "DABNA1ê³¼ ACRSAì˜ ì°¨ì´ëŠ”?",
        "CT ì—ë„ˆì§€ ë¶„ì‚°ì´ FRETì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
        "spiro-linkageì˜ ì—­í• ì€?",

        # Business + ê¸°ìˆ  ì—°ê²°
        "LGë””ìŠ¤í”Œë ˆì´ì˜ OLED ì‹œì¥ ë™í–¥ì€?",
        "8.6ì„¸ëŒ€ IT OLED ìƒì‚°ë¼ì¸ì€?",
        "LGë””ìŠ¤í”Œë ˆì´ì˜ OLED ê¸°ìˆ  ê²½ìŸë ¥ì€?",
        "LTPO ê¸°ìˆ ì´ë€?",
        "OLEDoS ê¸°ìˆ ì˜ ì¥ì ì€?",

        # HR ì‹œìŠ¤í…œ
        "HRD-Net ì¶œê²° ê´€ë¦¬ ë°©ë²•ì€?",
        "ì¶œê²°ê´€ë¦¬ ì•± ì„¤ì¹˜ ë°©ë²•ì€?",
        "HRD-Net ì•± ì‚¬ìš©ë²•ì€?",
        "ì¶œê²° QR ì½”ë“œ ìŠ¤ìº” ë°©ë²•ì€?",
        "ìë™ì‹œê°„ ì„¤ì •ì´ í•„ìš”í•œ ì´ìœ ëŠ”?",
    ],
    "hard": [
        # ë³µí•© ë„ë©”ì¸ ì§ˆë¬¸
        "TADF ì¬ë£Œì™€ OLED íš¨ìœ¨ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•´ì¤˜",
        "ë¶„ì êµ¬ì¡°ì™€ ì„±ëŠ¥ì˜ ê´€ê³„ëŠ”?",
        "FRET íš¨ìœ¨ê³¼ CT ì—ë„ˆì§€ì˜ ìƒê´€ê´€ê³„ëŠ”?",
        "Hyperfluorescenceê°€ OLED ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë©”ì»¤ë‹ˆì¦˜ì€?",

        # ë¹„êµ/ë¶„ì„ ì§ˆë¬¸
        "ACRSAì™€ DABNA1ì˜ ì„±ëŠ¥ì„ ë¹„êµí•´ì¤˜",
        "BM25ì™€ Vector ê²€ìƒ‰ì˜ ì°¨ì´ëŠ”?",
        "Small-to-Large ê²€ìƒ‰ê³¼ Standard ê²€ìƒ‰ì˜ ì¥ë‹¨ì ì€?",

        # ê¸°ìˆ +ë¹„ì¦ˆë‹ˆìŠ¤ í†µí•©
        "TADF ê¸°ìˆ  ë°œì „ì´ LGë””ìŠ¤í”Œë ˆì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
        "8.6ì„¸ëŒ€ IT OLED ìƒì‚°ë¼ì¸ì˜ íŠ¹ì§•ê³¼ LGë””ìŠ¤í”Œë ˆì´ ì „ëµì„ ì—°ê²°í•´ì„œ ì„¤ëª…í•´ì¤˜",
        "OLED ê¸°ìˆ  ë°œì „ì´ ë””ìŠ¤í”Œë ˆì´ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
    ],
}


def calculate_category_purity(query: str, categories: List[str]) -> float:
    """ì§ˆë¬¸ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ ìˆœë„ ê³„ì‚°

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        categories: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸

    Returns:
        ìˆœë„ ì ìˆ˜ (0-1)
    """
    if not categories:
        return 0.0

    # ì§ˆë¬¸ íƒ€ì… ì¶”ì •
    query_lower = query.lower()

    if any(kw in query_lower for kw in ['tadf', 'oled', 'fret', 'quantum', 'ì–‘ì', 'íš¨ìœ¨', 'eqe',
                                          'hyperfluorescence', 'acrsa', 'dabna', 'sensitizer',
                                          'ë¶„ì', 'êµ¬ì¡°', 'ct', 'ì—ë„ˆì§€']):
        expected = ['technical', 'business']  # ê¸°ìˆ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ì™€ ì—°ê²° ê°€ëŠ¥

    elif any(kw in query_lower for kw in ['lgë””ìŠ¤í”Œë ˆì´', 'ì‹œì¥', 'ë‰´ìŠ¤', 'ìƒì‚°', 'ë¼ì¸',
                                            'íˆ¬ì', 'ì „ëµ', 'oledo', 'ltpo']):
        expected = ['business', 'technical']  # ë¹„ì¦ˆë‹ˆìŠ¤ëŠ” ê¸°ìˆ ê³¼ ì—°ê²° ê°€ëŠ¥

    elif any(kw in query_lower for kw in ['hrd', 'ì¶œê²°', 'êµìœ¡', 'í›ˆë ¨', 'ì•±', 'ê´€ë¦¬',
                                            'qr', 'ìŠ¤ìº”']):
        expected = ['hr']

    elif any(kw in query_lower for kw in ['ì•ˆì „', 'ê·œì •', 'ìœ„í—˜', 'ë³´ê±´']):
        expected = ['safety']

    else:
        # íŒë‹¨ ë¶ˆê°€ëŠ¥ - ì¤‘ë¦½ì  í‰ê°€
        return 0.7

    # ìˆœë„ ê³„ì‚°
    match_count = sum(1 for c in categories if c in expected)
    purity = match_count / len(categories)

    return purity


def analyze_sources(sources: List[Dict[str, Any]], query: str) -> Dict[str, Any]:
    """ì¶œì²˜ ë¶„ì„

    Args:
        sources: RAG ì²´ì¸ì´ ë°˜í™˜í•œ ì¶œì²˜ ë¦¬ìŠ¤íŠ¸
        query: ì›ë³¸ ì§ˆë¬¸

    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    categories = []
    scores = []
    file_names = set()

    for source in sources:
        category = source.get('category', 'unknown')
        score = source.get('score', 0)
        file_name = source.get('file_name', 'unknown')

        categories.append(category)
        scores.append(score)
        file_names.add(file_name)

    # ì¹´í…Œê³ ë¦¬ ë¶„í¬
    category_dist = {}
    for cat in set(categories):
        count = categories.count(cat)
        category_dist[cat] = {
            'count': count,
            'percentage': count / len(categories) if categories else 0
        }

    # ì¹´í…Œê³ ë¦¬ ìˆœë„
    purity = calculate_category_purity(query, categories)

    return {
        'num_sources': len(sources),
        'unique_files': len(file_names),
        'categories': categories,
        'category_distribution': category_dist,
        'category_purity': purity,
        'avg_score': sum(scores) / len(scores) if scores else 0,
        'min_score': min(scores) if scores else 0,
        'max_score': max(scores) if scores else 0,
    }


def check_answer_quality(answer: str) -> Dict[str, Any]:
    """ë‹µë³€ í’ˆì§ˆ ì²´í¬

    Args:
        answer: ìƒì„±ëœ ë‹µë³€

    Returns:
        í’ˆì§ˆ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    # ì¸ë¼ì¸ ì¶œì²˜ í™•ì¸
    has_inline_citation = '[' in answer and ']' in answer
    citation_count = answer.count('[')

    # ê¸ˆì§€ êµ¬ë¬¸ ì²´í¬
    forbidden_phrases = [
        "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤",
        "í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ì œê³µëœ ë¬¸ì„œì—ì„œëŠ” í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    ]
    has_forbidden_phrase = any(phrase in answer for phrase in forbidden_phrases)
    found_forbidden = [phrase for phrase in forbidden_phrases if phrase in answer]

    # ë‹µë³€ êµ¬ì¡° í™•ì¸
    has_sections = '##' in answer  # Markdown ì„¹ì…˜ í—¤ë”
    has_list = any(marker in answer for marker in ['- ', '* ', '1.', '2.'])

    # ì°¸ì¡° ì •ë³´ ì„¹ì…˜ í™•ì¸
    has_reference_section = '## ì°¸ì¡° ì •ë³´' in answer or 'ì°¸ì¡° ì •ë³´' in answer

    return {
        'answer_length': len(answer),
        'has_inline_citation': has_inline_citation,
        'citation_count': citation_count,
        'has_forbidden_phrase': has_forbidden_phrase,
        'forbidden_phrases_found': found_forbidden,
        'has_sections': has_sections,
        'has_list': has_list,
        'has_reference_section': has_reference_section,
    }


def run_baseline_test():
    """Baseline ì„±ëŠ¥ ì¸¡ì • ì‹¤í–‰"""

    print("=" * 80)
    print("Phase A Baseline í…ŒìŠ¤íŠ¸ (v3.1)")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # ì„¤ì • ë¡œë“œ
    config = ConfigManager().get_all()

    # VectorStore ì´ˆê¸°í™”
    print("VectorStore ì´ˆê¸°í™” ì¤‘...")
    vector_manager = VectorStoreManager(
        persist_directory="data/chroma_db",
        embedding_api_type=config.get("embedding_api_type", "ollama"),
        embedding_base_url=config.get("embedding_base_url", "http://localhost:11434"),
        embedding_model=config.get("embedding_model", "nomic-embed-text"),
        embedding_api_key=config.get("embedding_api_key", ""),
    )

    # RAGChain ì´ˆê¸°í™”
    print("RAGChain ì´ˆê¸°í™” ì¤‘...")
    rag_chain = RAGChain(
        vectorstore=vector_manager,
        llm_api_type=config.get("llm_api_type", "ollama"),
        llm_base_url=config.get("llm_base_url", "http://localhost:11434"),
        llm_model=config.get("llm_model", "gemma3:latest"),
        llm_api_key=config.get("llm_api_key", ""),
        temperature=config.get("temperature", 0.3),
        top_k=config.get("top_k", 3),
        use_reranker=config.get("use_reranker", True),
        reranker_model=config.get("reranker_model", "multilingual-mini"),
        reranker_initial_k=config.get("reranker_initial_k", 20),
        enable_hybrid_search=config.get("enable_hybrid_search", True),
        hybrid_bm25_weight=config.get("hybrid_bm25_weight", 0.5),
    )
    print()

    # ê²°ê³¼ ì €ì¥ êµ¬ì¡°
    results = {
        "timestamp": datetime.now().isoformat(),
        "version": "v3.1 (before Phase A)",
        "config": {
            "llm_model": config.get("llm_model"),
            "embedding_model": config.get("embedding_model"),
            "top_k": config.get("top_k"),
            "use_reranker": config.get("use_reranker"),
            "enable_hybrid_search": config.get("enable_hybrid_search"),
        },
        "queries": {},
        "summary": {}
    }

    # ë‚œì´ë„ë³„ ì§‘ê³„
    difficulty_stats = {
        "easy": {"times": [], "purities": [], "citation_rates": [], "forbidden_rates": []},
        "medium": {"times": [], "purities": [], "citation_rates": [], "forbidden_rates": []},
        "hard": {"times": [], "purities": [], "citation_rates": [], "forbidden_rates": []},
    }

    # ì „ì²´ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    all_queries_list = []

    # Easy ì¿¼ë¦¬
    for category, queries in TEST_QUERIES["easy"].items():
        for query in queries:
            all_queries_list.append((query, "easy", category))

    # Medium ì¿¼ë¦¬
    for query in TEST_QUERIES["medium"]:
        all_queries_list.append((query, "medium", "mixed"))

    # Hard ì¿¼ë¦¬
    for query in TEST_QUERIES["hard"]:
        all_queries_list.append((query, "hard", "complex"))

    total_queries = len(all_queries_list)
    print(f"ì´ {total_queries}ê°œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")

    # ê° ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
    for idx, (query, difficulty, category_hint) in enumerate(all_queries_list, 1):
        print(f"\n{'='*80}")
        print(f"[{idx}/{total_queries}] ë‚œì´ë„: {difficulty.upper()}, ì¹´í…Œê³ ë¦¬: {category_hint}")
        print(f"ì§ˆë¬¸: {query}")
        print(f"{'='*80}")

        try:
            # ì„±ëŠ¥ ì¸¡ì •
            start_time = time.time()
            result = rag_chain.query(query)
            elapsed_time = time.time() - start_time

            # ê²°ê³¼ ì¶”ì¶œ
            answer = result.get("answer", "")
            sources = result.get("sources", [])

            # ë¶„ì„
            source_analysis = analyze_sources(sources, query)
            answer_quality = check_answer_quality(answer)

            # ì¶œë ¥
            print(f"\nâ±ï¸  ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            print(f"ğŸ“Š ì¶œì²˜: {source_analysis['num_sources']}ê°œ (íŒŒì¼ {source_analysis['unique_files']}ê°œ)")
            print(f"ğŸ“ ì¹´í…Œê³ ë¦¬ ë¶„í¬: {source_analysis['category_distribution']}")
            print(f"ğŸ¯ ì¹´í…Œê³ ë¦¬ ìˆœë„: {source_analysis['category_purity']:.1%}")
            print(f"â­ í‰ê·  ì‹ ë¢°ë„: {source_analysis['avg_score']:.1f}")
            print(f"ğŸ“ ë‹µë³€ ê¸¸ì´: {answer_quality['answer_length']}ì")
            print(f"ğŸ”— ì¸ë¼ì¸ ì¶œì²˜: {'âœ“' if answer_quality['has_inline_citation'] else 'âœ—'} ({answer_quality['citation_count']}ê°œ)")
            print(f"âš ï¸  ê¸ˆì§€ êµ¬ë¬¸: {'âœ— ë°œê²¬!' if answer_quality['has_forbidden_phrase'] else 'âœ“'}")

            if answer_quality['has_forbidden_phrase']:
                print(f"   ë°œê²¬ëœ êµ¬ë¬¸: {answer_quality['forbidden_phrases_found']}")

            # ê²°ê³¼ ì €ì¥
            query_result = {
                "query": query,
                "difficulty": difficulty,
                "category_hint": category_hint,
                "elapsed_time": elapsed_time,
                "source_analysis": source_analysis,
                "answer_quality": answer_quality,
                "answer_preview": answer[:200] + "..." if len(answer) > 200 else answer
            }

            results["queries"][f"query_{idx}"] = query_result

            # ë‚œì´ë„ë³„ ì§‘ê³„
            stats = difficulty_stats[difficulty]
            stats["times"].append(elapsed_time)
            stats["purities"].append(source_analysis['category_purity'])
            stats["citation_rates"].append(1 if answer_quality['has_inline_citation'] else 0)
            stats["forbidden_rates"].append(1 if answer_quality['has_forbidden_phrase'] else 0)

        except Exception as e:
            print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()

            results["queries"][f"query_{idx}"] = {
                "query": query,
                "difficulty": difficulty,
                "error": str(e)
            }

    # ìš”ì•½ í†µê³„ ê³„ì‚°
    print(f"\n\n{'='*80}")
    print("ğŸ“Š ìš”ì•½ í†µê³„")
    print(f"{'='*80}\n")

    for difficulty, stats in difficulty_stats.items():
        if not stats["times"]:
            continue

        avg_time = sum(stats["times"]) / len(stats["times"])
        avg_purity = sum(stats["purities"]) / len(stats["purities"])
        citation_rate = sum(stats["citation_rates"]) / len(stats["citation_rates"])
        forbidden_rate = sum(stats["forbidden_rates"]) / len(stats["forbidden_rates"])

        print(f"[{difficulty.upper()}] (n={len(stats['times'])})")
        print(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        print(f"  í‰ê·  ì¹´í…Œê³ ë¦¬ ìˆœë„: {avg_purity:.1%}")
        print(f"  ì¸ë¼ì¸ ì¶œì²˜ ë¹„ìœ¨: {citation_rate:.1%}")
        print(f"  ê¸ˆì§€ êµ¬ë¬¸ ì‚¬ìš© ë¹„ìœ¨: {forbidden_rate:.1%}")
        print()

        results["summary"][difficulty] = {
            "count": len(stats["times"]),
            "avg_response_time": avg_time,
            "avg_category_purity": avg_purity,
            "inline_citation_rate": citation_rate,
            "forbidden_phrase_rate": forbidden_rate,
        }

    # ì „ì²´ í†µê³„
    all_times = []
    all_purities = []
    all_citation_rates = []
    all_forbidden_rates = []

    for stats in difficulty_stats.values():
        all_times.extend(stats["times"])
        all_purities.extend(stats["purities"])
        all_citation_rates.extend(stats["citation_rates"])
        all_forbidden_rates.extend(stats["forbidden_rates"])

    if all_times:
        results["summary"]["overall"] = {
            "total_queries": len(all_times),
            "avg_response_time": sum(all_times) / len(all_times),
            "avg_category_purity": sum(all_purities) / len(all_purities),
            "inline_citation_rate": sum(all_citation_rates) / len(all_citation_rates),
            "forbidden_phrase_rate": sum(all_forbidden_rates) / len(all_forbidden_rates),
        }

        print(f"[OVERALL] (n={len(all_times)})")
        print(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {results['summary']['overall']['avg_response_time']:.2f}ì´ˆ")
        print(f"  í‰ê·  ì¹´í…Œê³ ë¦¬ ìˆœë„: {results['summary']['overall']['avg_category_purity']:.1%}")
        print(f"  ì¸ë¼ì¸ ì¶œì²˜ ë¹„ìœ¨: {results['summary']['overall']['inline_citation_rate']:.1%}")
        print(f"  ê¸ˆì§€ êµ¬ë¬¸ ì‚¬ìš© ë¹„ìœ¨: {results['summary']['overall']['forbidden_phrase_rate']:.1%}")

    # ê²°ê³¼ ì €ì¥
    os.makedirs("test_results", exist_ok=True)
    output_file = f"test_results/phase_a_baseline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*80}")
    print(f"âœ… Baseline í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {output_file}")
    print(f"â° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*80}\n")

    return results


if __name__ == "__main__":
    try:
        results = run_baseline_test()
        print("\ní…ŒìŠ¤íŠ¸ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n\nâŒ ì¹˜ëª…ì  ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
