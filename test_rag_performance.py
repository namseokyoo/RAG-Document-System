"""
RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ê¸°ì¡´ ì„ë² ë”© ì œê±° ë° í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì„ë² ë”©
- Reference ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ í‰ê°€
- ì„¸ì…˜ ë‚´ ì£¼ì œ ë³€ê²½ í…ŒìŠ¤íŠ¸ í¬í•¨
"""

import os
import json
import shutil
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

from config import ConfigManager
from utils.vector_store import VectorStoreManager
from utils.document_processor import DocumentProcessor
from utils.rag_chain import RAGChain
from utils.chat_history import ChatHistoryManager


class RAGPerformanceTester:
    """RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "config.json"):
        """ì´ˆê¸°í™”"""
        config_manager = ConfigManager()
        self.config = config_manager.config
        self.results = []
        self.test_start_time = None
        
        # ë””ë ‰í† ë¦¬ ì„¤ì •
        self.test_docs_dir = Path("data/test_documents")
        self.test_pptx_dir = Path("data/test_pptx")
        self.reference_pdf_path = self.test_docs_dir / "reference_result.json"
        self.reference_pptx_path = self.test_pptx_dir / "reference_result.json"
        self.output_dir = Path("test_results")
        self.output_dir.mkdir(exist_ok=True)
        
    def setup_test_environment(self, clear_existing: bool = True) -> bool:
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„"""
        print("\n" + "="*80)
        print("ğŸ“‹ Phase 1: í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„")
        print("="*80)
        
        try:
            # 1. ê¸°ì¡´ ì„ë² ë”© ì œê±° (ê°œë³„ ë¬¸ì„œ ì‚­ì œ ë°©ì‹)
            if clear_existing:
                print("\n[1/3] ê¸°ì¡´ ì„ë² ë”© ì œê±° ì¤‘...")
                try:
                    # ì„ì‹œ VectorStoreë¡œ ê¸°ì¡´ ë¬¸ì„œ ëª©ë¡ í™•ì¸
                    temp_vector_store = VectorStoreManager(
                        persist_directory="data/chroma_db",
                        embedding_api_type=self.config.get("embedding_api_type", "request"),
                        embedding_base_url=self.config.get("embedding_base_url", "http://localhost:11434"),
                        embedding_model=self.config.get("embedding_model", "mxbai-embed-large:latest"),
                        embedding_api_key=self.config.get("embedding_api_key", "")
                    )
                    existing_docs = temp_vector_store.get_documents_list()
                    if existing_docs:
                        print(f"  ê¸°ì¡´ ë¬¸ì„œ {len(existing_docs)}ê°œ ë°œê²¬, ê°œë³„ ì‚­ì œ ì¤‘...")
                        for doc in existing_docs:
                            try:
                                temp_vector_store.delete_document(doc['file_name'])
                                print(f"    - {doc['file_name']} ì‚­ì œ ì™„ë£Œ")
                            except Exception as e:
                                print(f"    - {doc['file_name']} ì‚­ì œ ì‹¤íŒ¨: {e}")
                        print(f"âœ… ê¸°ì¡´ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ")
                    else:
                        print(f"â„¹ï¸  ê¸°ì¡´ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    print(f"âš ï¸  ê¸°ì¡´ ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
            
            # 2. VectorStore ì´ˆê¸°í™”
            print("\n[2/3] VectorStore ì´ˆê¸°í™” ì¤‘...")
            self.vector_store = VectorStoreManager(
                persist_directory="data/chroma_db",
                embedding_api_type=self.config.get("embedding_api_type", "request"),
                embedding_base_url=self.config.get("embedding_base_url", "http://localhost:11434"),
                embedding_model=self.config.get("embedding_model", "mxbai-embed-large:latest"),
                embedding_api_key=self.config.get("embedding_api_key", "")
            )
            print("âœ… VectorStore ì´ˆê¸°í™” ì™„ë£Œ")
            
            # 3. DocumentProcessor ì´ˆê¸°í™”
            print("\n[3/3] DocumentProcessor ì´ˆê¸°í™” ì¤‘...")
            self.document_processor = DocumentProcessor(
                chunk_size=self.config.get("chunk_size", 1500),
                chunk_overlap=self.config.get("chunk_overlap", 400),
                enable_advanced_pdf_chunking=True,
                enable_advanced_pptx_chunking=True
            )
            print("âœ… DocumentProcessor ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ í™˜ê²½ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def embed_test_documents(self) -> bool:
        """í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì„ë² ë”©"""
        print("\n" + "="*80)
        print("ğŸ“š Phase 2: í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì„ë² ë”©")
        print("="*80)
        
        try:
            # PDF ë¬¸ì„œ ì„ë² ë”©
            print("\n[1/2] PDF ë¬¸ì„œ ì„ë² ë”© ì¤‘...")
            pdf_files = list(self.test_docs_dir.glob("*.pdf"))
            pdf_files = [f for f in pdf_files if f.name != "reference_result.json"]
            
            if not pdf_files:
                print("âš ï¸  PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            print(f"ğŸ“„ PDF íŒŒì¼ {len(pdf_files)}ê°œ ë°œê²¬")
            for pdf_file in pdf_files:
                print(f"  - {pdf_file.name}")
            
            for pdf_file in pdf_files:
                try:
                    print(f"\nğŸ“„ ì„ë² ë”© ì¤‘: {pdf_file.name}")
                    file_type = self.document_processor.get_file_type(pdf_file.name)
                    chunks = self.document_processor.process_document(
                        str(pdf_file), pdf_file.name, file_type
                    )
                    if chunks:
                        # ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
                        success = self.vector_store.add_documents(chunks)
                        if success:
                            print(f"  âœ… ì„±ê³µ: {len(chunks)}ê°œ ì²­í¬ ìƒì„± ë° ì„ë² ë”© ì™„ë£Œ")
                        else:
                            print(f"  âŒ ì‹¤íŒ¨: ë²¡í„°ìŠ¤í† ì–´ ì¶”ê°€ ì‹¤íŒ¨")
                    else:
                        print(f"  âŒ ì‹¤íŒ¨: ì²­í¬ ìƒì„± ì‹¤íŒ¨")
                except Exception as e:
                    print(f"  âŒ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
            
            # PPTX ë¬¸ì„œ ì„ë² ë”©
            print("\n[2/2] PPTX ë¬¸ì„œ ì„ë² ë”© ì¤‘...")
            pptx_files = list(self.test_pptx_dir.glob("*.pptx"))
            pptx_files = [f for f in pptx_files if f.name != "reference_result.json"]
            
            if not pptx_files:
                print("âš ï¸  PPTX íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            print(f"ğŸ“Š PPTX íŒŒì¼ {len(pptx_files)}ê°œ ë°œê²¬")
            for pptx_file in pptx_files:
                print(f"  - {pptx_file.name}")
            
            for pptx_file in pptx_files:
                try:
                    print(f"\nğŸ“Š ì„ë² ë”© ì¤‘: {pptx_file.name}")
                    file_type = self.document_processor.get_file_type(pptx_file.name)
                    chunks = self.document_processor.process_document(
                        str(pptx_file), pptx_file.name, file_type
                    )
                    if chunks:
                        # ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
                        success = self.vector_store.add_documents(chunks)
                        if success:
                            print(f"  âœ… ì„±ê³µ: {len(chunks)}ê°œ ì²­í¬ ìƒì„± ë° ì„ë² ë”© ì™„ë£Œ")
                        else:
                            print(f"  âŒ ì‹¤íŒ¨: ë²¡í„°ìŠ¤í† ì–´ ì¶”ê°€ ì‹¤íŒ¨")
                    else:
                        print(f"  âŒ ì‹¤íŒ¨: ì²­í¬ ìƒì„± ì‹¤íŒ¨")
                except Exception as e:
                    print(f"  âŒ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ì„ë² ë”© ê²€ì¦
            print("\n[ê²€ì¦] ì„ë² ë”©ëœ ë¬¸ì„œ í™•ì¸ ì¤‘...")
            documents = self.vector_store.get_documents_list()
            print(f"âœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì™„ë£Œ")
            for doc in documents:
                print(f"  - {doc['file_name']} ({doc['chunk_count']}ê°œ ì²­í¬)")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def load_reference_results(self) -> tuple:
        """Reference ê²°ê³¼ ë¡œë“œ"""
        pdf_ref = []
        pptx_ref = []
        
        try:
            if self.reference_pdf_path.exists():
                with open(self.reference_pdf_path, 'r', encoding='utf-8') as f:
                    pdf_ref = json.load(f)
                print(f"âœ… PDF Reference ê²°ê³¼ ë¡œë“œ: {len(pdf_ref)}ê°œ ì§ˆë¬¸")
        except Exception as e:
            print(f"âš ï¸  PDF Reference ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            if self.reference_pptx_path.exists():
                with open(self.reference_pptx_path, 'r', encoding='utf-8') as f:
                    pptx_ref = json.load(f)
                print(f"âœ… PPTX Reference ê²°ê³¼ ë¡œë“œ: {len(pptx_ref)}ê°œ ì§ˆë¬¸")
        except Exception as e:
            print(f"âš ï¸  PPTX Reference ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return pdf_ref, pptx_ref
    
    def test_pdf_documents(self, reference_results: List[Dict]) -> List[Dict]:
        """PDF ë¬¸ì„œ í…ŒìŠ¤íŠ¸"""
        print("\n" + "="*80)
        print("ğŸ“„ Phase 3: PDF ë¬¸ì„œ í…ŒìŠ¤íŠ¸")
        print("="*80)
        
        # RAGChain ì´ˆê¸°í™”
        rag_chain = RAGChain(
            vectorstore=self.vector_store,
            llm_api_type=self.config.get("llm_api_type", "request"),
            llm_base_url=self.config.get("llm_base_url", "http://localhost:11434"),
            llm_model=self.config.get("llm_model", "gemma3:latest"),
            llm_api_key=self.config.get("llm_api_key", ""),
            temperature=self.config.get("temperature", 0.3),
            top_k=self.config.get("top_k", 5),
            use_reranker=self.config.get("use_reranker", True),
            reranker_model=self.config.get("reranker_model", "multilingual-mini"),
            reranker_initial_k=self.config.get("reranker_initial_k", 40),
            enable_synonym_expansion=self.config.get("enable_synonym_expansion", True),
            enable_multi_query=self.config.get("enable_multi_query", False),
            multi_query_num=self.config.get("multi_query_num", 0)
        )
        
        results = []
        total = len(reference_results)
        
        print(f"\nğŸ“Š ì´ {total}ê°œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
        
        for idx, ref_item in enumerate(reference_results, 1):
            question = ref_item.get("ì§ˆë¬¸", ref_item.get("question", ""))
            expected_answer = ref_item.get("ë‹µë³€", ref_item.get("answer", ""))
            expected_sources = ref_item.get("ì¶œì²˜", ref_item.get("sources", []))
            
            if not question:
                continue
            
            print(f"[{idx}/{total}] ì§ˆë¬¸: {question[:60]}...")
            
            try:
                start_time = time.perf_counter()
                
                # RAG ì¿¼ë¦¬ ì‹¤í–‰
                result = rag_chain.query(question, chat_history=[])
                
                elapsed_time = time.perf_counter() - start_time
                
                answer = result.get("answer", "")
                sources = result.get("sources", [])
                confidence = result.get("confidence", 0.0)
                success = result.get("success", False)
                
                # ê²°ê³¼ ì €ì¥
                test_result = {
                    "question": question,
                    "expected_answer": expected_answer,
                    "expected_sources": expected_sources,
                    "actual_answer": answer,
                    "actual_sources": sources,
                    "confidence": confidence,
                    "success": success,
                    "elapsed_time": elapsed_time,
                    "question_type": "pdf",
                    "question_index": idx
                }
                
                results.append(test_result)
                
                if success:
                    print(f"  âœ… ì„±ê³µ ({elapsed_time:.2f}ì´ˆ, ì‹ ë¢°ë„: {confidence:.2f})")
                else:
                    print(f"  âŒ ì‹¤íŒ¨ ({elapsed_time:.2f}ì´ˆ)")
                
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {e}")
                results.append({
                    "question": question,
                    "error": str(e),
                    "question_type": "pdf",
                    "question_index": idx
                })
        
        return results
    
    def test_pptx_documents(self, reference_results: List[Dict]) -> List[Dict]:
        """PPTX ë¬¸ì„œ í…ŒìŠ¤íŠ¸"""
        print("\n" + "="*80)
        print("ğŸ“Š Phase 4: PPTX ë¬¸ì„œ í…ŒìŠ¤íŠ¸")
        print("="*80)
        
        # RAGChain ì´ˆê¸°í™”
        rag_chain = RAGChain(
            vectorstore=self.vector_store,
            llm_api_type=self.config.get("llm_api_type", "request"),
            llm_base_url=self.config.get("llm_base_url", "http://localhost:11434"),
            llm_model=self.config.get("llm_model", "gemma3:latest"),
            llm_api_key=self.config.get("llm_api_key", ""),
            temperature=self.config.get("temperature", 0.3),
            top_k=self.config.get("top_k", 5),
            use_reranker=self.config.get("use_reranker", True),
            reranker_model=self.config.get("reranker_model", "multilingual-mini"),
            reranker_initial_k=self.config.get("reranker_initial_k", 40),
            enable_synonym_expansion=self.config.get("enable_synonym_expansion", True),
            enable_multi_query=self.config.get("enable_multi_query", False),
            multi_query_num=self.config.get("multi_query_num", 0)
        )
        
        results = []
        total = len(reference_results)
        
        print(f"\nğŸ“Š ì´ {total}ê°œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
        
        for idx, ref_item in enumerate(reference_results, 1):
            question = ref_item.get("question", ref_item.get("ì§ˆë¬¸", ""))
            expected_answer = ref_item.get("answer", ref_item.get("ë‹µë³€", ""))
            expected_sources = ref_item.get("sources", ref_item.get("ì¶œì²˜", []))
            
            if not question:
                continue
            
            print(f"[{idx}/{total}] ì§ˆë¬¸: {question[:60]}...")
            
            try:
                start_time = time.perf_counter()
                
                # RAG ì¿¼ë¦¬ ì‹¤í–‰
                result = rag_chain.query(question, chat_history=[])
                
                elapsed_time = time.perf_counter() - start_time
                
                answer = result.get("answer", "")
                sources = result.get("sources", [])
                confidence = result.get("confidence", 0.0)
                success = result.get("success", False)
                
                # ê²°ê³¼ ì €ì¥
                test_result = {
                    "question": question,
                    "expected_answer": expected_answer,
                    "expected_sources": expected_sources,
                    "actual_answer": answer,
                    "actual_sources": sources,
                    "confidence": confidence,
                    "success": success,
                    "elapsed_time": elapsed_time,
                    "question_type": "pptx",
                    "question_index": idx
                }
                
                results.append(test_result)
                
                if success:
                    print(f"  âœ… ì„±ê³µ ({elapsed_time:.2f}ì´ˆ, ì‹ ë¢°ë„: {confidence:.2f})")
                else:
                    print(f"  âŒ ì‹¤íŒ¨ ({elapsed_time:.2f}ì´ˆ)")
                
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {e}")
                results.append({
                    "question": question,
                    "error": str(e),
                    "question_type": "pptx",
                    "question_index": idx
                })
        
        return results
    
    def test_topic_switching(self) -> List[Dict]:
        """ì„¸ì…˜ ë‚´ ì£¼ì œ ë³€ê²½ í…ŒìŠ¤íŠ¸"""
        print("\n" + "="*80)
        print("ğŸ”„ Phase 5: ì„¸ì…˜ ë‚´ ì£¼ì œ ë³€ê²½ í…ŒìŠ¤íŠ¸")
        print("="*80)
        
        # RAGChain ì´ˆê¸°í™”
        rag_chain = RAGChain(
            vectorstore=self.vector_store,
            llm_api_type=self.config.get("llm_api_type", "request"),
            llm_base_url=self.config.get("llm_base_url", "http://localhost:11434"),
            llm_model=self.config.get("llm_model", "gemma3:latest"),
            llm_api_key=self.config.get("llm_api_key", ""),
            temperature=self.config.get("temperature", 0.3),
            top_k=self.config.get("top_k", 5),
            use_reranker=self.config.get("use_reranker", True),
            reranker_model=self.config.get("reranker_model", "multilingual-mini"),
            reranker_initial_k=self.config.get("reranker_initial_k", 40),
            enable_synonym_expansion=self.config.get("enable_synonym_expansion", True),
            enable_multi_query=self.config.get("enable_multi_query", False),
            multi_query_num=self.config.get("multi_query_num", 0)
        )
        
        results = []
        
        # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: ì£¼ì œ ì „í™˜
        test_scenarios = [
            {
                "name": "OLED ì£¼ì œ â†’ í”„ë¡œì íŠ¸ ì£¼ì œ",
                "questions": [
                    "OLED íš¨ìœ¨ í–¥ìƒ ë°©ë²•ì€?",
                    "í”„ë¡œì íŠ¸ ê³„íšì„œì˜ 3ê°€ì§€ ì£¼ìš” ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                ]
            },
            {
                "name": "í”„ë¡œì íŠ¸ ì£¼ì œ â†’ OLED ì£¼ì œ",
                "questions": [
                    "í”„ë¡œì íŠ¸ ì˜ˆì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?",
                    "MIPSë€ ë¬´ì—‡ì¸ê°€?"
                ]
            },
            {
                "name": "ë™ì¼ ì£¼ì œ ì—°ì† ì§ˆë¬¸",
                "questions": [
                    "OLED íš¨ìœ¨ì€?",
                    "OLED íš¨ìœ¨ í–¥ìƒ ë°©ë²•ì€?",
                    "OLED íš¨ìœ¨ ì¸¡ì • ë°©ë²•ì€?"
                ]
            }
        ]
        
        print(f"\nğŸ“Š ì´ {len(test_scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
        
        chat_history = []
        
        for scenario_idx, scenario in enumerate(test_scenarios, 1):
            print(f"\n[ì‹œë‚˜ë¦¬ì˜¤ {scenario_idx}] {scenario['name']}")
            print("-" * 80)
            
            for q_idx, question in enumerate(scenario['questions'], 1):
                print(f"\n  ì§ˆë¬¸ {q_idx}: {question}")
                
                try:
                    start_time = time.perf_counter()
                    
                    # RAG ì¿¼ë¦¬ ì‹¤í–‰ (ì±„íŒ… ì´ë ¥ í¬í•¨)
                    result = rag_chain.query(question, chat_history=chat_history)
                    
                    elapsed_time = time.perf_counter() - start_time
                    
                    answer = result.get("answer", "")
                    sources = result.get("sources", [])
                    confidence = result.get("confidence", 0.0)
                    success = result.get("success", False)
                    
                    # ì±„íŒ… ì´ë ¥ ì—…ë°ì´íŠ¸
                    chat_history.append({"role": "user", "content": question})
                    chat_history.append({"role": "assistant", "content": answer})
                    
                    # ê²°ê³¼ ì €ì¥
                    test_result = {
                        "scenario": scenario['name'],
                        "question": question,
                        "question_index_in_scenario": q_idx,
                        "actual_answer": answer,
                        "actual_sources": sources,
                        "confidence": confidence,
                        "success": success,
                        "elapsed_time": elapsed_time,
                        "question_type": "topic_switching",
                        "chat_history_length": len(chat_history)
                    }
                    
                    results.append(test_result)
                    
                    if success:
                        print(f"    âœ… ì„±ê³µ ({elapsed_time:.2f}ì´ˆ, ì‹ ë¢°ë„: {confidence:.2f})")
                        # ê²€ìƒ‰ëœ íŒŒì¼ í™•ì¸
                        file_names = [s.get("file_name", "") for s in sources[:3]]
                        print(f"    ğŸ“ ê²€ìƒ‰ëœ íŒŒì¼ (ìƒìœ„ 3ê°œ): {', '.join(file_names)}")
                    else:
                        print(f"    âŒ ì‹¤íŒ¨ ({elapsed_time:.2f}ì´ˆ)")
                    
                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜: {e}")
                    results.append({
                        "scenario": scenario['name'],
                        "question": question,
                        "error": str(e),
                        "question_type": "topic_switching"
                    })
        
        return results
    
    def analyze_results(self, pdf_results: List[Dict], pptx_results: List[Dict], 
                       topic_results: List[Dict]) -> Dict[str, Any]:
        """ê²°ê³¼ ë¶„ì„"""
        print("\n" + "="*80)
        print("ğŸ“Š Phase 6: ê²°ê³¼ ë¶„ì„")
        print("="*80)
        
        analysis = {
            "timestamp": datetime.now().isoformat(),
            "pdf_results": {
                "total": len(pdf_results),
                "successful": len([r for r in pdf_results if r.get("success", False)]),
                "failed": len([r for r in pdf_results if "error" in r]),
                "avg_elapsed_time": sum([r.get("elapsed_time", 0) for r in pdf_results]) / len(pdf_results) if pdf_results else 0,
                "avg_confidence": sum([r.get("confidence", 0) for r in pdf_results]) / len(pdf_results) if pdf_results else 0
            },
            "pptx_results": {
                "total": len(pptx_results),
                "successful": len([r for r in pptx_results if r.get("success", False)]),
                "failed": len([r for r in pptx_results if "error" in r]),
                "avg_elapsed_time": sum([r.get("elapsed_time", 0) for r in pptx_results]) / len(pptx_results) if pptx_results else 0,
                "avg_confidence": sum([r.get("confidence", 0) for r in pptx_results]) / len(pptx_results) if pptx_results else 0
            },
            "topic_switching_results": {
                "total": len(topic_results),
                "successful": len([r for r in topic_results if r.get("success", False)]),
                "failed": len([r for r in topic_results if "error" in r]),
                "avg_elapsed_time": sum([r.get("elapsed_time", 0) for r in topic_results]) / len(topic_results) if topic_results else 0,
                "avg_confidence": sum([r.get("confidence", 0) for r in topic_results]) / len(topic_results) if topic_results else 0
            }
        }
        
        # ì „ì²´ í†µê³„
        all_results = pdf_results + pptx_results + topic_results
        analysis["overall"] = {
            "total": len(all_results),
            "successful": len([r for r in all_results if r.get("success", False)]),
            "failed": len([r for r in all_results if "error" in r]),
            "avg_elapsed_time": sum([r.get("elapsed_time", 0) for r in all_results]) / len(all_results) if all_results else 0,
            "avg_confidence": sum([r.get("confidence", 0) for r in all_results]) / len(all_results) if all_results else 0
        }
        
        # ì¶œë ¥
        print("\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
        print(f"\n  PDF ë¬¸ì„œ:")
        print(f"    - ì´ ì§ˆë¬¸: {analysis['pdf_results']['total']}")
        print(f"    - ì„±ê³µ: {analysis['pdf_results']['successful']}")
        print(f"    - ì‹¤íŒ¨: {analysis['pdf_results']['failed']}")
        print(f"    - í‰ê·  ì‘ë‹µ ì‹œê°„: {analysis['pdf_results']['avg_elapsed_time']:.2f}ì´ˆ")
        print(f"    - í‰ê·  ì‹ ë¢°ë„: {analysis['pdf_results']['avg_confidence']:.2f}")
        
        print(f"\n  PPTX ë¬¸ì„œ:")
        print(f"    - ì´ ì§ˆë¬¸: {analysis['pptx_results']['total']}")
        print(f"    - ì„±ê³µ: {analysis['pptx_results']['successful']}")
        print(f"    - ì‹¤íŒ¨: {analysis['pptx_results']['failed']}")
        print(f"    - í‰ê·  ì‘ë‹µ ì‹œê°„: {analysis['pptx_results']['avg_elapsed_time']:.2f}ì´ˆ")
        print(f"    - í‰ê·  ì‹ ë¢°ë„: {analysis['pptx_results']['avg_confidence']:.2f}")
        
        print(f"\n  ì£¼ì œ ë³€ê²½ í…ŒìŠ¤íŠ¸:")
        print(f"    - ì´ ì§ˆë¬¸: {analysis['topic_switching_results']['total']}")
        print(f"    - ì„±ê³µ: {analysis['topic_switching_results']['successful']}")
        print(f"    - ì‹¤íŒ¨: {analysis['topic_switching_results']['failed']}")
        print(f"    - í‰ê·  ì‘ë‹µ ì‹œê°„: {analysis['topic_switching_results']['avg_elapsed_time']:.2f}ì´ˆ")
        print(f"    - í‰ê·  ì‹ ë¢°ë„: {analysis['topic_switching_results']['avg_confidence']:.2f}")
        
        print(f"\n  ì „ì²´:")
        print(f"    - ì´ ì§ˆë¬¸: {analysis['overall']['total']}")
        print(f"    - ì„±ê³µ: {analysis['overall']['successful']}")
        print(f"    - ì‹¤íŒ¨: {analysis['overall']['failed']}")
        print(f"    - í‰ê·  ì‘ë‹µ ì‹œê°„: {analysis['overall']['avg_elapsed_time']:.2f}ì´ˆ")
        print(f"    - í‰ê·  ì‹ ë¢°ë„: {analysis['overall']['avg_confidence']:.2f}")
        
        return analysis
    
    def save_results(self, pdf_results: List[Dict], pptx_results: List[Dict], 
                    topic_results: List[Dict], analysis: Dict[str, Any]) -> str:
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"test_results_{timestamp}.json"
        
        results_data = {
            "analysis": analysis,
            "pdf_results": pdf_results,
            "pptx_results": pptx_results,
            "topic_switching_results": topic_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        return str(output_file)
    
    def run_all_tests(self, clear_existing: bool = True) -> str:
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.test_start_time = time.perf_counter()
        
        print("\n" + "="*80)
        print("[RAG] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*80)
        
        # Phase 1: í™˜ê²½ ì¤€ë¹„
        if not self.setup_test_environment(clear_existing):
            return None
        
        # Phase 2: ë¬¸ì„œ ì„ë² ë”©
        if not self.embed_test_documents():
            return None
        
        # Reference ê²°ê³¼ ë¡œë“œ
        pdf_ref, pptx_ref = self.load_reference_results()
        
        # Phase 3: PDF í…ŒìŠ¤íŠ¸
        pdf_results = []
        if pdf_ref:
            pdf_results = self.test_pdf_documents(pdf_ref)
        else:
            print("\nâš ï¸  PDF Reference ê²°ê³¼ê°€ ì—†ì–´ PDF í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        # Phase 4: PPTX í…ŒìŠ¤íŠ¸
        pptx_results = []
        if pptx_ref:
            pptx_results = self.test_pptx_documents(pptx_ref)
        else:
            print("\nâš ï¸  PPTX Reference ê²°ê³¼ê°€ ì—†ì–´ PPTX í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        
        # Phase 5: ì£¼ì œ ë³€ê²½ í…ŒìŠ¤íŠ¸
        topic_results = self.test_topic_switching()
        
        # Phase 6: ê²°ê³¼ ë¶„ì„
        analysis = self.analyze_results(pdf_results, pptx_results, topic_results)
        
        # Phase 7: ê²°ê³¼ ì €ì¥
        output_file = self.save_results(pdf_results, pptx_results, topic_results, analysis)
        
        total_time = time.perf_counter() - self.test_start_time
        print(f"\nâœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ)")
        
        return output_file


if __name__ == "__main__":
    tester = RAGPerformanceTester()
    output_file = tester.run_all_tests(clear_existing=True)
    
    if output_file:
        print(f"\nğŸ“„ ê²°ê³¼ íŒŒì¼: {output_file}")
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

