================================================================================
Phase 3 Day 3 회귀 테스트
================================================================================

실행 시간: 2025-11-12 17:02:35

[Config]
  diversity_penalty: 0.35
  enable_file_aggregation: True
  LLM: gpt-4o-mini
  Reranker: multilingual-mini

[테스트]
  총 테스트: 23개
  제외: conversation 테스트

[초기화] VectorStore 로드 중...
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 4자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[VectorStore] 임베딩 모델 차원: 1024
[VectorStore] BM25 인덱스 구축 완료: 8139개 문서
  ✓ VectorStore 로드 완료: 9.6초
[초기화] RAG Chain 로드 중...
[HybridRetriever] 초기화 완료 (BM25:0.5 / Vector:0.5)
[HybridRetriever] BM25 인덱스 구축 완료: 8139개 문서
  ✓ RAG Chain 로드 완료: 3.2초

================================================================================
테스트 실행 시작
================================================================================

================================================================================
[1/23] simple_001 (simple)
질문: OLED의 정의는?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 5 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 5 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 10자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED의 정의는?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] candidate_retrieval (fallback): 5.31s (candidates=60)
[Timing] final_rerank (fallback): 6.20s
[SCORE] 동적 Threshold: 4.6450 (top1=7.7417 × 0.6)
[ADAPTIVE] Default mode → max=20
[SCORE] Score-based 필터링: 31개 문서 제거 (threshold=4.6450)
       최종 선택: 9개 문서 (점수 범위: 7.7417 ~ 7.4217)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 6.20s (selected=7)
[Timing] context_standard total: 12.40s (mode=fallback, top_k=5)
[Timing] context retrieval (standard, type=general): 15.50s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 5 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 5 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=30
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 10자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED의 정의는?...' candidates={'vector': 60, 'bm25': 8139}, top_k=30
[Timing] candidate_retrieval (fallback): 1.95s (candidates=30)
[Timing] final_rerank (fallback): 0.72s
[SCORE] 동적 Threshold: 4.6450 (top1=7.7417 × 0.6)
[ADAPTIVE] Default mode → max=10
[SCORE] Score-based 필터링: 27개 문서 제거 (threshold=4.6450)
       최종 선택: 3개 문서 (점수 범위: 7.7417 ~ 7.6019)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 0.73s (selected=3)
[Timing] context_standard total: 3.60s (mode=fallback, top_k=5)
[Timing] context retrieval (standard, type=general): 5.41s
  [CITE] Citation 생성 중... (문서 3개)
    [OK] 문장 분리: 2개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 77자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 50자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 103자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 50자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 2/2개 문장
✓ 성공
  소요시간: 23.5초
  출처: 3개 (고유: 3개, Diversity: 100.0%)
  답변 길이: 331자

================================================================================
[2/23] simple_002 (simple)
질문: 페로브스카이트 태양전지는 무엇인가?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 19자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Timing] context retrieval (Small-to-Large, type=specific_info): 2.76s
[SEARCH] 구체적 정보 추출 모드: Small-to-Large 검색 (쿼리 타입: specific_info)
  [INFO] 카테고리 필터링 비활성화됨
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 19자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Timing] context retrieval (Small-to-Large, type=specific_info): 2.51s
[SEARCH] 구체적 정보 추출 모드: Small-to-Large 검색 (쿼리 타입: specific_info)
[WARN] 답변 검증 실패: 금지 구문 사용, 문서 내용과 불일치
[INFO] 문서 기반 재생성 시도...
[OK] 답변 재생성 완료
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 3개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 43자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 52자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 79자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 63자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 34자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 52자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 79자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 63자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 70자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 52자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 79자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 63자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 3/3개 문장
✓ 성공
  소요시간: 11.1초
  출처: 5개 (고유: 2개, Diversity: 40.0%)
  답변 길이: 377자

================================================================================
[3/23] simple_003 (simple)
질문: 그래핀의 주요 특성은?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 10 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 10 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 12자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 주요 특성은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] candidate_retrieval (fallback): 7.97s (candidates=60)
[Timing] final_rerank (fallback): 6.55s
[SCORE] 동적 Threshold: 5.0487 (top1=8.4146 × 0.6)
[ADAPTIVE] Default mode → max=20
[SCORE] Score-based 필터링: 30개 문서 제거 (threshold=5.0487)
       최종 선택: 10개 문서 (점수 범위: 8.4146 ~ 6.6459)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 6.55s (selected=8)
[Timing] context_standard total: 15.02s (mode=fallback, top_k=10)
[Timing] context retrieval (standard, type=general): 16.43s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 10 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 10 (기본: 5)
[REWRITE] 다중 쿼리 생성: 그래핀의 주요 특성은? → 4개 쿼리
[Timing] multi_query_generate: 2.32s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 12자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 주요 특성은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 14.37s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 13.82s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 26자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 물리적 및 화학적 특성은 무엇인가?",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 17.30s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 전기 전도성과 강도에 대한 이론적 설명",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 16.48s (docs=15)
[Timing] final_rerank (multi-query): 4.60s (candidates=41)
[STAT] 통계 기반 이상치 제거: 7개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.0487 (top1=8.4146 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 69.43s (mode=multi-query, docs=11)
[Timing] context retrieval (standard, type=general): 71.30s
[WARN] 답변 검증 실패: 문서 인용 부족, 문서 내용과 불일치
[INFO] 문서 기반 재생성 시도...
[OK] 답변 재생성 완료
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 5개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 46자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 45자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 87자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 80자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 5/5개 문장
✓ 성공
  소요시간: 100.0초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 701자

================================================================================
[4/23] normal_001 (normal)
질문: OLED 디바이스의 효율을 향상시키는 방법은?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 디바이스의 효율을 향상시키는 방법은? → 4개 쿼리
[Timing] multi_query_generate: 2.19s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 25자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 디바이스의 효율을 향상시키는 방법은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 11.71s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 13.63s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 디바이스의 발광 효율을 높이는 기술적 방법은 무엇인가?",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 13.34s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 기술의 효율성 향상에 대한 이론적 접근",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 14.12s (docs=15)
[Timing] final_rerank (multi-query): 4.51s (candidates=40)
[SCORE] 동적 Threshold: 4.9440 (top1=8.2399 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 60.03s (mode=multi-query, docs=16)
[Timing] context retrieval (standard, type=general): 61.51s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 디바이스의 효율을 향상시키는 방법은? → 4개 쿼리
[Timing] multi_query_generate: 2.95s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 25자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 디바이스의 효율을 향상시키는 방법은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 11.77s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 13.60s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 38자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 디바이스의 발광 효율을 높이는 기술적 접근법은 무엇인가?",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 13.46s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 30자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 기술의 효율성 향상에 대한 이론적 배경은?",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 14.21s (docs=15)
[Timing] final_rerank (multi-query): 4.34s (candidates=40)
[SCORE] 동적 Threshold: 4.9440 (top1=8.2399 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 60.88s (mode=multi-query, docs=16)
[Timing] context retrieval (standard, type=general): 62.58s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 5개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 109자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 97자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 68자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 5/5개 문장
✓ 성공
  소요시간: 134.2초
  출처: 5개 (고유: 2개, Diversity: 40.0%)
  답변 길이: 781자

================================================================================
[5/23] normal_002 (normal)
질문: 페로브스카이트 태양전지의 안정성 문제를 해결하는 방법은?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 30 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 30 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 31자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지의 안정성 문제를 해결하는 방법은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] candidate_retrieval (fallback): 8.60s (candidates=60)
[Timing] final_rerank (fallback): 6.04s
[SCORE] 동적 Threshold: 4.4181 (top1=7.3634 × 0.6)
[ADAPTIVE] Default mode → max=20
[SCORE] Score-based 필터링: 32개 문서 제거 (threshold=4.4181)
       최종 선택: 8개 문서 (점수 범위: 7.3634 ~ 5.3646)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 6.04s (selected=5)
[Timing] context_standard total: 15.36s (mode=fallback, top_k=30)
[Timing] context retrieval (standard, type=general): 17.32s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 30 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 30 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 31자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지의 안정성 문제를 해결하는 방법은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] candidate_retrieval (fallback): 7.13s (candidates=60)
[Timing] final_rerank (fallback): 6.27s
[SCORE] 동적 Threshold: 4.4181 (top1=7.3634 × 0.6)
[ADAPTIVE] Default mode → max=20
[SCORE] Score-based 필터링: 32개 문서 제거 (threshold=4.4181)
       최종 선택: 8개 문서 (점수 범위: 7.3634 ~ 5.3646)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 6.27s (selected=5)
[Timing] context_standard total: 15.02s (mode=fallback, top_k=30)
[Timing] context retrieval (standard, type=general): 16.48s
[WARN] 답변 검증 실패: 금지 구문 사용, 문서 내용과 불일치
[INFO] 문서 기반 재생성 시도...
[OK] 답변 재생성 완료
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 4개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 85자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 52자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 21자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 4/4개 문장
✓ 성공
  소요시간: 42.0초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 521자

================================================================================
[6/23] normal_003 (normal)
질문: 그래핀 기반 센서의 감도를 높이는 전략은?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 그래핀 기반 센서의 감도를 높이는 전략은? → 4개 쿼리
[Timing] multi_query_generate: 2.09s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 23자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 기반 센서의 감도를 높이는 전략은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 13.15s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 12.54s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 27자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 센서의 감도 향상을 위한 기술적 접근법",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 13.36s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 26자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 기반 센서의 감도 개선 이론 및 원리",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 13.30s (docs=15)
[Timing] final_rerank (multi-query): 4.26s (candidates=41)
[STAT] 통계 기반 이상치 제거: 7개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.1923 (top1=8.6539 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 59.37s (mode=multi-query, docs=11)
[Timing] context retrieval (standard, type=general): 61.03s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 그래핀 기반 센서의 감도를 높이는 전략은? → 4개 쿼리
[Timing] multi_query_generate: 2.49s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 23자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 기반 센서의 감도를 높이는 전략은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 15.30s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 13.79s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 30자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 기반 센서의 감도 향상을 위한 기술적 접근법",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 14.60s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 26자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 센서의 감도 개선에 대한 이론적 배경",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 13.38s (docs=15)
[Timing] final_rerank (multi-query): 4.57s (candidates=43)
[STAT] 통계 기반 이상치 제거: 7개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.1923 (top1=8.6539 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 64.62s (mode=multi-query, docs=11)
[Timing] context retrieval (standard, type=general): 66.59s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 6개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 57자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 81자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 87자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 59자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 58자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 71자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 6/6개 문장
✓ 성공
  소요시간: 137.7초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 869자

================================================================================
[7/23] complex_001 (complex)
질문: OLED와 QLED의 효율, 수명, 색재현율을 비교해줘
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 15 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 15 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED와 QLED의 효율, 수명, 색재현율을 비교해줘 → 4개 쿼리
[Timing] multi_query_generate: 2.53s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 30자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 QLED의 효율, 수명, 색재현율을 비교해줘...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[1/4]: 15.27s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[2/4]: 17.44s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 32자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 QLED의 에너지 효율성 및 수명 비교 분석",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[3/4]: 10.85s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 32자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 QLED의 색재현율 차이에 대한 이론적 고찰",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[4/4]: 9.26s (docs=15)
[Timing] final_rerank (multi-query): 2.96s (candidates=45)
[SCORE] 동적 Threshold: 4.7663 (top1=7.9439 × 0.6)
[ADAPTIVE] Default mode → max=30
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 58.82s (mode=multi-query, docs=13)
[Timing] context retrieval (standard, type=comparison): 61.14s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 15 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 15 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED와 QLED의 효율, 수명, 색재현율을 비교해줘 → 4개 쿼리
[Timing] multi_query_generate: 2.46s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 30자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 QLED의 효율, 수명, 색재현율을 비교해줘...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[1/4]: 10.09s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[2/4]: 10.95s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 36자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 QLED의 발광 효율, 수명, 색재현율 기술적 비교",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[3/4]: 9.71s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 34자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 QLED의 색재현율 및 수명에 대한 이론적 분석",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[4/4]: 10.84s (docs=15)
[Timing] final_rerank (multi-query): 2.41s (candidates=36)
[SCORE] 동적 Threshold: 4.7663 (top1=7.9439 × 0.6)
[ADAPTIVE] Default mode → max=30
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 46.85s (mode=multi-query, docs=12)
[Timing] context retrieval (standard, type=comparison): 48.53s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 11개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 61자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 48자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 44자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 137자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 55자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 65자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 59자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 45자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 53자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 108자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 42자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 11/11개 문장
✓ 성공
  소요시간: 126.5초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 1552자

================================================================================
[8/23] complex_002 (complex)
질문: 페로브스카이트 태양전지와 실리콘 태양전지의 장단점을 분석해줘
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 15 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 15 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트 태양전지와 실리콘 태양전지의 장단점을 분석해줘 → 4개 쿼리
[Timing] multi_query_generate: 2.11s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 33자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지와 실리콘 태양전지의 장단점을 분석해줘...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[1/4]: 11.45s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[2/4]: 10.98s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 45자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지의 기술적 장점과 실리콘 태양전지의 단점을 비교 분석해줘",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[3/4]: 11.53s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트와 실리콘 태양전지의 효율성 및 안정성 이론적 고찰",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[4/4]: 11.49s (docs=15)
[Timing] final_rerank (multi-query): 2.73s (candidates=42)
[STAT] 통계 기반 이상치 제거: 2개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 4.6793 (top1=7.7989 × 0.6)
[ADAPTIVE] Default mode → max=30
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 50.94s (mode=multi-query, docs=14)
[Timing] context retrieval (standard, type=general): 50.94s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트 태양전지와 실리콘 태양전지의 장단점을 분석해줘 → 4개 쿼리
[Timing] multi_query_generate: 3.88s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 33자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지와 실리콘 태양전지의 장단점을 분석해줘...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[1/4]: 11.73s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[2/4]: 11.14s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 39자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지의 기술적 장점과 실리콘 태양전지의 단점 분석",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[3/4]: 12.44s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 36자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트와 실리콘 태양전지의 에너지 변환 효율 개념 비교",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[4/4]: 12.25s (docs=15)
[Timing] final_rerank (multi-query): 2.65s (candidates=39)
[STAT] 통계 기반 이상치 제거: 1개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 4.6793 (top1=7.7989 × 0.6)
[ADAPTIVE] Default mode → max=30
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 54.64s (mode=multi-query, docs=12)
[Timing] context retrieval (standard, type=general): 54.65s
[WARN] 답변 검증 실패: 문서 인용 부족, 문서 내용과 불일치
[INFO] 문서 기반 재생성 시도...
[OK] 답변 재생성 완료
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 6개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 58자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 35자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 50자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 110자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 68자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 57자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 6/6개 문장
✓ 성공
  소요시간: 122.8초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 833자

================================================================================
[9/23] exhaustive_001 (exhaustive)
질문: OLED 관련 모든 연구를 요약해줘
================================================================================
[HybridRetriever] BM25 검색: 200개 결과
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 19자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[HybridRetriever] Vector 검색: 200개 결과
[HybridRetriever] 융합 완료: 100개 결과 (BM25:200, Vector:200)
✓ 성공
  소요시간: 0.4초
  출처: 0개 (고유: 0개, Diversity: 0.0%)
  답변 길이: 1004자

================================================================================
[10/23] exhaustive_002 (exhaustive)
질문: 그래핀 연구의 모든 응용 분야를 나열해줘
================================================================================
[HybridRetriever] BM25 검색: 1개 결과
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 22자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[HybridRetriever] Vector 검색: 200개 결과
[HybridRetriever] 융합 완료: 100개 결과 (BM25:1, Vector:200)
✓ 성공
  소요시간: 0.6초
  출처: 0개 (고유: 0개, Diversity: 0.0%)
  답변 길이: 1204자

================================================================================
[11/23] hybrid_001 (hybrid_search)
질문: OLED efficiency enhancement
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 27자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED efficiency enhancement...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] candidate_retrieval (fallback): 4.14s (candidates=60)
[Timing] final_rerank (fallback): 2.15s
[SCORE] 동적 Threshold: 5.2404 (top1=8.7341 × 0.6)
[ADAPTIVE] Default mode → max=20
[SCORE] Score-based 필터링: 20개 문서 제거 (threshold=5.2404)
       최종 선택: 20개 문서 (점수 범위: 8.7341 ~ 5.2888)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 2.15s (selected=19)
[Timing] context_standard total: 6.93s (mode=fallback, top_k=20)
[Timing] context retrieval (standard, type=general): 9.24s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED efficiency enhancement → 4개 쿼리
[Timing] multi_query_generate: 1.92s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 27자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED efficiency enhancement...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 6.34s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.30s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 발광 효율(luminous efficacy) 개선 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.70s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 21자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='유기발광다이오드의 광출력 향상 원리",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.76s (docs=15)
[Timing] final_rerank (multi-query): 3.52s (candidates=55)
[STAT] 통계 기반 이상치 제거: 5개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.2404 (top1=8.7341 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 38.03s (mode=multi-query, docs=14)
[Timing] context retrieval (standard, type=general): 39.70s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 7개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 61자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 359자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 83자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 359자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 81자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 359자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 76자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 359자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 64자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 359자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 75자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 359자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 77자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 62자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 359자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 7/7개 문장
✓ 성공
  소요시간: 57.3초
  출처: 5개 (고유: 2개, Diversity: 40.0%)
  답변 길이: 894자

================================================================================
[12/23] hybrid_002 (hybrid_search)
질문: 페로브스카이트 안정성
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트 안정성 → 4개 쿼리
[Timing] multi_query_generate: 3.61s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 11자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 안정성...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 8.69s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.30s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 23자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 구조의 안정성 향상 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.83s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 22자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트의 열역학적 안정성 개념",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.77s (docs=15)
[Timing] final_rerank (multi-query): 2.73s (candidates=42)
[STAT] 통계 기반 이상치 제거: 4개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.1345 (top1=8.5574 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 41.72s (mode=multi-query, docs=13)
[Timing] context retrieval (standard, type=general): 44.19s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트 안정성 → 4개 쿼리
[Timing] multi_query_generate: 2.39s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 11자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 안정성...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 8.94s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.40s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 24자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 소재의 구조적 안정성 연구",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.71s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 22자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트의 열역학적 안정성 개념",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.76s (docs=15)
[Timing] final_rerank (multi-query): 2.34s (candidates=36)
[STAT] 통계 기반 이상치 제거: 8개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.1131 (top1=8.5218 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 39.88s (mode=multi-query, docs=7)
[Timing] context retrieval (standard, type=general): 42.40s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 5개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 45자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 67자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 41자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 53자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 57자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 5/5개 문장
✓ 성공
  소요시간: 95.2초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 642자

================================================================================
[13/23] hybrid_003 (hybrid_search)
질문: 그래핀 electrical conductivity
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 그래핀 electrical conductivity → 4개 쿼리
[Timing] multi_query_generate: 2.24s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 27자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 electrical conductivity...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 6.68s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 10.04s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 23자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 전기 전도성 특성 및 메커니즘",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.98s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 24자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 전기 전도성 개념과 이론적 배경",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.73s (docs=15)
[Timing] final_rerank (multi-query): 3.08s (candidates=47)
[SCORE] 동적 Threshold: 2.0223 (top1=3.3706 × 0.6)
[ADAPTIVE] Default mode → max=20
[SCORE] Score-based 필터링: 12개 문서 제거 (threshold=2.0223)
       최종 선택: 8개 문서 (점수 범위: 3.3706 ~ 2.0701)
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 40.20s (mode=multi-query, docs=6)
[Timing] context retrieval (standard, type=general): 43.02s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 그래핀 electrical conductivity → 4개 쿼리
[Timing] multi_query_generate: 2.23s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 27자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀 electrical conductivity...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 6.67s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.37s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 24자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 전기 전도도 특성 및 측정 방법",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.73s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 24자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그래핀의 전기 전도성에 대한 이론적 이해",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.60s (docs=15)
[Timing] final_rerank (multi-query): 3.18s (candidates=45)
[SCORE] 동적 Threshold: 2.0223 (top1=3.3706 × 0.6)
[ADAPTIVE] Default mode → max=20
[SCORE] Score-based 필터링: 15개 문서 제거 (threshold=2.0223)
       최종 선택: 5개 문서 (점수 범위: 3.3706 ~ 2.2644)
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 38.30s (mode=multi-query, docs=4)
[Timing] context retrieval (standard, type=general): 40.61s
  [CITE] Citation 생성 중... (문서 4개)
    [OK] 문장 분리: 3개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 125자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 116자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 3/3개 문장
✓ 성공
  소요시간: 89.9초
  출처: 4개 (고유: 2개, Diversity: 50.0%)
  답변 길이: 528자

================================================================================
[14/23] citation_001 (citation)
질문: OLED 효율 향상 방법
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 효율 향상 방법 → 4개 쿼리
[Timing] multi_query_generate: 2.23s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 13자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 효율 향상 방법...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 5.38s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.14s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 발광 효율(luminous efficacy) 개선 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.46s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 21자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='유기발광다이오드의 광출력 향상 원리",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.54s (docs=15)
[Timing] final_rerank (multi-query): 2.87s (candidates=46)
[SCORE] 동적 Threshold: 5.2224 (top1=8.7041 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 36.19s (mode=multi-query, docs=14)
[Timing] context retrieval (standard, type=general): 39.48s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 효율 향상 방법 → 4개 쿼리
[Timing] multi_query_generate: 1.76s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 13자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 효율 향상 방법...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 5.41s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.05s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 발광 효율(luminous efficacy) 개선 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.41s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 21자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='유기발광다이오드의 광출력 향상 원리",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.57s (docs=15)
[Timing] final_rerank (multi-query): 2.95s (candidates=46)
[SCORE] 동적 Threshold: 5.2224 (top1=8.7041 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 35.78s (mode=multi-query, docs=14)
[Timing] context retrieval (standard, type=general): 37.32s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 6개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 55자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 95자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 65자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 95자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 121자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 97자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 6/6개 문장
✓ 성공
  소요시간: 85.6초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 983자

================================================================================
[15/23] citation_002 (citation)
질문: 페로브스카이트 안정성 개선
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트 안정성 개선 → 4개 쿼리
[Timing] multi_query_generate: 2.43s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 14자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 안정성 개선...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 8.55s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.11s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 25자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지의 안정성 향상 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.51s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 24자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 구조의 안정성 개념과 이론",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.58s (docs=15)
[Timing] final_rerank (multi-query): 2.51s (candidates=40)
[STAT] 통계 기반 이상치 제거: 4개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.0355 (top1=8.3926 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 39.18s (mode=multi-query, docs=15)
[Timing] context retrieval (standard, type=general): 40.48s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 30 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 30 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트 안정성 개선 → 4개 쿼리
[Timing] multi_query_generate: 2.81s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 14자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 안정성 개선...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 8.41s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.10s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 25자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 태양전지의 안정성 향상 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.47s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 26자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트 물질의 내구성 및 안정성 개념",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.48s (docs=15)
[Timing] final_rerank (multi-query): 2.43s (candidates=38)
[STAT] 통계 기반 이상치 제거: 6개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.0355 (top1=8.3926 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 39.22s (mode=multi-query, docs=13)
[Timing] context retrieval (standard, type=general): 41.72s
[WARN] 답변 검증 실패: 금지 구문 사용, 문서 내용과 불일치
[INFO] 문서 기반 재생성 시도...
[OK] 답변 재생성 완료
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 3개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 51자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 32자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 39자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 312자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 3/3개 문장
✓ 성공
  소요시간: 88.8초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 349자

================================================================================
[16/23] edge_001 (ambiguous)
질문: 그거 뭐였지?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 5 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 5 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=30
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그거 뭐였지?...' candidates={'vector': 60, 'bm25': 8139}, top_k=30
[Timing] candidate_retrieval (fallback): 3.00s (candidates=30)
[Timing] final_rerank (fallback): 1.90s
[SCORE] 동적 Threshold: 4.9150 (top1=8.1916 × 0.6)
[ADAPTIVE] Default mode → max=10
[SCORE] 최소 개수 보장: threshold 무시하고 3개 선택
[SCORE] Score-based 필터링: 27개 문서 제거 (threshold=4.9150)
       최종 선택: 3개 문서 (점수 범위: 8.1916 ~ -8.3566)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 1.90s (selected=3)
[Timing] context_standard total: 5.26s (mode=fallback, top_k=5)
[Timing] context retrieval (standard, type=general): 6.71s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 5 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 5 (기본: 5)
[Timing] synonym_expand: 0.00s
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=30
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='그거 뭐였지?...' candidates={'vector': 60, 'bm25': 8139}, top_k=30
[Timing] candidate_retrieval (fallback): 2.92s (candidates=30)
[Timing] final_rerank (fallback): 1.85s
[SCORE] 동적 Threshold: 4.9150 (top1=8.1916 × 0.6)
[ADAPTIVE] Default mode → max=10
[SCORE] 최소 개수 보장: threshold 무시하고 3개 선택
[SCORE] Score-based 필터링: 27개 문서 제거 (threshold=4.9150)
       최종 선택: 3개 문서 (점수 범위: 8.1916 ~ -8.3566)
[Timing] score_filtering: 0.00s
[Timing] deduplication: 1.85s (selected=3)
[Timing] context_standard total: 5.18s (mode=fallback, top_k=5)
[Timing] context retrieval (standard, type=general): 6.50s
[WARN] 답변 검증 실패: 문서 인용 부족, 문서 내용과 불일치
[INFO] 문서 기반 재생성 시도...
[OK] 답변 재생성 완료
  [CITE] Citation 생성 중... (문서 3개)
    [OK] 문장 분리: 3개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 50자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 84자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 45자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 66자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 3/3개 문장
✓ 성공
  소요시간: 19.4초
  출처: 3개 (고유: 2개, Diversity: 66.7%)
  답변 길이: 382자

================================================================================
[17/23] edge_002 (no_info)
질문: OLED의 양자 터널링 효과는?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED의 양자 터널링 효과는? → 4개 쿼리
[Timing] multi_query_generate: 2.32s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 17자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED의 양자 터널링 효과는?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 6.62s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.26s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED의 양자 터널링 효과에 대한 기술적 설명",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.20s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 26자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED에서의 양자 터널링 원리와 그 중요성",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.90s (docs=15)
[Timing] final_rerank (multi-query): 2.45s (candidates=40)
[STAT] 통계 기반 이상치 제거: 8개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.0878 (top1=8.4797 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 37.25s (mode=multi-query, docs=9)
[Timing] context retrieval (standard, type=general): 39.82s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED의 양자 터널링 효과는? → 4개 쿼리
[Timing] multi_query_generate: 2.45s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 17자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED의 양자 터널링 효과는?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 6.70s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.08s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED의 양자 터널링 효과에 대한 기술적 분석",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.30s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 29자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='양자 터널링이 OLED 기술에 미치는 이론적 영향",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 9.21s (docs=15)
[Timing] final_rerank (multi-query): 3.19s (candidates=45)
[STAT] 통계 기반 이상치 제거: 3개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 5.0878 (top1=8.4797 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 38.50s (mode=multi-query, docs=13)
[Timing] context retrieval (standard, type=general): 42.20s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 5개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 51자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 80자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 82자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 59자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 451자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 5/5개 문장
✓ 성공
  소요시간: 93.4초
  출처: 5개 (고유: 2개, Diversity: 40.0%)
  답변 길이: 688자

================================================================================
[18/23] edge_003 (no_info)
질문: 페로브스카이트의 초전도 현상은?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트의 초전도 현상은? → 4개 쿼리
[Timing] multi_query_generate: 3.69s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 17자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트의 초전도 현상은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 8.67s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.14s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트의 초전도 현상에 대한 기술적 분석",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.59s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 26자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트의 초전도성 개념과 이론적 배경",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.76s (docs=15)
[Timing] final_rerank (multi-query): 2.50s (candidates=38)
[STAT] 통계 기반 이상치 제거: 7개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 4.7448 (top1=7.9081 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 41.01s (mode=multi-query, docs=11)
[Timing] context retrieval (standard, type=general): 43.69s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: 페로브스카이트의 초전도 현상은? → 4개 쿼리
[Timing] multi_query_generate: 2.17s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 17자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트의 초전도 현상은?...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 8.49s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.18s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트의 초전도 현상에 대한 기술적 분석",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.58s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 31자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='페로브스카이트에서 나타나는 초전도 현상의 이론적 배경",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.65s (docs=15)
[Timing] final_rerank (multi-query): 2.51s (candidates=40)
[STAT] 통계 기반 이상치 제거: 8개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 4.7448 (top1=7.9081 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 38.97s (mode=multi-query, docs=10)
[Timing] context retrieval (standard, type=general): 41.10s
[WARN] 답변 검증 실패: 금지 구문 사용, 문서 내용과 불일치
[INFO] 문서 기반 재생성 시도...
[OK] 답변 재생성 완료
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 6개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 46자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 93자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 74자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 58자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 70자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 453자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 6/6개 문장
✓ 성공
  소요시간: 97.3초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 856자

================================================================================
[19/23] edge_004 (multi_condition)
질문: OLED 논문 중 2020년 이후이고 효율 20% 이상인 연구
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 30 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 30 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 논문 중 2020년 이후이고 효율 20% 이상인 연구 → 4개 쿼리
[Timing] multi_query_generate: 2.62s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 34자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 논문 중 2020년 이후이고 효율 20% 이상인 연구...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[1/4]: 17.73s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[2/4]: 16.12s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 39자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='2020년 이후 발표된 OLED 연구 중 효율이 20% 이상인 논문",...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[3/4]: 18.87s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 41자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 기술의 효율성 향상에 대한 이론적 접근: 2020년 이후 연구",...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[4/4]: 16.11s (docs=15)
[Timing] final_rerank (multi-query): 2.54s (candidates=40)
[SCORE] 동적 Threshold: 4.5357 (top1=7.5595 × 0.6)
[ADAPTIVE] Default mode → max=100
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 74.38s (mode=multi-query, docs=16)
[Timing] context retrieval (standard, type=general): 76.67s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 30 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 30 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 논문 중 2020년 이후이고 효율 20% 이상인 연구 → 4개 쿼리
[Timing] multi_query_generate: 3.09s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 34자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 논문 중 2020년 이후이고 효율 20% 이상인 연구...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[1/4]: 19.23s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[2/4]: 16.49s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 39자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='2020년 이후 발표된 OLED 연구 중 효율이 20% 이상인 논문",...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[3/4]: 18.62s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=150
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 45자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='유기발광다이오드(OLED)의 효율 향상에 관한 이론적 연구 (2020년 이후)",...' candidates={'vector': 300, 'bm25': 8139}, top_k=150
[Timing] retrieval[4/4]: 18.61s (docs=15)
[Timing] final_rerank (multi-query): 2.75s (candidates=42)
[SCORE] 동적 Threshold: 4.5357 (top1=7.5595 × 0.6)
[ADAPTIVE] Default mode → max=100
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 79.23s (mode=multi-query, docs=15)
[Timing] context retrieval (standard, type=general): 81.39s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 5개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 71자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 68자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 104자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 88자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 42자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 473자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 432자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 5/5개 문장
✓ 성공
  소요시간: 166.5초
  출처: 5개 (고유: 2개, Diversity: 40.0%)
  답변 길이: 752자

================================================================================
[20/23] perf_001 (performance)
질문: OLED 기술은 무엇인가?
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 14자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 60자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Timing] context retrieval (Small-to-Large, type=specific_info): 1.58s
[SEARCH] 구체적 정보 추출 모드: Small-to-Large 검색 (쿼리 타입: specific_info)
  [INFO] 카테고리 필터링 비활성화됨
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 14자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Timing] context retrieval (Small-to-Large, type=specific_info): 1.37s
[SEARCH] 구체적 정보 추출 모드: Small-to-Large 검색 (쿼리 타입: specific_info)
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 5개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 77자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 147자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 70자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 147자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 85자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 147자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 75자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 147자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 73자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 147자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 488자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 476자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 5/5개 문장
✓ 성공
  소요시간: 10.7초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 759자

================================================================================
[21/23] perf_002 (performance)
질문: OLED 효율 개선 방법
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 효율 개선 방법 → 4개 쿼리
[Timing] multi_query_generate: 2.05s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 13자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 효율 개선 방법...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 6.98s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.15s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 발광 효율(luminous efficacy) 개선 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.66s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 21자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='유기발광다이오드의 광출력 향상 원리",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.50s (docs=15)
[Timing] final_rerank (multi-query): 3.07s (candidates=48)
[SCORE] 동적 Threshold: 5.1714 (top1=8.6190 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 37.92s (mode=multi-query, docs=14)
[Timing] context retrieval (standard, type=general): 39.81s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 20 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 20 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED 효율 개선 방법 → 4개 쿼리
[Timing] multi_query_generate: 1.76s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 13자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 효율 개선 방법...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[1/4]: 6.85s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[2/4]: 8.06s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED 발광 효율(luminous efficacy) 개선 기술",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[3/4]: 8.43s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=60
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 21자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='유기발광다이오드의 광출력 향상 원리",...' candidates={'vector': 120, 'bm25': 8139}, top_k=60
[Timing] retrieval[4/4]: 8.56s (docs=15)
[Timing] final_rerank (multi-query): 3.11s (candidates=48)
[SCORE] 동적 Threshold: 5.1714 (top1=8.6190 × 0.6)
[ADAPTIVE] Default mode → max=20
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 37.30s (mode=multi-query, docs=14)
[Timing] context retrieval (standard, type=general): 39.28s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 7개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 39자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 108자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 89자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 97자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 56자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 99자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 163자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 455자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 7/7개 문장
✓ 성공
  소요시간: 88.7초
  출처: 5개 (고유: 3개, Diversity: 60.0%)
  답변 길이: 1047자

================================================================================
[22/23] perf_003 (performance)
질문: OLED와 LCD를 비교해줘
================================================================================
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 15 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 15 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED와 LCD를 비교해줘 → 4개 쿼리
[Timing] multi_query_generate: 1.61s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 15자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 LCD를 비교해줘...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[1/4]: 10.03s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[2/4]: 10.76s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 23자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 LCD의 기술적 차이점 분석",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[3/4]: 10.46s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 22자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 LCD의 장단점 개념 비교",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[4/4]: 10.23s (docs=15)
[Timing] final_rerank (multi-query): 2.44s (candidates=37)
[STAT] 통계 기반 이상치 제거: 5개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 4.7942 (top1=7.9903 × 0.6)
[ADAPTIVE] Default mode → max=30
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 46.09s (mode=multi-query, docs=13)
[Timing] context retrieval (standard, type=comparison): 47.67s
  [INFO] 카테고리 필터링 비활성화됨
[LLM-TOPK] 동적 top_k 결정: 15 (질문 유형 분석)
[SEARCH] 질문 특성 분석: top_k = 15 (기본: 5)
[REWRITE] 다중 쿼리 생성: OLED와 LCD를 비교해줘 → 4개 쿼리
[Timing] multi_query_generate: 1.77s (queries=4)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 15자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 LCD를 비교해줘...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[1/4]: 10.15s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 7자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='```json...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[2/4]: 10.77s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 28자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 LCD의 기술적 차이점은 무엇인가요?",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[3/4]: 10.53s (docs=15)
[SEARCH] 듀얼 DB 검색 모드: integrated, initial_k=80
[VectorStore] 공유 DB 비활성화 - 개인 DB만 검색
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 26자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Hybrid-RRF] query='OLED와 LCD의 기본 원리 및 개념 비교",...' candidates={'vector': 160, 'bm25': 8139}, top_k=80
[Timing] retrieval[4/4]: 10.32s (docs=15)
[Timing] final_rerank (multi-query): 2.35s (candidates=38)
[STAT] 통계 기반 이상치 제거: 5개 문서 필터링 (MAD 방식)
[SCORE] 동적 Threshold: 4.7942 (top1=7.9903 × 0.6)
[ADAPTIVE] Default mode → max=30
[Timing] score_filtering: 0.00s
[Timing] context_standard total: 46.45s (mode=multi-query, docs=13)
[Timing] context retrieval (standard, type=comparison): 48.74s
  [CITE] Citation 생성 중... (문서 5개)
    [OK] 문장 분리: 13개
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 56자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 67자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 54자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 56자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 37자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 47자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 72자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 56자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 96자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 96자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 47자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 347자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 500자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 69자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
    [OK] Citation 추가: 13/13개 문장
✓ 성공
  소요시간: 112.4초
  출처: 5개 (고유: 2개, Diversity: 40.0%)
  답변 길이: 1779자

================================================================================
[23/23] perf_004 (performance)
질문: OLED 연구 전체를 요약해줘
================================================================================
[HybridRetriever] BM25 검색: 200개 결과
[Embeddings] 요청 모델: mxbai-embed-large:latest
[Embeddings] 엔드포인트: http://localhost:11434/api/embeddings
[Embeddings] 텍스트 길이: 16자
[Embeddings] 응답 상태: 200
[Embeddings] 임베딩 성공: 1024차원
[HybridRetriever] Vector 검색: 200개 결과
[HybridRetriever] 융합 완료: 100개 결과 (BM25:200, Vector:200)
✓ 성공
  소요시간: 0.4초
  출처: 0개 (고유: 0개, Diversity: 0.0%)
  답변 길이: 909자

================================================================================
테스트 결과 분석
================================================================================

[전체]
  총 테스트: 23개
  성공: 23개 (100.0%)
  실패: 0개
  총 소요시간: 28.4분
  평균 소요시간: 74.1초/테스트

[Diversity 지표]
  평균 고유 문서: 2.26개
  Diversity Ratio: 48.6%
  Multi-doc 비율: 20/23 (87.0%)
  ✗ 평균 고유 문서 목표 미달 (< 2.5개)
  ✗ Diversity Ratio 목표 미달 (< 50%)
  ✓ Multi-doc 비율 목표 달성 (>= 60%)

달성한 보수적 목표: 1/3

[고유 문서 수 분포]
  0개 문서:  3회 ( 13.0%) ██████
  2개 문서:  8회 ( 34.8%) █████████████████
  3개 문서: 12회 ( 52.2%) ██████████████████████████

결과 저장: regression_test_day3_20251112_173112.json

================================================================================
회귀 테스트 완료
================================================================================
