# OC Papers - 엔지니어 보조 AI 시스템

> **사내망 논문 DB 기반 RAG 챗봇에서 엔지니어 보조 에이전트 AI로 진화**

**프로젝트 코드명**: OC Papers
**현재 버전**: v3.7.0 (2025-11-12)
**개발 기간**: 2024.10.14 - 현재
**상태**: ✅ 프로덕션 준비 완료

---

## 🗣️ 중요: 대화 언어

**이 프로젝트의 모든 대화는 한글로 진행합니다.**

- **개발 논의**: 한글 사용 (기술 용어는 영어 병기 가능)
- **코드 주석**: 한글 권장 (복잡한 로직 설명)
- **문서화**: 한글 우선 (필요시 영문 버전 별도 작성)
- **커밋 메시지**: 한글 사용 가능
- **이슈/PR**: 한글로 작성

**예외**:
- 코드 내 변수명, 함수명, 클래스명: 영어 사용 (PEP 8)
- 기술 문서 일부: 국제 협업 필요시 영어 사용

---

## 📋 프로젝트 개요

### 🎯 핵심 목적

**OC Papers**는 사내망 환경에서 논문 데이터베이스를 구축하고, 이를 기반으로 엔지니어들에게 정확하고 신뢰할 수 있는 정보를 제공하는 AI 챗봇 시스템입니다. 향후 논문뿐만 아니라 다양한 개발결과물(엑셀, 파워포인트, PDF, raw data 등)을 활용하여 **엔지니어를 보조하는 자율 에이전트 AI**로 발전시킬 계획입니다.

### 🌟 차별화 요소

1. **폐쇄망 최적화**: 외부 네트워크 없이 완전히 작동 (로컬 모델 캐시)
2. **정확한 인용 시스템**: 95% 이상의 citation coverage (NotebookLM 스타일)
3. **지능형 검색**: 질문 유형 자동 분류 및 exhaustive retrieval
4. **Vision-Augmented**: PPTX 슬라이드 이미지 분석으로 표/그래프 인식
5. **Dual DB 아키텍처**: 개인 DB + 공유 DB 통합 검색

### 📊 운영 환경 및 규모

#### 개발 환경
- **개발 LLM**: Gemma3:4b (Ollama, 집 환경 - 속도 느림)
- **운영 LLM**: Llama-4-scout (Request API, 사내 환경)
- **임베딩**: mxbai-embed-large (Ollama)

#### 예상 데이터 규모
- **논문 수**: 수백 여건 (단계적 확대)
- **주요 분야**: OLED 소자, 광학, 재료과학
- **DB 용량**: TBD (논문당 평균 10-20MB 예상 → 총 5-10GB)

#### 사용자 규모
- **Phase 1 (네트워크 폴더)**: 약 20명
- **Phase 2 (DB 서버)**: 수백 명 예상
- **동시 접속**: 최대 10-20명 예상

#### 운영 방식
- **피드백 수집**: 수동 수집 (향후 시스템 통합 검토)
- **모니터링**: 성능 로그 자동 수집
- **배포 방식**: 수동 배포 (당분간)
- **업데이트 주기**: 월 1-2회 (기능 추가 시)

---

## 🏗️ 현재 아키텍처 (v3.6.2)

### 📊 시스템 구조

```
┌─────────────────────────────────────────────────────────────┐
│                    PySide6 Desktop UI                        │
│          (System Tray | Settings | Chat History)            │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│                   RAG Chain (LCEL)                           │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   Question   │→ │   Hybrid     │→ │  Re-ranker   │      │
│  │  Classifier  │  │   Retrieval  │  │(multilingual)│      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  Small-to-   │→ │   Citation   │→ │  Streaming   │      │
│  │    Large     │  │   Generator  │  │   Response   │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│                Vector Store Layer                            │
│  ┌──────────────────┐         ┌──────────────────┐          │
│  │  Personal DB     │ ◄─────► │   Shared DB      │          │
│  │  (ChromaDB)      │         │   (ChromaDB)     │          │
│  └──────────────────┘         └──────────────────┘          │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│               Document Processing Layer                      │
│  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐            │
│  │  PDF   │  │  PPTX  │  │  DOCX  │  │  XLSX  │            │
│  │ Parser │  │ Vision │  │ Parser │  │ Parser │            │
│  └────────┘  └────────┘  └────────┘  └────────┘            │
└─────────────────────────────────────────────────────────────┘
```

### 🔧 기술 스택

#### Core Framework
- **UI**: PySide6 (Qt6), Streamlit
- **RAG**: LangChain 0.3+ (LCEL)
- **Vector DB**: ChromaDB (persistent local storage)
- **Python**: 3.10+

#### LLM & Embedding
- **Ollama**: 로컬 LLM 서버 (gemma3:4b, llama3, etc.)
- **OpenAI**: API 지원 (gpt-4o, gpt-4o-mini)
- **범용 API**: vLLM, FastChat 등 OpenAI 호환
- **Embedding**: mxbai-embed-large (Ollama)

#### Document Processing
- **PDF**: PyMuPDF, pdfplumber, pypdf
- **PowerPoint**: python-pptx + Windows COM (Vision 렌더링)
- **Excel**: openpyxl
- **Vision**: Pillow, pywin32 (Windows)

#### Retrieval & Ranking
- **Vector Search**: ChromaDB (HNSW)
- **Keyword Search**: BM25 (rank-bm25)
- **Re-ranker**: sentence-transformers (cross-encoder/ms-marco-MiniLM-L-6-v2)
- **Hybrid**: RRF (Reciprocal Rank Fusion)

---

## 🚀 주요 기능 (v3.6.0)

### 1️⃣ Phase A-3: 답변 검증 및 품질 보증
- ✅ **Answer Verification**: 답변 신뢰도 검증 (Citation coverage 기반)
- ✅ **Confidence Score**: 답변 품질 점수 표시
- ✅ **Fallback 전략**: 신뢰도 낮을 시 재검색

### 2️⃣ Phase B: 질문 분류 및 검색 최적화
- ✅ **Question Classifier**: 규칙 기반 + LLM 하이브리드 분류
  - 구체적 정보 (Specific Info)
  - 요약 (Summary)
  - 비교/대조 (Comparison)
  - 관계 분석 (Relationship)
- ✅ **적응형 Top-k**: 질문 유형별 최적 검색 개수 자동 결정
- ✅ **Exhaustive Retrieval**: "모든/전체" 키워드 감지 → 최대 100개 문서 검색

### 3️⃣ Phase C: Citation 95% 달성
- ✅ **다중 출처 지원**: 문장당 최대 2개 출처 인용
- ✅ **적응형 임계값**: 0.35-0.5 동적 조정
- ✅ **짧은 문장 최적화**: 10단어 이하 임계값 낮춤

### 4️⃣ Phase D: 답변 자연화
- ✅ **섹션 강제 구조 제거**: 자연스러운 답변 흐름
- ✅ **Inline Citation**: NotebookLM 스타일 인용 ([1], [2])
- ✅ **max_tokens 증가**: 4096으로 확대

### 5️⃣ Phase E: 품질 개선 (v3.5.0)
- ✅ **Score-based Filtering**: OpenAI 스타일 적응형 threshold
- ✅ **Re-ranker 통일**: multilingual-mini로 단일화
- ✅ **Hybrid Search 단순화**: 2단계 우선순위
- ✅ **Singleton 패턴**: Re-ranker 인스턴스 재사용

### 6️⃣ Vision-Augmented Chunking
- ✅ **PPTX 슬라이드 렌더링**: 표/그래프 자동 인식
- ✅ **Vision API 통합**: Ollama LLaVA, OpenAI Vision
- ✅ **일괄 처리**: PowerPoint 한 번만 열기

### 7️⃣ Small-to-Large 전략
- ✅ **구조 인식 청킹**: PDF/PPTX 구조 보존
- ✅ **컨텍스트 확장**: 800자 parent context
- ✅ **중복 제거**: 슬라이드/페이지 단위

---

## 📂 프로젝트 구조

```
RAG_for_OC_251014/
├── 📱 UI Layer
│   ├── desktop_app.py          # PySide6 데스크톱 앱 (메인)
│   ├── app.py                  # Streamlit 웹 앱 (선택)
│   └── ui/
│       ├── chat_widget.py      # 채팅 위젯
│       ├── settings_dialog.py  # 설정 다이얼로그
│       └── tray_icon.py        # 시스템 트레이
│
├── 🧠 RAG Core
│   └── utils/
│       ├── rag_chain.py        # RAG 체인 (LCEL)
│       ├── vector_store.py     # 벡터 스토어 관리
│       ├── document_processor.py # 문서 파싱
│       ├── reranker.py         # Re-ranker (cross-encoder)
│       ├── question_classifier.py # 질문 분류기
│       └── drive_scanner.py    # 공유 DB 스캐너
│
├── ⚙️ Configuration
│   ├── config.py               # 설정 관리자
│   ├── config.json             # 사용자 설정 (gitignore)
│   └── config.json.example     # 설정 템플릿
│
├── 🗄️ Database
│   ├── chroma_db/              # 개인 DB (로컬)
│   └── [shared_db]/            # 공유 DB (네트워크 드라이브)
│
├── 📦 Models (로컬 캐시)
│   ├── reranker-mini/          # Re-ranker 모델 (22MB)
│   └── tiktoken_cache/         # OpenAI tokenizer
│
├── 🧪 Tests
│   ├── test_phase2_verification.py  # Phase 2 검증
│   ├── test_phase2_integration.py   # Phase 2 통합
│   └── comprehensive_test.py        # 전체 시스템 테스트
│
├── 📚 Documentation
│   ├── README.md               # 사용자 가이드
│   ├── SYSTEM_QC_REPORT.md     # QC 보고서
│   ├── .CLAUDE.md              # 프로젝트 개요 (이 문서)
│   └── docs/
│       ├── PHASE2_COMPLETION_SUMMARY.md
│       ├── QUESTION_CLASSIFIER_GUIDE.md
│       └── phase_d_implementation_plan.md
│
└── 🔧 Build & Deploy
    ├── RAG_System_v3.6.0.spec  # PyInstaller 스펙
    └── dist/RAG_System_v3.6.0/ # 빌드 결과물
```

---

## 🗺️ 향후 발전 방향 (로드맵)

### 🔧 Phase 2.5: PDF/PPTX 개선 및 시스템 최적화 (Phase 3 준비)
**목표**: 기존 문서 처리 품질 향상 및 운영 안정화
**예상 소요 시간**: 1.5-2주
**우선순위**: High

#### 2.5.1 Question Classifier 로깅 시스템
- [ ] **분류 기록 로깅**: JSONL 형식으로 모든 분류 기록 저장
  ```python
  # logs/classifier_history.jsonl
  {"timestamp": "2025-01-09T14:32:11", "query": "...", "type": "summary", "confidence": 0.85}
  ```
- [ ] **분석 도구 개발**: 로그 분석 스크립트 (타입별 분포, 낮은 신뢰도 케이스)
- [ ] **터미널 실시간 출력**: verbose 모드 시 분류 결과 출력
- [ ] **성능 지표 추적**: 평균 신뢰도, 오분류율 모니터링

**예상 소요 시간**: 1일

#### 2.5.2 PDF 그래프/표 Vision 처리
- [ ] **PyMuPDF 이미지 추출**: PDF 페이지별 이미지 자동 감지
- [ ] **GPT-4o Vision 분석**: 그래프/표 이미지 → 검색 가능한 텍스트 변환
  - 이미지 타입 식별 (그래프/표/도식)
  - 축 제목, 범례, 데이터 트렌드 추출
  - 수치 정보 텍스트화
- [ ] **오프라인 대안 검토**: Tesseract OCR + Camelot 표 추출 (비용 절감)
- [ ] **비용 최적화**: 이미지 크기 512x512 다운샘플링 (비용 50% 절감)
- [ ] **청킹 전략**: 이미지 설명을 해당 페이지 텍스트 청크와 병합

**예상 소요 시간**: 3-4일
**비용 추정**: 100페이지 논문 평균 5개 이미지 → $3.19 (512x512 기준)

#### 2.5.3 Exhaustive Retrieval 자동 감지
- [ ] **쿼리 복잡도 분석기**: LLM 기반 쿼리 범위 사전 판단
  - narrow (특정 정보) → top_k=3
  - medium (비교/관계) → top_k=10
  - broad (포괄 조사) → exhaustive retrieval (top_k=100)
- [ ] **Question Classifier 확장**: 기존 분류기에 `scope` 속성 추가
- [ ] **키워드 독립적 판단**: "모든/전체" 없이도 자동 감지
- [ ] **로깅 및 검증**: 자동 감지 정확도 추적

**예상 소요 시간**: 2-3일

#### 2.5.4 ChromaDB 동시 접속 대응
- [ ] **읽기 전용 공유 DB 모드**:
  ```python
  VectorStoreManager(mode="readonly")  # 공유 DB
  VectorStoreManager(mode="readwrite") # 개인 DB
  ```
- [ ] **파일 잠금 처리**: 쓰기 작업 시 `.lock` 파일 생성 (타임아웃 10초)
- [ ] **동시 접속 테스트**: 여러 사용자 시뮬레이션 테스트
- [ ] **운영 가이드 작성**: 공유 DB 업데이트 프로세스 문서화
  - 공유 DB: 관리자만 주기적 업데이트 (주 1회)
  - 개인 DB: 자유롭게 추가/삭제
  - 통합 검색: 중복 제거 로직 (공유 DB 우선)

**예상 소요 시간**: 1-2일

#### 2.5.5 성능 모니터링 및 로깅 시스템
- [ ] **응답 시간 측정 로깅**: 각 단계별 소요 시간 기록
  ```python
  # logs/performance_history.jsonl
  {
    "timestamp": "2025-01-09T14:32:11",
    "query": "...",
    "total_time_ms": 3500,
    "breakdown": {
      "retrieval_ms": 800,
      "reranking_ms": 1200,
      "llm_generation_ms": 1400,
      "context_expansion_ms": 100
    },
    "llm_model": "llama-4-scout",
    "num_docs_retrieved": 60,
    "num_docs_reranked": 60,
    "final_docs": 5
  }
  ```
- [ ] **병목 지점 자동 감지**: 3초 이상 소요 시 경고 로그
- [ ] **성능 대시보드**: 평균 응답 시간, 병목 단계 시각화 (선택)
- [ ] **메모리 사용량 추적**: Re-ranker, LLM 메모리 프로파일링

**예상 소요 시간**: 1일

#### 2.5.6 메타데이터 기반 검색 아키텍처 (Metadata-based Search)
**배경**: "김철수 저자의 논문 요약해줘" 같은 메타데이터 쿼리는 기존 의미론적 검색으로 부족
**목표**: 상용 서비스(Semantic Scholar, Perplexity) 수준의 메타데이터 검색 구현

- [ ] **PDF 메타데이터 자동 추출 파이프라인**:
  - GROBID 또는 PyPDF2 기반 메타데이터 추출
  - 저자명, 소속, 제목, 저널, 연도, DOI 자동 파싱
  - 첫 2페이지 정규식 매칭으로 저자/소속 추출 (GROBID 설치 어려운 경우)

- [ ] **ChromaDB 메타데이터 필드 확장**:
  ```python
  metadata = {
      "source": "paper.pdf",
      "page": 1,
      "authors": ["김철수", "이영희"],        # NEW
      "author_affiliations": ["LG Display"],  # NEW
      "title": "OLED 효율 향상 연구",         # NEW
      "journal": "Nature Photonics",          # NEW
      "year": 2024,                            # NEW
      "doi": "10.1038/...",                    # NEW
  }
  ```
  - DB 재구축 필요 (메타데이터 추가)
  - 기존 문서 재처리 스크립트 작성

- [ ] **Question Classifier 메타데이터 쿼리 타입 추가**:
  ```python
  # 새로운 쿼리 타입
  "metadata_search": {
      "description": "저자명, 제목, 기관 등으로 논문 검색",
      "keywords": ["저자", "작성자", "소속", "제목", "저널"],
      "examples": [
          "김철수가 쓴 논문 찾아줘",
          "LG Display 소속 연구자의 OLED 논문",
          "Nature에 실린 최신 연구"
      ]
  }
  ```

- [ ] **하이브리드 검색 전략 구현**:
  ```python
  # 2단계 검색
  if query_type == "metadata_search":
      # Stage 1: 메타데이터 필터링
      papers = vectorstore.get(
          where={"authors": {"$contains": "김철수"}}
      )

      # Stage 2: 필터링된 논문의 모든 청크 로드
      all_chunks = []
      for paper_id in papers:
          chunks = load_all_chunks_from_paper(paper_id)
          all_chunks.extend(chunks)

      # Stage 3: LLM에 전달하여 요약
      summary = llm.summarize(all_chunks)
  ```

- [ ] **상용 서비스 벤치마크 분석 문서 작성**:
  - `docs/METADATA_SEARCH_ANALYSIS.md` 생성
  - Semantic Scholar, Perplexity, Elicit 아키텍처 분석
  - Query Router, Fusion Ranking, Knowledge Graph 개념 정리
  - 현재 프로젝트 적용 방안 로드맵

**예상 소요 시간**: 3-5일
**우선순위**: Medium-High (사용자 요구사항 반영)

#### 2.5.7 사용자 피드백 시스템 (옵션)
- [ ] **답변 평가 UI**: 👍/👎 버튼 추가 (PySide6 ChatWidget)
- [ ] **피드백 로그 수집**:
  ```python
  # logs/user_feedback.jsonl
  {
    "timestamp": "2025-01-09T14:32:11",
    "query": "...",
    "answer": "...",
    "rating": "positive" | "negative",
    "user_comment": "...",
    "sources_used": [...]
  }
  ```
- [ ] **부정 피드백 알림**: 오답 케이스 자동 수집
- [ ] **주간 피드백 리포트**: 자동 생성 스크립트

**예상 소요 시간**: 2일 (선택 사항)

**Phase 2.5 완료 조건**:
- ✅ Question Classifier 로그 1주일 수집 완료
- ✅ PDF Vision 처리 샘플 테스트 (10개 논문)
- ✅ Exhaustive Retrieval 자동 감지 정확도 80% 이상
- ✅ ChromaDB 동시 접속 3명 이상 테스트 통과
- ✅ 성능 로깅 1주일 수집 완료
- ✅ 평균 응답 시간 5초 이하 달성 (Llama-4-scout 기준)
- ✅ 메타데이터 검색 기본 기능 구현 (저자명 검색)

---

### 🎯 Phase 3: 검색 품질 및 응답 전략 개선 (2025 W46)
**목표**: 검색 다양성 향상 및 지능형 응답 전략 구현
**상태**: 🔄 진행 중 (Day 2 완료)

#### ✅ Day 1: File-level Retrieval & Response Strategy Selector (완료)
**날짜**: 2025-11-12
**소요 시간**: 4시간

**구현 내용**:
1. **FileAggregator 클래스 개발**
   - WEIGHTED 전략: 청크 점수 합산 → 파일 수준 점수 산출
   - COUNT 전략: 청크 개수 기반 (backup)
   - 파일별 청크 집계 및 정렬

2. **Response Strategy Selector**
   - Exhaustive query 자동 감지 (키워드: "모든", "전체", "찾아줘" 등)
   - 일반 쿼리: 기존 RAG 플로우 (top_k=5)
   - Exhaustive 쿼리: 파일 리스트 형식 응답 (top_k=100)
   - 분기 로직: `_is_exhaustive_query()` → `_handle_exhaustive_query()`

3. **파일 리스트 응답 포맷**
   ```markdown
   | 순위 | 파일명 | 관련도 | 청크 수 |
   |------|--------|--------|---------|
   | 1    | paper1.pdf | 95.2% | 15 |
   | 2    | paper2.pdf | 87.3% | 12 |
   ```

**완료 지표**:
- ✅ 코드 구현 완료 (utils/file_aggregator.py 추가)
- ✅ RAGChain 통합 (utils/rag_chain.py 수정)
- ✅ config.json 파라미터 추가 (enable_file_aggregation, file_aggregation_strategy 등)

**미완료 사항** (당시 발견 못함):
- ⚠️ enable_file_aggregation=false로 설정되어 실제 작동 안 함 → Day 2에서 발견

---

#### ✅ Day 2: Diversity Penalty 검증 및 Config 최적화 (완료)
**날짜**: 2025-11-12
**소요 시간**: 6시간 (테스트 2시간 + 분석 4시간)

**테스트 실행**:
- **방법**: Comprehensive Test (40개 케이스, OpenAI gpt-4o-mini)
- **성공률**: 87.5% (35/40 성공, 5개 conversation 실패)
- **LLM**: gpt-4o-mini (속도 개선: 2-3x faster than Ollama)

**Diversity 검증 결과**:
```
목표 지표 (diversity_penalty=0.3):
├─ 평균 고유 문서: 2.5개 목표 → 2.40개 달성 (❌ -4.0%)
├─ Diversity Ratio: 50% 목표 → 53.3% 달성 (✅ +6.6%)
└─ Multi-doc 비율: 60% 목표 → 97.1% 달성 (✅ +61.8%)

판정: 3개 중 2개 목표 달성 (부분 성공)
```

**중요 발견사항**: ⚠️ **Exhaustive Query 기능 미작동**
1. **원인 규명**:
   ```python
   # config_test.json
   "enable_file_aggregation": false  ← 비활성화!

   # utils/rag_chain.py:2001
   if self.enable_file_aggregation and self._is_exhaustive_query(question):
       return self._handle_exhaustive_query(...)  ← 조건 false로 통과 안 됨
   ```

2. **영향 분석**:
   - 3개 exhaustive query 테스트가 모두 **일반 RAG 답변**으로 처리됨
   - "모든 OLED 논문 찾아줘" → 파일 리스트 대신 **내용 요약** 반환
   - Phase 3 Day 1 기능이 **검증되지 않음**

3. **문서화**:
   - [EXHAUSTIVE_QUERY_ANALYSIS.md](EXHAUSTIVE_QUERY_ANALYSIS.md) 작성
   - [DAY2_VERIFICATION_FINAL_REPORT.md](DAY2_VERIFICATION_FINAL_REPORT.md) 작성

**Config 최적화**:
```json
{
  "diversity_penalty": 0.35,        // 0.3 → 0.35 (+16.7%)
  "enable_file_aggregation": true   // false → true (활성화!)
}
```

**조정 근거**:
1. **diversity_penalty 증가**: 평균 고유 문서 2.40 → 2.6개 목표
   - 동일 파일 2회 등장: 70% → 65% 점수
   - 동일 파일 3회 등장: 40% → 30% 점수

2. **file_aggregation 활성화**: Exhaustive query 기능 작동
   - Response Strategy Selector 활성화
   - 사용자 기대 충족 ("파일 리스트" 반환)

**완료 지표**:
- ✅ Diversity 정량 평가 완료 (40개 케이스)
- ✅ Config 조정 근거 문서화 ([CONFIG_ADJUSTMENT_SUMMARY.md](CONFIG_ADJUSTMENT_SUMMARY.md))
- ✅ Exhaustive query 미작동 원인 규명
- ✅ ChromaDB 복구 및 재임베딩 진행 중 (34개 문서)

---

#### ⏳ Day 3: 회귀 테스트 및 성능 벤치마킹 (예정)
**예상 소요 시간**: 3-4시간

**계획**:
1. **Config 검증 테스트**
   - diversity_penalty=0.35 효과 측정
   - enable_file_aggregation=true 동작 확인
   - Exhaustive query 파일 리스트 형식 검증

2. **회귀 테스트**
   - 기존 35개 테스트 케이스 재실행
   - 성능 저하 없는지 확인 (평균 응답 시간)
   - Citation coverage 유지 확인 (95% 이상)

3. **성능 벤치마킹**
   - 일반 쿼리 vs Exhaustive 쿼리 소요 시간 비교
   - Diversity Ratio 분포 분석
   - 파일 집계 오버헤드 측정

4. **문서화**
   - Phase 3 완료 보고서 작성
   - v3.7.0 릴리즈 노트 작성

**완료 조건**:
- ✅ Diversity Ratio 55% 이상 달성
- ✅ 평균 고유 문서 2.5개 이상 달성
- ✅ Exhaustive query 파일 리스트 정확도 90% 이상
- ✅ 회귀 테스트 통과 (100% 성공률)
- ✅ 문서화 완료

---

### 🎯 Phase 4: 다양한 문서 형식 지원 확대 (2025 Q1)
**목표**: 논문 외 개발결과물 통합

#### 4.1 고급 엑셀 처리
- [ ] **복잡한 표 구조 이해**: 병합 셀, 다층 헤더
- [ ] **수식 및 계산 보존**: Excel 수식 그대로 저장
- [ ] **차트 데이터 추출**: 그래프 → 텍스트 변환
- [ ] **시트 간 관계 분석**: 참조 관계 파악

#### 4.2 Raw Data 지원
- [ ] **CSV/TSV 파서**: 대용량 데이터 청킹
- [ ] **JSON/YAML**: 구조화된 데이터 임베딩
- [ ] **Parquet**: 컬럼 기반 저장 형식
- [ ] **데이터 스키마 인식**: 자동 필드 감지

#### 4.3 코드 및 로그 파일
- [ ] **Python/C++/Java**: 코드 구조 파싱
- [ ] **로그 파일 분석**: 에러 패턴 인식
- [ ] **실험 결과 매핑**: 코드 ↔ 결과 연결

**예상 소요 시간**: 3-4주
**우선순위**: High

---

### 🤖 Phase 5: 에이전트 기능 추가 (2025 Q2)
**목표**: 단순 QA → 자율 작업 수행

#### 4.1 도구 사용 (Tool Use)
- [ ] **검색 에이전트**: 특정 조건 문서 자동 검색
- [ ] **계산 에이전트**: 수식 계산, 단위 변환
- [ ] **시각화 에이전트**: 데이터 → 차트 자동 생성
- [ ] **파일 관리**: 문서 정리, 분류, 태깅

#### 4.2 다단계 추론 (Multi-Step Reasoning)
- [ ] **Plan & Execute**: 복잡한 질문 분해 → 단계별 실행
- [ ] **Self-Reflection**: 답변 검증 및 개선
- [ ] **Iterative Refinement**: 피드백 기반 재검색

#### 4.3 외부 도구 통합
- [ ] **Python REPL**: 실시간 코드 실행
- [ ] **데이터 분석**: pandas, numpy 자동 활용
- [ ] **API 호출**: 외부 서비스 연동 (필요 시)

**예상 소요 시간**: 6-8주
**우선순위**: Medium

---

### 👥 Phase 5: 협업 기능 (2025 Q3)
**목표**: 개인 사용 → 팀 협업

#### 5.1 공유 및 권한 관리
- [ ] **팀 DB 공유**: 부서별 공유 DB
- [ ] **권한 레벨**: Read/Write/Admin
- [ ] **액세스 로그**: 사용 기록 추적

#### 5.2 피드백 및 개선
- [ ] **답변 평가**: 👍/👎 피드백
- [ ] **오류 보고**: 잘못된 정보 신고
- [ ] **개선 제안**: 커뮤니티 기여

#### 5.3 지식 큐레이션
- [ ] **태그 시스템**: 문서 분류 체계
- [ ] **즐겨찾기**: 자주 찾는 문서
- [ ] **추천 시스템**: 관련 문서 자동 추천

**예상 소요 시간**: 4-6주
**우선순위**: Low

---

### 📊 Phase 6: 고급 분석 및 인사이트 (2025 Q4)
**목표**: 정보 제공 → 인사이트 발견

#### 6.1 트렌드 분석
- [ ] **연구 동향**: 시간별 키워드 변화
- [ ] **기술 로드맵**: 발전 방향 예측
- [ ] **Gap 분석**: 부족한 연구 영역 식별

#### 6.2 지식 그래프
- [ ] **논문 간 관계**: 인용 네트워크
- [ ] **개념 연결**: 키워드 클러스터링
- [ ] **영향력 분석**: 핵심 논문 식별

#### 6.3 자동 보고서 생성
- [ ] **주간 요약**: 새로운 문서 요약
- [ ] **프로젝트 리포트**: 관련 자료 자동 수집
- [ ] **벤치마크**: 경쟁사 분석

**예상 소요 시간**: 8-10주
**우선순위**: Future

---

## ✅ 품질 관리 원칙 (Quality Assurance)

**배경**: Phase 3 Day 2 회고를 통해 발견한 개선 영역을 시스템화

### 1️⃣ 기능 구현 후 즉시 검증
**문제**: Phase 3 Day 1에서 Response Strategy Selector를 구현했지만, enable_file_aggregation=false로 인해 실제로 작동하지 않았음. Day 2 테스트에서 우연히 발견.

**원칙**:
```python
# 새 기능 구현 후 체크리스트
✅ 1. 코드 구현 완료
✅ 2. Config 파라미터 확인 (기본값 = 의도한 동작?)
✅ 3. Quick Test 작성 및 실행
✅ 4. 실제 동작 검증
✅ 5. 문서화 (README, CHANGELOG)
```

**적용 예시**:
```python
# utils/rag_chain.py에 새 기능 추가 시
def test_new_feature():
    config = {"enable_new_feature": True}
    rag = RAGChain(config)
    result = rag.query("test query")
    assert result['new_field'] is not None
    print("✅ New feature works!")
```

---

### 2️⃣ Feature Toggle 관리 시스템
**문제**: enable_file_aggregation 같은 feature flag가 여러 곳에 분산되어 있고, 일관성 검증이 어려움.

**원칙**:
```json
// config.json - Feature Flags 섹션
{
  "feature_flags": {
    "enable_file_aggregation": true,     // Phase 3
    "enable_multi_query": true,          // Phase 2
    "enable_vision_chunking": false,     // Phase 2.5 (예정)
    "enable_metadata_search": false      // Phase 2.5.6 (예정)
  }
}
```

**검증 스크립트**:
```python
# verify_feature_flags.py (작성 예정)
def verify_flags():
    """모든 feature flag의 실제 동작을 검증"""
    for flag, enabled in config['feature_flags'].items():
        if enabled:
            assert_feature_works(flag)
```

---

### 3️⃣ 데이터 기반 의사결정
**성공 사례**: Diversity Penalty 조정

**잘한 점**:
```
추측: "diversity가 부족한 것 같아" (X)
데이터: "평균 고유 문서 2.40개, 목표 2.5개 대비 -4.0%" (O)
      ↓
조치: penalty 16.7% 증가 (0.3 → 0.35)
      ↓
예상: 고유 문서 2.6개로 증가
```

**원칙**:
- 모든 개선 조치에 **정량 지표** 설정
- 변경 전/후 **측정 및 비교**
- **문서화** (근거, 조치, 예상 효과)

---

### 4️⃣ 통합 테스트 우선
**교훈**: Unit Test만으로는 불충분

**현실**:
```
Unit Test: ✅ diversity_penalty 적용 확인
Integration Test: ❌ enable_file_aggregation=false로 전체 플로우 막힘
                   ↑ 여기서 발견!
```

**원칙**:
1. **Unit Test**: 개별 함수 동작
2. **Integration Test**: 전체 플로우 (실제 쿼리 → 답변)
3. **Comprehensive Test**: 다양한 시나리오 (35-40개)

**주기**:
- Unit Test: 코드 변경 시마다
- Integration Test: Feature 완료 시
- Comprehensive Test: Phase 완료 시 (주 1회)

---

### 5️⃣ Config 파일 리뷰 프로세스
**문제**: config.json 수정 시 실수 방지 부족

**원칙**:
```bash
# 새 기능 추가 시
1. config.json에 파라미터 추가
2. config.json.example 업데이트
3. README에 설명 추가
4. verify_config.py 실행 (검증 스크립트)
```

**검증 스크립트 예시**:
```python
# verify_config.py
def verify_config(config_file="config.json"):
    """Config 파일 무결성 검증"""
    config = load_config(config_file)

    # Phase 3 관련 검증
    if config.get('enable_file_aggregation'):
        assert 'file_aggregation_strategy' in config
        assert 'file_aggregation_top_n' in config
        print("✅ File aggregation config OK")

    # Diversity 관련 검증
    penalty = config.get('diversity_penalty', 0)
    assert 0 <= penalty <= 1.0
    print(f"✅ Diversity penalty OK: {penalty}")
```

---

### 6️⃣ 회고 및 개선 주기
**원칙**: 각 Phase 완료 후 회고

**템플릿**:
1. **잘한 점** (What Went Well)
   - 데이터 기반 의사결정
   - 체계적 문서화

2. **아쉬운 점** (What Needs Improvement)
   - Feature flag 검증 부족
   - 통합 테스트 지연

3. **배운 점** (Lessons Learned)
   - 기능 구현 ≠ 기능 작동
   - 설정 파일 관리 중요성

4. **Action Items**
   - verify_feature_flags.py 작성
   - Quick test 템플릿 생성

---

## 🧭 개발 가이드라인

### 🎨 코드 스타일
- **Python Style**: PEP 8 준수
- **Docstring**: Google 스타일
- **Type Hints**: 필수 (Python 3.10+)
- **Logging**: logging 모듈 사용 (print 금지)

### 🏗️ 아키텍처 원칙
1. **모듈화**: 각 기능을 독립적 모듈로 분리
2. **의존성 주입**: 하드코딩 최소화
3. **설정 중심**: config.json으로 모든 동작 제어
4. **오프라인 우선**: 외부 네트워크 의존성 최소화
5. **테스트 가능**: 단위 테스트 작성 용이하게

### 🔒 보안 원칙
- **API Key 보호**: `.env` 파일 또는 환경 변수 (config.json 금지)
- **입력 검증**: 사용자 입력 sanitization
- **로그 보안**: 민감 정보 마스킹
- **권한 최소화**: 필요한 권한만 요청

### 📝 커밋 규칙
```
<type>(<scope>): <subject>

<body>

<footer>
```

**Type**:
- `feat`: 새로운 기능
- `fix`: 버그 수정
- `docs`: 문서 변경
- `refactor`: 리팩토링
- `test`: 테스트 추가/수정
- `chore`: 빌드/설정 변경

**예시**:
```
feat(rag_chain): Add exhaustive retrieval mode

- Detect "모든/전체" keywords
- Increase max_results to 100
- Add classifier integration

Closes #42
```

---

## 🧪 테스트 전략

### 1️⃣ 단위 테스트
```bash
# 개별 모듈 테스트
python -m pytest tests/unit/
```

### 2️⃣ 통합 테스트
```bash
# Phase 2 통합 테스트
python test_phase2_integration.py

# Phase 2 검증 테스트
python test_phase2_verification.py
```

### 3️⃣ 전체 시스템 테스트
```bash
# 종합 성능 테스트
python comprehensive_test.py

# 빠른 성능 체크
python quick_performance_check.py
```

### 4️⃣ 빌드 검증
```bash
# 빌드 후 실행 테스트
dist/RAG_System_v3.6.0/RAG_System_v3.6.0.exe
```

---

## 🚀 빌드 및 배포

### PyInstaller 빌드
```bash
# 빌드 실행
venv/Scripts/python.exe -m PyInstaller -y \
  --name=RAG_System_v3.6.0 \
  --icon=oc.ico \
  --onedir \
  --console \
  --add-data="resources;resources" \
  --add-data="config.json.example;." \
  --add-data="models;models" \
  --hidden-import=win32timezone \
  --hidden-import=sentencepiece \
  --hidden-import=chromadb.api.segment \
  --hidden-import=chromadb.api.types \
  --hidden-import=chromadb.segment.impl.vector.local_persistent_hnsw \
  --collect-all=chromadb \
  --exclude-module=magic \
  desktop_app.py

# 빌드 결과 확인
dir dist\RAG_System_v3.6.0
```

### 배포 체크리스트
- [ ] config.json.example 업데이트
- [ ] README.md 버전 정보 업데이트
- [ ] CHANGELOG 작성
- [ ] 테스트 통과 확인
- [ ] 빌드 성공 확인
- [ ] 실행 파일 동작 확인
- [ ] Git 태그 생성 (v3.6.0)
- [ ] Release 노트 작성

---

## 📚 주요 문서

### 사용자 문서
- [README.md](README.md) - 설치 및 사용 가이드
- [설정 가이드](docs/CONFIGURATION.md) - 상세 설정 방법
- [FAQ](docs/FAQ.md) - 자주 묻는 질문

### 개발자 문서
- [SYSTEM_QC_REPORT.md](SYSTEM_QC_REPORT.md) - 품질 검증 보고서
- [Phase 2 완료 요약](docs/PHASE2_COMPLETION_SUMMARY.md)
- [질문 분류기 가이드](docs/QUESTION_CLASSIFIER_GUIDE.md)
- [Phase D 구현 계획](docs/phase_d_implementation_plan.md)

### 기술 문서
- [아키텍처 다이어그램](docs/ARCHITECTURE.md)
- [API 레퍼런스](docs/API_REFERENCE.md)
- [성능 벤치마크](docs/BENCHMARKS.md)

---

## 🤝 기여 방법

### 이슈 제보
1. GitHub Issues에서 이슈 검색
2. 중복 이슈 없으면 새 이슈 생성
3. 템플릿에 따라 상세 정보 기입

### 코드 기여
1. Fork 후 feature 브랜치 생성
2. 코드 작성 및 테스트
3. Pull Request 생성
4. 리뷰 반영 후 머지

### 문서 기여
- 오타 수정: 즉시 PR
- 내용 추가: Issue 논의 후 PR
- 번역: 별도 브랜치에서 작업

---

## 📞 문의 및 지원

- **GitHub Issues**: 버그 제보 및 기능 요청
- **Discussions**: 질문 및 토론
- **Email**: [내부 메일 주소]

---

## 📄 라이선스

이 프로젝트는 내부 사용 목적으로 제작되었습니다.
외부 공개 시 라이선스 정책을 별도로 정의할 예정입니다.

---

## 🙏 감사의 말

이 프로젝트는 다음 오픈소스 프로젝트들을 기반으로 합니다:
- [LangChain](https://github.com/langchain-ai/langchain) - RAG 프레임워크
- [ChromaDB](https://github.com/chroma-core/chroma) - 벡터 데이터베이스
- [PySide6](https://wiki.qt.io/Qt_for_Python) - Qt6 Python 바인딩
- [sentence-transformers](https://github.com/UKPLab/sentence-transformers) - Re-ranker

---

## 📋 개발 히스토리

### v3.7.0 (2025-11-12)
**테마**: Phase 3 - 검색 품질 및 응답 전략 개선

**주요 변경사항**:
1. **File-level Retrieval & Response Strategy Selector (Day 1)**
   - FileAggregator 클래스 개발 (WEIGHTED/COUNT 전략)
   - Exhaustive query 자동 감지 및 파일 리스트 응답
   - 일반 쿼리 vs Exhaustive 쿼리 분기 로직
   - utils/file_aggregator.py 추가

2. **Diversity Penalty 검증 및 최적화 (Day 2)**
   - Comprehensive Test 실행 (40개 케이스, 87.5% 성공률)
   - Diversity 정량 평가: 평균 고유 문서 2.40개 (목표 2.5개 대비 -4.0%)
   - Multi-doc 비율 97.1% 달성 (목표 60% 초과 달성)
   - Config 조정: diversity_penalty 0.3 → 0.35, enable_file_aggregation true

3. **중요 발견: Exhaustive Query 미작동 원인 규명**
   - enable_file_aggregation=false 설정으로 인해 Phase 3 기능 작동 안 함
   - 3개 exhaustive query 테스트가 일반 RAG 답변으로 처리됨
   - Response Strategy Selector 조건문 우회됨
   - EXHAUSTIVE_QUERY_ANALYSIS.md 작성

4. **ChromaDB 복구 및 재임베딩**
   - Rust 바인딩 에러 발견 (pyo3_runtime.PanicException)
   - data/chroma_db_backup에 백업 (8,177 embeddings)
   - 34개 문서 (31 PDF + 3 PPTX) 재임베딩 진행

5. **품질 관리 원칙 체계화**
   - 기능 구현 후 즉시 검증 체크리스트 작성
   - Feature Toggle 관리 시스템 정의
   - 데이터 기반 의사결정 프로세스 확립
   - 통합 테스트 우선 원칙 수립
   - Config 파일 리뷰 프로세스 정의
   - 회고 및 개선 주기 템플릿 작성

**문서화**:
- DAY2_VERIFICATION_FINAL_REPORT.md - Diversity 검증 최종 보고서
- EXHAUSTIVE_QUERY_ANALYSIS.md - Exhaustive query 미작동 분석
- CONFIG_ADJUSTMENT_SUMMARY.md - Config 조정 근거 및 예상 효과
- .CLAUDE.md 업데이트 - Phase 3 진행 상황, 품질 관리 원칙 추가

**영향**:
- diversity_penalty 증가로 고유 문서 수 개선 예상 (2.40 → 2.6개)
- enable_file_aggregation 활성화로 Exhaustive query 기능 작동
- DB 재구축 필요 (ChromaDB 복구)

**다음 단계 (Day 3)**:
- Config 검증 테스트 (diversity_penalty=0.35, enable_file_aggregation=true)
- Exhaustive query 파일 리스트 형식 검증
- 회귀 테스트 (35개 테스트 케이스 재실행)
- 성능 벤치마킹 (일반 vs Exhaustive 쿼리)

---

### v3.6.2 (2025-01-09)
**테마**: 메타데이터 검색 아키텍처 분석 및 Phase 2.5 로드맵 업데이트

**주요 변경사항**:
1. **상용 RAG 서비스 벤치마크 분석**
   - Semantic Scholar, Perplexity, Elicit, ChatGPT Enterprise 아키텍처 분석
   - Hybrid Search, Query Decomposition, Knowledge Graph 전략 연구
   - `docs/METADATA_SEARCH_ANALYSIS.md` 작성

2. **Phase 2.5.6: 메타데이터 기반 검색 로드맵 추가**
   - PDF 메타데이터 자동 추출 파이프라인 (GROBID/PyPDF2)
   - ChromaDB 메타데이터 필드 확장 (authors, title, journal, year, doi)
   - Question Classifier에 `metadata_search` 타입 추가
   - 2단계 검색 전략 (메타데이터 필터 → 전체 청크 로드 → 요약)

3. **구현 우선순위 정의**:
   - Phase 1 (1-2일): 파일명 기반 검색 (즉시 적용 가능)
   - Phase 2 (3-4일): PyPDF2 기반 메타데이터 추출
   - Phase 3 (선택): GROBID 통합 (90% 정확도)

**배경**:
- 사용자 요구사항: "김철수 저자의 논문 요약" 같은 메타데이터 쿼리 지원 필요
- 현재 시스템: 벡터 검색만으로는 메타데이터 정확 매칭 불가
- 상용 서비스: Metadata Index + Vector Index 병렬 운영

**영향**:
- 코드 변경 없음 (분석 및 문서화만)
- 향후 구현 시 DB 재구축 필요 (메타데이터 필드 추가)

---

### v3.6.1 (2025-01-09)
**테마**: 벡터 DB 최적화 및 임베딩 모델 유연성 강화

**주요 변경사항**:
1. **ChromaDB 거리 함수 cosine 변경**
   - 정규화된 임베딩 모델에 최적화 (mxbai-embed-large, qwen3-embedding-8B)
   - config.json에 `chroma_distance_function: "cosine"` 추가
   - VectorStoreManager에 distance_function 파라미터 추가

2. **공유 DB 볼륨 레이블 수정**
   - LGDKBB → LGDKRB (정확한 볼륨 레이블)
   - drive_scanner.py 및 main_window.py 에러 메시지 수정

3. **qwen3-embedding-8B 테스트 스크립트 추가**
   - check_qwen3_embedding.py 생성
   - 차원(4096d), 정규화(L2=1.0), 속도 검증
   - Ollama/OpenAI 호환 API 모두 지원

**영향**:
- DB 재구축 필요 (거리 함수 변경)
- mxbai ↔ qwen3 모델 전환 시 DB 재구축 필요 (차원 불일치: 1024 vs 4096)

---

**마지막 업데이트**: 2025-11-12
**작성자**: Claude Code + OC Papers Team
**버전**: v3.7.0
